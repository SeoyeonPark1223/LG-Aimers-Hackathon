{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "706c7aa6",
   "metadata": {
    "papermill": {
     "duration": 0.005286,
     "end_time": "2025-02-18T17:21:45.964229",
     "exception": false,
     "start_time": "2025-02-18T17:21:45.958943",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 데이터셋 비교 (LGBM) - 베이스라인 버전 (one-hot encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c95e124f",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-18T17:21:45.974749Z",
     "iopub.status.busy": "2025-02-18T17:21:45.974443Z",
     "iopub.status.idle": "2025-02-18T17:21:46.722771Z",
     "shell.execute_reply": "2025-02-18T17:21:46.721642Z"
    },
    "papermill": {
     "duration": 0.755383,
     "end_time": "2025-02-18T17:21:46.724344",
     "exception": false,
     "start_time": "2025-02-18T17:21:45.968961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/lg-aimers/sample_submission.csv\n",
      "/kaggle/input/lg-aimers/train.csv\n",
      "/kaggle/input/lg-aimers/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f50c1435",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:21:46.735372Z",
     "iopub.status.busy": "2025-02-18T17:21:46.735018Z",
     "iopub.status.idle": "2025-02-18T17:21:50.898673Z",
     "shell.execute_reply": "2025-02-18T17:21:50.898004Z"
    },
    "papermill": {
     "duration": 4.170746,
     "end_time": "2025-02-18T17:21:50.900229",
     "exception": false,
     "start_time": "2025-02-18T17:21:46.729483",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = '/kaggle/input/lg-aimers/'\n",
    "\n",
    "train = pd.read_csv(data_path + 'train.csv', index_col= 'ID')\n",
    "test = pd.read_csv(data_path + 'test.csv', index_col= 'ID')\n",
    "submission = pd.read_csv(data_path + 'sample_submission.csv', index_col= 'ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d53d4d",
   "metadata": {
    "papermill": {
     "duration": 0.004567,
     "end_time": "2025-02-18T17:21:50.909746",
     "exception": false,
     "start_time": "2025-02-18T17:21:50.905179",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. 데이터 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f500c013",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:21:50.919931Z",
     "iopub.status.busy": "2025-02-18T17:21:50.919616Z",
     "iopub.status.idle": "2025-02-18T17:21:51.133158Z",
     "shell.execute_reply": "2025-02-18T17:21:51.132413Z"
    },
    "papermill": {
     "duration": 0.220377,
     "end_time": "2025-02-18T17:21:51.134640",
     "exception": false,
     "start_time": "2025-02-18T17:21:50.914263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([train, test], ignore_index= True)\n",
    "all_data = all_data.drop('임신 성공 여부', axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4639acca",
   "metadata": {
    "papermill": {
     "duration": 0.004519,
     "end_time": "2025-02-18T17:21:51.144192",
     "exception": false,
     "start_time": "2025-02-18T17:21:51.139673",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. 피처 엔지니어링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e339a0f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:21:51.154377Z",
     "iopub.status.busy": "2025-02-18T17:21:51.154133Z",
     "iopub.status.idle": "2025-02-18T17:21:51.158451Z",
     "shell.execute_reply": "2025-02-18T17:21:51.157817Z"
    },
    "papermill": {
     "duration": 0.010804,
     "end_time": "2025-02-18T17:21:51.159630",
     "exception": false,
     "start_time": "2025-02-18T17:21:51.148826",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "categorical_columns = [\n",
    "    \"시술 시기 코드\",\n",
    "    \"시술 당시 나이\",\n",
    "    \"시술 유형\",\n",
    "    \"특정 시술 유형\",\n",
    "    \"배란 자극 여부\",\n",
    "    \"배란 유도 유형\",\n",
    "    \"단일 배아 이식 여부\",\n",
    "    \"착상 전 유전 검사 사용 여부\",\n",
    "    \"착상 전 유전 진단 사용 여부\",\n",
    "    \"남성 주 불임 원인\",\n",
    "    \"남성 부 불임 원인\",\n",
    "    \"여성 주 불임 원인\",\n",
    "    \"여성 부 불임 원인\",\n",
    "    \"부부 주 불임 원인\",\n",
    "    \"부부 부 불임 원인\",\n",
    "    \"불명확 불임 원인\",\n",
    "    \"불임 원인 - 난관 질환\",\n",
    "    \"불임 원인 - 남성 요인\",\n",
    "    \"불임 원인 - 배란 장애\",\n",
    "    \"불임 원인 - 여성 요인\",\n",
    "    \"불임 원인 - 자궁경부 문제\",\n",
    "    \"불임 원인 - 자궁내막증\",\n",
    "    \"불임 원인 - 정자 농도\",\n",
    "    \"불임 원인 - 정자 면역학적 요인\",\n",
    "    \"불임 원인 - 정자 운동성\",\n",
    "    \"불임 원인 - 정자 형태\",\n",
    "    \"배아 생성 주요 이유\",\n",
    "    \"총 시술 횟수\",\n",
    "    \"클리닉 내 총 시술 횟수\",\n",
    "    \"IVF 시술 횟수\",\n",
    "    \"DI 시술 횟수\",\n",
    "    \"총 임신 횟수\",\n",
    "    \"IVF 임신 횟수\",\n",
    "    \"DI 임신 횟수\",\n",
    "    \"총 출산 횟수\",\n",
    "    \"IVF 출산 횟수\",\n",
    "    \"DI 출산 횟수\",\n",
    "    \"난자 출처\",\n",
    "    \"정자 출처\",\n",
    "    \"난자 기증자 나이\",\n",
    "    \"정자 기증자 나이\",\n",
    "    \"동결 배아 사용 여부\",\n",
    "    \"신선 배아 사용 여부\",\n",
    "    \"기증 배아 사용 여부\",\n",
    "    \"대리모 여부\",\n",
    "    \"PGD 시술 여부\",\n",
    "    \"PGS 시술 여부\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bb812a3e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:21:51.169653Z",
     "iopub.status.busy": "2025-02-18T17:21:51.169431Z",
     "iopub.status.idle": "2025-02-18T17:21:53.882145Z",
     "shell.execute_reply": "2025-02-18T17:21:53.881336Z"
    },
    "papermill": {
     "duration": 2.719384,
     "end_time": "2025-02-18T17:21:53.883684",
     "exception": false,
     "start_time": "2025-02-18T17:21:51.164300",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 카테고리형 컬럼들을 문자열로 변환\n",
    "for col in categorical_columns:\n",
    "    all_data[col] = all_data[col].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61af59ab",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:21:53.894421Z",
     "iopub.status.busy": "2025-02-18T17:21:53.894155Z",
     "iopub.status.idle": "2025-02-18T17:21:59.039466Z",
     "shell.execute_reply": "2025-02-18T17:21:59.038566Z"
    },
    "papermill": {
     "duration": 5.151981,
     "end_time": "2025-02-18T17:21:59.040711",
     "exception": false,
     "start_time": "2025-02-18T17:21:53.888730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<346418x205 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 16281646 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot_encoder = OneHotEncoder()\n",
    "\n",
    "encoded_cat_matrix = onehot_encoder.fit_transform(all_data[categorical_columns])\n",
    "\n",
    "encoded_cat_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bb5562c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:21:59.051519Z",
     "iopub.status.busy": "2025-02-18T17:21:59.051139Z",
     "iopub.status.idle": "2025-02-18T17:21:59.055032Z",
     "shell.execute_reply": "2025-02-18T17:21:59.054257Z"
    },
    "papermill": {
     "duration": 0.010316,
     "end_time": "2025-02-18T17:21:59.056187",
     "exception": false,
     "start_time": "2025-02-18T17:21:59.045871",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "numeric_columns = [\n",
    "    \"임신 시도 또는 마지막 임신 경과 연수\",\n",
    "    \"총 생성 배아 수\",\n",
    "    \"미세주입된 난자 수\",\n",
    "    \"미세주입에서 생성된 배아 수\",\n",
    "    \"이식된 배아 수\",\n",
    "    \"미세주입 배아 이식 수\",\n",
    "    \"저장된 배아 수\",\n",
    "    \"미세주입 후 저장된 배아 수\",\n",
    "    \"해동된 배아 수\",\n",
    "    \"해동 난자 수\",\n",
    "    \"수집된 신선 난자 수\",\n",
    "    \"저장된 신선 난자 수\",\n",
    "    \"혼합된 난자 수\",\n",
    "    \"파트너 정자와 혼합된 난자 수\",\n",
    "    \"기증자 정자와 혼합된 난자 수\",\n",
    "    \"난자 채취 경과일\",\n",
    "    \"난자 해동 경과일\",\n",
    "    \"난자 혼합 경과일\",\n",
    "    \"배아 이식 경과일\",\n",
    "    \"배아 해동 경과일\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a8e433d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:21:59.066358Z",
     "iopub.status.busy": "2025-02-18T17:21:59.066113Z",
     "iopub.status.idle": "2025-02-18T17:21:59.070900Z",
     "shell.execute_reply": "2025-02-18T17:21:59.070118Z"
    },
    "papermill": {
     "duration": 0.011138,
     "end_time": "2025-02-18T17:21:59.072091",
     "exception": false,
     "start_time": "2025-02-18T17:21:59.060953",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['시술 시기 코드', '시술 당시 나이', '임신 시도 또는 마지막 임신 경과 연수', '시술 유형', '특정 시술 유형',\n",
       "       '배란 자극 여부', '배란 유도 유형', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부',\n",
       "       '착상 전 유전 진단 사용 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인',\n",
       "       '여성 부 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인', '불명확 불임 원인', '불임 원인 - 난관 질환',\n",
       "       '불임 원인 - 남성 요인', '불임 원인 - 배란 장애', '불임 원인 - 여성 요인', '불임 원인 - 자궁경부 문제',\n",
       "       '불임 원인 - 자궁내막증', '불임 원인 - 정자 농도', '불임 원인 - 정자 면역학적 요인',\n",
       "       '불임 원인 - 정자 운동성', '불임 원인 - 정자 형태', '배아 생성 주요 이유', '총 시술 횟수',\n",
       "       '클리닉 내 총 시술 횟수', 'IVF 시술 횟수', 'DI 시술 횟수', '총 임신 횟수', 'IVF 임신 횟수',\n",
       "       'DI 임신 횟수', '총 출산 횟수', 'IVF 출산 횟수', 'DI 출산 횟수', '총 생성 배아 수',\n",
       "       '미세주입된 난자 수', '미세주입에서 생성된 배아 수', '이식된 배아 수', '미세주입 배아 이식 수', '저장된 배아 수',\n",
       "       '미세주입 후 저장된 배아 수', '해동된 배아 수', '해동 난자 수', '수집된 신선 난자 수', '저장된 신선 난자 수',\n",
       "       '혼합된 난자 수', '파트너 정자와 혼합된 난자 수', '기증자 정자와 혼합된 난자 수', '난자 출처', '정자 출처',\n",
       "       '난자 기증자 나이', '정자 기증자 나이', '동결 배아 사용 여부', '신선 배아 사용 여부', '기증 배아 사용 여부',\n",
       "       '대리모 여부', 'PGD 시술 여부', 'PGS 시술 여부', '난자 채취 경과일', '난자 해동 경과일',\n",
       "       '난자 혼합 경과일', '배아 이식 경과일', '배아 해동 경과일'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_columns = all_data.columns\n",
    "all_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "27a53f5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:21:59.082389Z",
     "iopub.status.busy": "2025-02-18T17:21:59.082149Z",
     "iopub.status.idle": "2025-02-18T17:21:59.086505Z",
     "shell.execute_reply": "2025-02-18T17:21:59.085721Z"
    },
    "papermill": {
     "duration": 0.01093,
     "end_time": "2025-02-18T17:21:59.087861",
     "exception": false,
     "start_time": "2025-02-18T17:21:59.076931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "208489c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:21:59.098982Z",
     "iopub.status.busy": "2025-02-18T17:21:59.098730Z",
     "iopub.status.idle": "2025-02-18T17:21:59.579953Z",
     "shell.execute_reply": "2025-02-18T17:21:59.579226Z"
    },
    "papermill": {
     "duration": 0.488182,
     "end_time": "2025-02-18T17:21:59.581390",
     "exception": false,
     "start_time": "2025-02-18T17:21:59.093208",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "extracted_data_sprs = sparse.hstack([sparse.csr_matrix(all_data[numeric_columns]),\n",
    "                               encoded_cat_matrix],\n",
    "                              format='csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3aeedfc",
   "metadata": {
    "papermill": {
     "duration": 0.004739,
     "end_time": "2025-02-18T17:21:59.591388",
     "exception": false,
     "start_time": "2025-02-18T17:21:59.586649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c005a6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:21:59.601915Z",
     "iopub.status.busy": "2025-02-18T17:21:59.601616Z",
     "iopub.status.idle": "2025-02-18T17:21:59.940988Z",
     "shell.execute_reply": "2025-02-18T17:21:59.940015Z"
    },
    "papermill": {
     "duration": 0.346354,
     "end_time": "2025-02-18T17:21:59.942530",
     "exception": false,
     "start_time": "2025-02-18T17:21:59.596176",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_train = len(train) \n",
    "\n",
    "X = extracted_data_sprs[:num_train]\n",
    "X_test = extracted_data_sprs[num_train:]\n",
    "\n",
    "y = train['임신 성공 여부'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4769de9a",
   "metadata": {
    "papermill": {
     "duration": 0.004687,
     "end_time": "2025-02-18T17:21:59.952625",
     "exception": false,
     "start_time": "2025-02-18T17:21:59.947938",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. 평가 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f959e70",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:21:59.963141Z",
     "iopub.status.busy": "2025-02-18T17:21:59.962849Z",
     "iopub.status.idle": "2025-02-18T17:21:59.966501Z",
     "shell.execute_reply": "2025-02-18T17:21:59.965676Z"
    },
    "papermill": {
     "duration": 0.010387,
     "end_time": "2025-02-18T17:21:59.967758",
     "exception": false,
     "start_time": "2025-02-18T17:21:59.957371",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lgb_roc_auc(y_pred, dataset):\n",
    "    y_true = dataset.get_label()\n",
    "    return \"roc_auc\", roc_auc_score(y_true, y_pred), True  # (지표 이름, 값, 높은 값이 더 좋은지 여부)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf6fdc6",
   "metadata": {
    "papermill": {
     "duration": 0.004639,
     "end_time": "2025-02-18T17:21:59.977242",
     "exception": false,
     "start_time": "2025-02-18T17:21:59.972603",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. 파라미터 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5bee1424",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:21:59.987719Z",
     "iopub.status.busy": "2025-02-18T17:21:59.987445Z",
     "iopub.status.idle": "2025-02-18T17:22:04.306905Z",
     "shell.execute_reply": "2025-02-18T17:22:04.305920Z"
    },
    "papermill": {
     "duration": 4.326336,
     "end_time": "2025-02-18T17:22:04.308455",
     "exception": false,
     "start_time": "2025-02-18T17:21:59.982119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 8:2 비율로 훈련 데이터, 검증 데이터 분리 (베이지안 최적화 수행용)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "                                                      test_size=0.2, \n",
    "                                                      random_state=0)\n",
    "\n",
    "# 베이지안 최적화용 데이터셋\n",
    "bayes_dtrain = lgb.Dataset(X_train, y_train)\n",
    "bayes_dvalid = lgb.Dataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a48f0285",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:22:04.320608Z",
     "iopub.status.busy": "2025-02-18T17:22:04.320005Z",
     "iopub.status.idle": "2025-02-18T17:22:04.324480Z",
     "shell.execute_reply": "2025-02-18T17:22:04.323872Z"
    },
    "papermill": {
     "duration": 0.011749,
     "end_time": "2025-02-18T17:22:04.325699",
     "exception": false,
     "start_time": "2025-02-18T17:22:04.313950",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 베이지안 최적화를 위한 하이퍼파라미터 범위\n",
    "# TODO: 점점 줄여나가자!!!!\n",
    "param_bounds = {\n",
    "    'num_leaves': (30, 100),  \n",
    "    'lambda_l1': (0, 1),  \n",
    "    'lambda_l2': (0, 2),  \n",
    "    'feature_fraction': (0.7, 1),  \n",
    "    'bagging_fraction': (0.5, 0.8),  \n",
    "    'min_child_samples': (5, 50),  \n",
    "    'min_child_weight': (25, 50)  \n",
    "}\n",
    "\n",
    "# 값이 고정된 하이퍼파라미터\n",
    "fixed_params = {'objective': 'binary', # binary classification\n",
    "                'learning_rate': 0.005, # 0.01~0.001\n",
    "                'bagging_freq': 1, # 0 or 1\n",
    "                'force_row_wise': True,\n",
    "                'random_state': 1991}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "14d69a52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:22:04.336484Z",
     "iopub.status.busy": "2025-02-18T17:22:04.336260Z",
     "iopub.status.idle": "2025-02-18T17:22:04.341267Z",
     "shell.execute_reply": "2025-02-18T17:22:04.340664Z"
    },
    "papermill": {
     "duration": 0.011574,
     "end_time": "2025-02-18T17:22:04.342371",
     "exception": false,
     "start_time": "2025-02-18T17:22:04.330797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import early_stopping\n",
    "\n",
    "def eval_function(num_leaves, lambda_l1, lambda_l2, feature_fraction,\n",
    "                  bagging_fraction, min_child_samples, min_child_weight):\n",
    "    '''최적화하려는 평가지표 계산 함수'''\n",
    "    \n",
    "    # 베이지안 최적화를 수행할 하이퍼파라미터 \n",
    "    params = {'num_leaves': int(round(num_leaves)),\n",
    "              'lambda_l1': lambda_l1,\n",
    "              'lambda_l2': lambda_l2,\n",
    "              'feature_fraction': feature_fraction,\n",
    "              'bagging_fraction': bagging_fraction,\n",
    "              'min_child_samples': int(round(min_child_samples)),\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'feature_pre_filter': False}\n",
    "    # 고정된 하이퍼파라미터도 추가\n",
    "    params.update(fixed_params)\n",
    "    \n",
    "    print('하이퍼파라미터:', params)    \n",
    "    \n",
    "    # LightGBM 모델 훈련\n",
    "    lgb_model = lgb.train(params=params, \n",
    "                           train_set=bayes_dtrain,\n",
    "                           num_boost_round=2500,\n",
    "                           valid_sets=bayes_dvalid,\n",
    "                           callbacks=[early_stopping(stopping_rounds=200)])\n",
    "    # 검증 데이터로 예측 수행\n",
    "    preds = lgb_model.predict(X_valid) \n",
    "    # roc-auc 계산\n",
    "    roc_auc = roc_auc_score(y_valid, preds)\n",
    "    print(f'roc-auc : {roc_auc}\\n')\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "535c7cca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:22:04.354504Z",
     "iopub.status.busy": "2025-02-18T17:22:04.354264Z",
     "iopub.status.idle": "2025-02-18T17:22:04.409502Z",
     "shell.execute_reply": "2025-02-18T17:22:04.408604Z"
    },
    "papermill": {
     "duration": 0.062262,
     "end_time": "2025-02-18T17:22:04.411011",
     "exception": false,
     "start_time": "2025-02-18T17:22:04.348749",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# 베이지안 최적화 객체 생성\n",
    "optimizer = BayesianOptimization(f=eval_function,      # 평가지표 계산 함수\n",
    "                                 pbounds=param_bounds, # 하이퍼파라미터 범위\n",
    "                                 random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe6a73b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T17:22:04.422076Z",
     "iopub.status.busy": "2025-02-18T17:22:04.421792Z",
     "iopub.status.idle": "2025-02-18T18:16:38.882013Z",
     "shell.execute_reply": "2025-02-18T18:16:38.880865Z"
    },
    "papermill": {
     "duration": 3274.467231,
     "end_time": "2025-02-18T18:16:38.883422",
     "exception": false,
     "start_time": "2025-02-18T17:22:04.416191",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | lambda_l1 | lambda_l2 | min_ch... | min_ch... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "하이퍼파라미터: {'num_leaves': 61, 'lambda_l1': 0.6027633760716439, 'lambda_l2': 1.0897663659937937, 'feature_fraction': 0.9145568099117258, 'bagging_fraction': 0.6646440511781975, 'min_child_samples': 24, 'min_child_weight': 41.147352826666406, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1692]\tvalid_0's binary_logloss: 0.488785\n",
      "roc-auc : 0.7421527852128359\n",
      "\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.6646   \u001b[39m | \u001b[39m0.9146   \u001b[39m | \u001b[39m0.6028   \u001b[39m | \u001b[39m1.09     \u001b[39m | \u001b[39m24.06    \u001b[39m | \u001b[39m41.15    \u001b[39m | \u001b[39m60.63    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 95, 'lambda_l1': 0.3834415188257777, 'lambda_l2': 1.5834500761653292, 'feature_fraction': 0.9890988281503088, 'bagging_fraction': 0.7675319002346239, 'min_child_samples': 29, 'min_child_weight': 39.20111402734831, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1314]\tvalid_0's binary_logloss: 0.489021\n",
      "roc-auc : 0.7416721701177522\n",
      "\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.7675   \u001b[39m | \u001b[39m0.9891   \u001b[39m | \u001b[39m0.3834   \u001b[39m | \u001b[39m1.583    \u001b[39m | \u001b[39m28.8     \u001b[39m | \u001b[39m39.2     \u001b[39m | \u001b[39m94.79    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 99, 'lambda_l1': 0.02021839744032572, 'lambda_l2': 1.665239691095876, 'feature_fraction': 0.7261387899104622, 'bagging_fraction': 0.5213108174593661, 'min_child_samples': 40, 'min_child_weight': 46.75030370617048, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1290]\tvalid_0's binary_logloss: 0.48902\n",
      "roc-auc : 0.7419983368327655\n",
      "\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.742    \u001b[39m | \u001b[39m0.5213   \u001b[39m | \u001b[39m0.7261   \u001b[39m | \u001b[39m0.02022  \u001b[39m | \u001b[39m1.665    \u001b[39m | \u001b[39m40.02    \u001b[39m | \u001b[39m46.75    \u001b[39m | \u001b[39m98.5     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 96, 'lambda_l1': 0.7805291762864555, 'lambda_l2': 0.23654885173786644, 'feature_fraction': 0.8384438086758795, 'bagging_fraction': 0.7397475692650171, 'min_child_samples': 34, 'min_child_weight': 28.58383218522616, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1326]\tvalid_0's binary_logloss: 0.489\n",
      "roc-auc : 0.7417613579098494\n",
      "\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.7418   \u001b[39m | \u001b[39m0.7397   \u001b[39m | \u001b[39m0.8384   \u001b[39m | \u001b[39m0.7805   \u001b[39m | \u001b[39m0.2365   \u001b[39m | \u001b[39m33.8     \u001b[39m | \u001b[39m28.58    \u001b[39m | \u001b[39m96.13    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.26455561210462697, 'lambda_l2': 1.5484673788684333, 'feature_fraction': 0.8243985819971571, 'bagging_fraction': 0.6565544965250215, 'min_child_samples': 26, 'min_child_weight': 39.21084872171621, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2493]\tvalid_0's binary_logloss: 0.488675\n",
      "roc-auc : 0.7423475571360095\n",
      "\n",
      "| \u001b[35m5        \u001b[39m | \u001b[35m0.7423   \u001b[39m | \u001b[35m0.6566   \u001b[39m | \u001b[35m0.8244   \u001b[39m | \u001b[35m0.2646   \u001b[39m | \u001b[35m1.548    \u001b[39m | \u001b[35m25.53    \u001b[39m | \u001b[35m39.21    \u001b[39m | \u001b[35m31.32    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 61, 'lambda_l1': 0.6169339968747569, 'lambda_l2': 1.8874961570292483, 'feature_fraction': 0.8836287168167264, 'bagging_fraction': 0.6852906491227632, 'min_child_samples': 36, 'min_child_weight': 33.987697514344646, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1698]\tvalid_0's binary_logloss: 0.488843\n",
      "roc-auc : 0.7420206826440516\n",
      "\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.742    \u001b[39m | \u001b[39m0.6853   \u001b[39m | \u001b[39m0.8836   \u001b[39m | \u001b[39m0.6169   \u001b[39m | \u001b[39m1.887    \u001b[39m | \u001b[39m35.68    \u001b[39m | \u001b[39m33.99    \u001b[39m | \u001b[39m60.59    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 52, 'lambda_l1': 0.6667667154456677, 'lambda_l2': 1.3412757392363188, 'feature_fraction': 0.7180676414887809, 'bagging_fraction': 0.7092893587781794, 'min_child_samples': 14, 'min_child_weight': 28.223157441371335, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1936]\tvalid_0's binary_logloss: 0.488802\n",
      "roc-auc : 0.74207642723517\n",
      "\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.7421   \u001b[39m | \u001b[39m0.7093   \u001b[39m | \u001b[39m0.7181   \u001b[39m | \u001b[39m0.6668   \u001b[39m | \u001b[39m1.341    \u001b[39m | \u001b[39m14.47    \u001b[39m | \u001b[39m28.22    \u001b[39m | \u001b[39m52.08    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 41, 'lambda_l1': 0.43860151346232035, 'lambda_l2': 1.9767476761184524, 'feature_fraction': 0.8710590311253639, 'bagging_fraction': 0.6091132312827868, 'min_child_samples': 10, 'min_child_weight': 30.221918902370867, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2207]\tvalid_0's binary_logloss: 0.488768\n",
      "roc-auc : 0.7421085437245545\n",
      "\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.7421   \u001b[39m | \u001b[39m0.6091   \u001b[39m | \u001b[39m0.8711   \u001b[39m | \u001b[39m0.4386   \u001b[39m | \u001b[39m1.977    \u001b[39m | \u001b[39m9.592    \u001b[39m | \u001b[39m30.22    \u001b[39m | \u001b[39m41.29    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 76, 'lambda_l1': 0.4663107728563063, 'lambda_l2': 0.4888511840032055, 'feature_fraction': 0.7759874807619346, 'bagging_fraction': 0.6959324976396195, 'min_child_samples': 12, 'min_child_weight': 27.75937852910763, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1550]\tvalid_0's binary_logloss: 0.488995\n",
      "roc-auc : 0.7417480493341655\n",
      "\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.6959   \u001b[39m | \u001b[39m0.776    \u001b[39m | \u001b[39m0.4663   \u001b[39m | \u001b[39m0.4889   \u001b[39m | \u001b[39m12.15    \u001b[39m | \u001b[39m27.76    \u001b[39m | \u001b[39m75.94    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 37, 'lambda_l1': 0.3687251706609641, 'lambda_l2': 1.6419864596958702, 'feature_fraction': 0.758974708504016, 'bagging_fraction': 0.5414548854045842, 'min_child_samples': 9, 'min_child_weight': 45.9486226874701, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2167]\tvalid_0's binary_logloss: 0.488797\n",
      "roc-auc : 0.742216177151219\n",
      "\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.5415   \u001b[39m | \u001b[39m0.759    \u001b[39m | \u001b[39m0.3687   \u001b[39m | \u001b[39m1.642    \u001b[39m | \u001b[39m9.37     \u001b[39m | \u001b[39m45.95    \u001b[39m | \u001b[39m36.73    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 50, 'lambda_l1': 0.9767610881903371, 'lambda_l2': 1.209691039490092, 'feature_fraction': 0.8405953604943104, 'bagging_fraction': 0.7929378395040187, 'min_child_samples': 38, 'min_child_weight': 25.979694806358015, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1976]\tvalid_0's binary_logloss: 0.488834\n",
      "roc-auc : 0.7420434124514765\n",
      "\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.742    \u001b[39m | \u001b[39m0.7929   \u001b[39m | \u001b[39m0.8406   \u001b[39m | \u001b[39m0.9768   \u001b[39m | \u001b[39m1.21     \u001b[39m | \u001b[39m38.27    \u001b[39m | \u001b[39m25.98    \u001b[39m | \u001b[39m49.8     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 78, 'lambda_l1': 0.11872771895424405, 'lambda_l2': 0.635966358787952, 'feature_fraction': 0.7888420592566434, 'bagging_fraction': 0.5360589683639507, 'min_child_samples': 24, 'min_child_weight': 26.60368740871961, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1456]\tvalid_0's binary_logloss: 0.488838\n",
      "roc-auc : 0.7420608057984246\n",
      "\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.7421   \u001b[39m | \u001b[39m0.5361   \u001b[39m | \u001b[39m0.7888   \u001b[39m | \u001b[39m0.1187   \u001b[39m | \u001b[39m0.636    \u001b[39m | \u001b[39m23.64    \u001b[39m | \u001b[39m26.6     \u001b[39m | \u001b[39m78.47    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 52, 'lambda_l1': 0.5232480534666997, 'lambda_l2': 0.18788102151688335, 'feature_fraction': 0.7796168472818336, 'bagging_fraction': 0.6699804362619726, 'min_child_samples': 31, 'min_child_weight': 48.232404939405356, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1733]\tvalid_0's binary_logloss: 0.488816\n",
      "roc-auc : 0.7421765189381861\n",
      "\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.67     \u001b[39m | \u001b[39m0.7796   \u001b[39m | \u001b[39m0.5232   \u001b[39m | \u001b[39m0.1879   \u001b[39m | \u001b[39m30.92    \u001b[39m | \u001b[39m48.23    \u001b[39m | \u001b[39m52.3     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.7163272041185655, 'lambda_l2': 0.5788121858944022, 'feature_fraction': 0.7395393587213176, 'bagging_fraction': 0.7002231139891045, 'min_child_samples': 13, 'min_child_weight': 39.66282337025208, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2478]\tvalid_0's binary_logloss: 0.488758\n",
      "roc-auc : 0.7421873201868981\n",
      "\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.7002   \u001b[39m | \u001b[39m0.7395   \u001b[39m | \u001b[39m0.7163   \u001b[39m | \u001b[39m0.5788   \u001b[39m | \u001b[39m13.24    \u001b[39m | \u001b[39m39.66    \u001b[39m | \u001b[39m31.41    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 47, 'lambda_l1': 0.6778165367962301, 'lambda_l2': 0.5400159463843297, 'feature_fraction': 0.701408642857764, 'bagging_fraction': 0.748682008765209, 'min_child_samples': 38, 'min_child_weight': 49.05471362793595, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2183]\tvalid_0's binary_logloss: 0.48884\n",
      "roc-auc : 0.7420752722853444\n",
      "\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m0.7421   \u001b[39m | \u001b[39m0.7487   \u001b[39m | \u001b[39m0.7014   \u001b[39m | \u001b[39m0.6778   \u001b[39m | \u001b[39m0.54     \u001b[39m | \u001b[39m38.08    \u001b[39m | \u001b[39m49.05    \u001b[39m | \u001b[39m47.41    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.866609869207686, 'lambda_l2': 0.5193374575684109, 'feature_fraction': 0.7710188835472112, 'bagging_fraction': 0.6723368998410637, 'min_child_samples': 24, 'min_child_weight': 49.75146074574185, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2478]\tvalid_0's binary_logloss: 0.488735\n",
      "roc-auc : 0.7422495927123732\n",
      "\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.6723   \u001b[39m | \u001b[39m0.771    \u001b[39m | \u001b[39m0.8666   \u001b[39m | \u001b[39m0.5193   \u001b[39m | \u001b[39m24.12    \u001b[39m | \u001b[39m49.75    \u001b[39m | \u001b[39m31.0     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.7213214822219586, 'lambda_l2': 1.6427023842529864, 'feature_fraction': 0.9218552514076116, 'bagging_fraction': 0.7983695320125637, 'min_child_samples': 30, 'min_child_weight': 27.224032469118534, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2487]\tvalid_0's binary_logloss: 0.488753\n",
      "roc-auc : 0.7421783875877759\n",
      "\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.7984   \u001b[39m | \u001b[39m0.9219   \u001b[39m | \u001b[39m0.7213   \u001b[39m | \u001b[39m1.643    \u001b[39m | \u001b[39m30.09    \u001b[39m | \u001b[39m27.22    \u001b[39m | \u001b[39m30.31    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 32, 'lambda_l1': 0.4038318027662431, 'lambda_l2': 1.31908281002761, 'feature_fraction': 0.9597097106367154, 'bagging_fraction': 0.7389139361765316, 'min_child_samples': 26, 'min_child_weight': 38.57058368700699, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2460]\tvalid_0's binary_logloss: 0.488687\n",
      "roc-auc : 0.7422862164674877\n",
      "\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.7389   \u001b[39m | \u001b[39m0.9597   \u001b[39m | \u001b[39m0.4038   \u001b[39m | \u001b[39m1.319    \u001b[39m | \u001b[39m26.45    \u001b[39m | \u001b[39m38.57    \u001b[39m | \u001b[39m31.72    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 37, 'lambda_l1': 0.4284162249557437, 'lambda_l2': 1.4646737303489246, 'feature_fraction': 0.7416215381277959, 'bagging_fraction': 0.527708114289154, 'min_child_samples': 21, 'min_child_weight': 43.083863946799795, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2176]\tvalid_0's binary_logloss: 0.488716\n",
      "roc-auc : 0.7423222360950013\n",
      "\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.5277   \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.4284   \u001b[39m | \u001b[39m1.465    \u001b[39m | \u001b[39m20.86    \u001b[39m | \u001b[39m43.08    \u001b[39m | \u001b[39m37.14    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 49, 'lambda_l1': 0.687751307601599, 'lambda_l2': 0.14884430304737628, 'feature_fraction': 0.9495921289217069, 'bagging_fraction': 0.701924459273281, 'min_child_samples': 15, 'min_child_weight': 48.945725544871564, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1966]\tvalid_0's binary_logloss: 0.488795\n",
      "roc-auc : 0.742136005864855\n",
      "\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m0.7421   \u001b[39m | \u001b[39m0.7019   \u001b[39m | \u001b[39m0.9496   \u001b[39m | \u001b[39m0.6878   \u001b[39m | \u001b[39m0.1488   \u001b[39m | \u001b[39m15.2     \u001b[39m | \u001b[39m48.95    \u001b[39m | \u001b[39m48.8     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.6732253611643528, 'lambda_l2': 0.6447626741248682, 'feature_fraction': 0.7726356201569491, 'bagging_fraction': 0.6842786387333677, 'min_child_samples': 21, 'min_child_weight': 41.65343742371236, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2499]\tvalid_0's binary_logloss: 0.488693\n",
      "roc-auc : 0.7423080756204287\n",
      "\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.6843   \u001b[39m | \u001b[39m0.7726   \u001b[39m | \u001b[39m0.6732   \u001b[39m | \u001b[39m0.6448   \u001b[39m | \u001b[39m21.25    \u001b[39m | \u001b[39m41.65    \u001b[39m | \u001b[39m30.34    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.8673000345641743, 'lambda_l2': 1.146903153640466, 'feature_fraction': 0.9731158530685066, 'bagging_fraction': 0.5774387387066969, 'min_child_samples': 19, 'min_child_weight': 29.47960407960771, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2315]\tvalid_0's binary_logloss: 0.488712\n",
      "roc-auc : 0.74220475598072\n",
      "\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.5774   \u001b[39m | \u001b[39m0.9731   \u001b[39m | \u001b[39m0.8673   \u001b[39m | \u001b[39m1.147    \u001b[39m | \u001b[39m18.56    \u001b[39m | \u001b[39m29.48    \u001b[39m | \u001b[39m30.55    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.2945686144616644, 'lambda_l2': 1.726832421456661, 'feature_fraction': 0.8701970194451158, 'bagging_fraction': 0.7288556863656697, 'min_child_samples': 34, 'min_child_weight': 48.25221963800884, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2488]\tvalid_0's binary_logloss: 0.488698\n",
      "roc-auc : 0.7423227128819806\n",
      "\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.7289   \u001b[39m | \u001b[39m0.8702   \u001b[39m | \u001b[39m0.2946   \u001b[39m | \u001b[39m1.727    \u001b[39m | \u001b[39m33.77    \u001b[39m | \u001b[39m48.25    \u001b[39m | \u001b[39m30.9     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.7421663200874575, 'lambda_l2': 1.0369088301685243, 'feature_fraction': 0.9038309190849851, 'bagging_fraction': 0.7415170685248147, 'min_child_samples': 46, 'min_child_weight': 49.10133221707664, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2196]\tvalid_0's binary_logloss: 0.488745\n",
      "roc-auc : 0.7422306979306517\n",
      "\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.7415   \u001b[39m | \u001b[39m0.9038   \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m1.037    \u001b[39m | \u001b[39m46.33    \u001b[39m | \u001b[39m49.1     \u001b[39m | \u001b[39m30.82    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.9912375282652814, 'lambda_l2': 0.8294373681137586, 'feature_fraction': 0.9590658681113847, 'bagging_fraction': 0.7702626252742071, 'min_child_samples': 50, 'min_child_weight': 33.334973500283, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2476]\tvalid_0's binary_logloss: 0.488712\n",
      "roc-auc : 0.7422446817077724\n",
      "\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.7703   \u001b[39m | \u001b[39m0.9591   \u001b[39m | \u001b[39m0.9912   \u001b[39m | \u001b[39m0.8294   \u001b[39m | \u001b[39m49.52    \u001b[39m | \u001b[39m33.33    \u001b[39m | \u001b[39m30.28    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 73, 'lambda_l1': 0.9083582561088861, 'lambda_l2': 1.5951228172226881, 'feature_fraction': 0.9855373681526487, 'bagging_fraction': 0.5626537451567816, 'min_child_samples': 49, 'min_child_weight': 49.52431790544004, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1389]\tvalid_0's binary_logloss: 0.488966\n",
      "roc-auc : 0.7419584397326747\n",
      "\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m0.742    \u001b[39m | \u001b[39m0.5627   \u001b[39m | \u001b[39m0.9855   \u001b[39m | \u001b[39m0.9084   \u001b[39m | \u001b[39m1.595    \u001b[39m | \u001b[39m48.95    \u001b[39m | \u001b[39m49.52    \u001b[39m | \u001b[39m72.68    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 38, 'lambda_l1': 0.4125894759919547, 'lambda_l2': 1.2844885492689035, 'feature_fraction': 0.9829799884147612, 'bagging_fraction': 0.6789272057698732, 'min_child_samples': 28, 'min_child_weight': 48.918468253545484, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2166]\tvalid_0's binary_logloss: 0.488705\n",
      "roc-auc : 0.7422640335337412\n",
      "\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.6789   \u001b[39m | \u001b[39m0.983    \u001b[39m | \u001b[39m0.4126   \u001b[39m | \u001b[39m1.284    \u001b[39m | \u001b[39m27.74    \u001b[39m | \u001b[39m48.92    \u001b[39m | \u001b[39m38.37    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 37, 'lambda_l1': 0.2562452807229223, 'lambda_l2': 1.9956441524605064, 'feature_fraction': 0.9472327579207627, 'bagging_fraction': 0.5960826420063317, 'min_child_samples': 49, 'min_child_weight': 25.66162327458516, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2208]\tvalid_0's binary_logloss: 0.488704\n",
      "roc-auc : 0.7422446047111173\n",
      "\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.5961   \u001b[39m | \u001b[39m0.9472   \u001b[39m | \u001b[39m0.2562   \u001b[39m | \u001b[39m1.996    \u001b[39m | \u001b[39m49.22    \u001b[39m | \u001b[39m25.66    \u001b[39m | \u001b[39m37.44    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 39, 'lambda_l1': 0.34067067817552577, 'lambda_l2': 1.733685424928199, 'feature_fraction': 0.8116217251737179, 'bagging_fraction': 0.7014770238649535, 'min_child_samples': 50, 'min_child_weight': 38.26105667838645, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2384]\tvalid_0's binary_logloss: 0.488706\n",
      "roc-auc : 0.7422262676615766\n",
      "\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.7015   \u001b[39m | \u001b[39m0.8116   \u001b[39m | \u001b[39m0.3407   \u001b[39m | \u001b[39m1.734    \u001b[39m | \u001b[39m49.7     \u001b[39m | \u001b[39m38.26    \u001b[39m | \u001b[39m39.43    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 99, 'lambda_l1': 0.499085454994195, 'lambda_l2': 1.5769623688863261, 'feature_fraction': 0.7936315997482007, 'bagging_fraction': 0.6517696388106659, 'min_child_samples': 6, 'min_child_weight': 49.26999683738927, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1335]\tvalid_0's binary_logloss: 0.489057\n",
      "roc-auc : 0.7417557667681292\n",
      "\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m0.7418   \u001b[39m | \u001b[39m0.6518   \u001b[39m | \u001b[39m0.7936   \u001b[39m | \u001b[39m0.4991   \u001b[39m | \u001b[39m1.577    \u001b[39m | \u001b[39m5.726    \u001b[39m | \u001b[39m49.27    \u001b[39m | \u001b[39m99.37    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 64, 'lambda_l1': 0.41676873608326626, 'lambda_l2': 1.0662996376841753, 'feature_fraction': 0.738879753618667, 'bagging_fraction': 0.6220756077714391, 'min_child_samples': 6, 'min_child_weight': 49.9029235983147, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1545]\tvalid_0's binary_logloss: 0.488915\n",
      "roc-auc : 0.7420090926731938\n",
      "\n",
      "| \u001b[39m31       \u001b[39m | \u001b[39m0.742    \u001b[39m | \u001b[39m0.6221   \u001b[39m | \u001b[39m0.7389   \u001b[39m | \u001b[39m0.4168   \u001b[39m | \u001b[39m1.066    \u001b[39m | \u001b[39m5.863    \u001b[39m | \u001b[39m49.9     \u001b[39m | \u001b[39m63.73    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 73, 'lambda_l1': 0.539517778652437, 'lambda_l2': 0.7124034966476178, 'feature_fraction': 0.9433498525822088, 'bagging_fraction': 0.6910068001455039, 'min_child_samples': 49, 'min_child_weight': 25.413385479067177, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1385]\tvalid_0's binary_logloss: 0.488899\n",
      "roc-auc : 0.7418872770549513\n",
      "\n",
      "| \u001b[39m32       \u001b[39m | \u001b[39m0.7419   \u001b[39m | \u001b[39m0.691    \u001b[39m | \u001b[39m0.9433   \u001b[39m | \u001b[39m0.5395   \u001b[39m | \u001b[39m0.7124   \u001b[39m | \u001b[39m49.1     \u001b[39m | \u001b[39m25.41    \u001b[39m | \u001b[39m72.79    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.47234836042865136, 'lambda_l2': 1.4433976885161883, 'feature_fraction': 0.9513477040596058, 'bagging_fraction': 0.7604298832340245, 'min_child_samples': 42, 'min_child_weight': 26.11229974196585, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2460]\tvalid_0's binary_logloss: 0.48875\n",
      "roc-auc : 0.7421745357807503\n",
      "\n",
      "| \u001b[39m33       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.7604   \u001b[39m | \u001b[39m0.9513   \u001b[39m | \u001b[39m0.4723   \u001b[39m | \u001b[39m1.443    \u001b[39m | \u001b[39m41.75    \u001b[39m | \u001b[39m26.11    \u001b[39m | \u001b[39m30.34    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 47, 'lambda_l1': 0.6623510569555487, 'lambda_l2': 1.8825592570107657, 'feature_fraction': 0.814581264994578, 'bagging_fraction': 0.5543272115972049, 'min_child_samples': 23, 'min_child_weight': 39.34235668478469, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1770]\tvalid_0's binary_logloss: 0.488872\n",
      "roc-auc : 0.7420620120793536\n",
      "\n",
      "| \u001b[39m34       \u001b[39m | \u001b[39m0.7421   \u001b[39m | \u001b[39m0.5543   \u001b[39m | \u001b[39m0.8146   \u001b[39m | \u001b[39m0.6624   \u001b[39m | \u001b[39m1.883    \u001b[39m | \u001b[39m23.07    \u001b[39m | \u001b[39m39.34    \u001b[39m | \u001b[39m46.83    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 66, 'lambda_l1': 0.48433944452039557, 'lambda_l2': 1.8288526587263714, 'feature_fraction': 0.9624269045448092, 'bagging_fraction': 0.7685587344797862, 'min_child_samples': 29, 'min_child_weight': 49.94249838860724, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1546]\tvalid_0's binary_logloss: 0.488891\n",
      "roc-auc : 0.7419675075695115\n",
      "\n",
      "| \u001b[39m35       \u001b[39m | \u001b[39m0.742    \u001b[39m | \u001b[39m0.7686   \u001b[39m | \u001b[39m0.9624   \u001b[39m | \u001b[39m0.4843   \u001b[39m | \u001b[39m1.829    \u001b[39m | \u001b[39m28.73    \u001b[39m | \u001b[39m49.94    \u001b[39m | \u001b[39m65.7     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.6703038601521769, 'lambda_l2': 1.8564631034932484, 'feature_fraction': 0.7126814439957323, 'bagging_fraction': 0.6925065194186371, 'min_child_samples': 28, 'min_child_weight': 44.09696757633063, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2324]\tvalid_0's binary_logloss: 0.488725\n",
      "roc-auc : 0.7422872302567795\n",
      "\n",
      "| \u001b[39m36       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.6925   \u001b[39m | \u001b[39m0.7127   \u001b[39m | \u001b[39m0.6703   \u001b[39m | \u001b[39m1.856    \u001b[39m | \u001b[39m28.02    \u001b[39m | \u001b[39m44.1     \u001b[39m | \u001b[39m31.13    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.6209835239811056, 'lambda_l2': 0.374355358714608, 'feature_fraction': 0.922659067132134, 'bagging_fraction': 0.7173229012745231, 'min_child_samples': 41, 'min_child_weight': 43.00308201272138, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2485]\tvalid_0's binary_logloss: 0.488699\n",
      "roc-auc : 0.7423006681473585\n",
      "\n",
      "| \u001b[39m37       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.7173   \u001b[39m | \u001b[39m0.9227   \u001b[39m | \u001b[39m0.621    \u001b[39m | \u001b[39m0.3744   \u001b[39m | \u001b[39m41.37    \u001b[39m | \u001b[39m43.0     \u001b[39m | \u001b[39m30.66    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.1879460453192775, 'lambda_l2': 1.973444895708173, 'feature_fraction': 0.9219666763878673, 'bagging_fraction': 0.7580460512180496, 'min_child_samples': 6, 'min_child_weight': 27.183885054606023, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2491]\tvalid_0's binary_logloss: 0.488699\n",
      "roc-auc : 0.7422976208566643\n",
      "\n",
      "| \u001b[39m38       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.758    \u001b[39m | \u001b[39m0.922    \u001b[39m | \u001b[39m0.1879   \u001b[39m | \u001b[39m1.973    \u001b[39m | \u001b[39m5.744    \u001b[39m | \u001b[39m27.18    \u001b[39m | \u001b[39m30.68    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.8976790907425035, 'lambda_l2': 1.9723760956107004, 'feature_fraction': 0.7026642351011078, 'bagging_fraction': 0.6037194367500099, 'min_child_samples': 5, 'min_child_weight': 35.242577763910646, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2451]\tvalid_0's binary_logloss: 0.488751\n",
      "roc-auc : 0.7422179016788647\n",
      "\n",
      "| \u001b[39m39       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.6037   \u001b[39m | \u001b[39m0.7027   \u001b[39m | \u001b[39m0.8977   \u001b[39m | \u001b[39m1.972    \u001b[39m | \u001b[39m5.484    \u001b[39m | \u001b[39m35.24    \u001b[39m | \u001b[39m30.19    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 36, 'lambda_l1': 0.8413117320216867, 'lambda_l2': 1.9702920332566598, 'feature_fraction': 0.7855157942366316, 'bagging_fraction': 0.7705705068344251, 'min_child_samples': 18, 'min_child_weight': 49.842539319077545, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2367]\tvalid_0's binary_logloss: 0.488775\n",
      "roc-auc : 0.7421898285010069\n",
      "\n",
      "| \u001b[39m40       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.7706   \u001b[39m | \u001b[39m0.7855   \u001b[39m | \u001b[39m0.8413   \u001b[39m | \u001b[39m1.97     \u001b[39m | \u001b[39m17.7     \u001b[39m | \u001b[39m49.84    \u001b[39m | \u001b[39m35.9     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 47, 'lambda_l1': 0.6808260132105334, 'lambda_l2': 1.9680467831562367, 'feature_fraction': 0.7949952243923863, 'bagging_fraction': 0.58970608969234, 'min_child_samples': 50, 'min_child_weight': 27.603371513765147, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1833]\tvalid_0's binary_logloss: 0.488739\n",
      "roc-auc : 0.7421696543902476\n",
      "\n",
      "| \u001b[39m41       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.5897   \u001b[39m | \u001b[39m0.795    \u001b[39m | \u001b[39m0.6808   \u001b[39m | \u001b[39m1.968    \u001b[39m | \u001b[39m49.95    \u001b[39m | \u001b[39m27.6     \u001b[39m | \u001b[39m46.58    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 36, 'lambda_l1': 0.34133048877784633, 'lambda_l2': 1.894396163312223, 'feature_fraction': 0.9367731495013296, 'bagging_fraction': 0.6555470848164642, 'min_child_samples': 38, 'min_child_weight': 49.88961074716576, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2008]\tvalid_0's binary_logloss: 0.488722\n",
      "roc-auc : 0.7423322683642994\n",
      "\n",
      "| \u001b[39m42       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.6555   \u001b[39m | \u001b[39m0.9368   \u001b[39m | \u001b[39m0.3413   \u001b[39m | \u001b[39m1.894    \u001b[39m | \u001b[39m37.8     \u001b[39m | \u001b[39m49.89    \u001b[39m | \u001b[39m35.61    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 46, 'lambda_l1': 0.6842098079737332, 'lambda_l2': 1.9865648312584514, 'feature_fraction': 0.9082926729286942, 'bagging_fraction': 0.6002188376020822, 'min_child_samples': 5, 'min_child_weight': 42.536401292225904, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1815]\tvalid_0's binary_logloss: 0.488775\n",
      "roc-auc : 0.7422207258766864\n",
      "\n",
      "| \u001b[39m43       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.6002   \u001b[39m | \u001b[39m0.9083   \u001b[39m | \u001b[39m0.6842   \u001b[39m | \u001b[39m1.987    \u001b[39m | \u001b[39m5.366    \u001b[39m | \u001b[39m42.54    \u001b[39m | \u001b[39m46.39    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.7210303959008197, 'lambda_l2': 0.7982049313237487, 'feature_fraction': 0.982849470934186, 'bagging_fraction': 0.7020616300997446, 'min_child_samples': 5, 'min_child_weight': 49.56131129110776, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2485]\tvalid_0's binary_logloss: 0.488675\n",
      "roc-auc : 0.7423320768597984\n",
      "\n",
      "| \u001b[39m44       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.7021   \u001b[39m | \u001b[39m0.9828   \u001b[39m | \u001b[39m0.721    \u001b[39m | \u001b[39m0.7982   \u001b[39m | \u001b[39m5.22     \u001b[39m | \u001b[39m49.56    \u001b[39m | \u001b[39m31.22    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 41, 'lambda_l1': 0.9504477210564288, 'lambda_l2': 0.023275575296295647, 'feature_fraction': 0.7255901723952088, 'bagging_fraction': 0.5536369371349928, 'min_child_samples': 6, 'min_child_weight': 49.518776981910776, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2175]\tvalid_0's binary_logloss: 0.488805\n",
      "roc-auc : 0.7422246260534057\n",
      "\n",
      "| \u001b[39m45       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.5536   \u001b[39m | \u001b[39m0.7256   \u001b[39m | \u001b[39m0.9504   \u001b[39m | \u001b[39m0.02328  \u001b[39m | \u001b[39m5.534    \u001b[39m | \u001b[39m49.52    \u001b[39m | \u001b[39m40.61    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 34, 'lambda_l1': 0.27163651614780526, 'lambda_l2': 1.829445474943049, 'feature_fraction': 0.8483993406512449, 'bagging_fraction': 0.6516739676226977, 'min_child_samples': 22, 'min_child_weight': 38.17316380792434, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2416]\tvalid_0's binary_logloss: 0.488701\n",
      "roc-auc : 0.7422784911364313\n",
      "\n",
      "| \u001b[39m46       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.6517   \u001b[39m | \u001b[39m0.8484   \u001b[39m | \u001b[39m0.2716   \u001b[39m | \u001b[39m1.829    \u001b[39m | \u001b[39m21.91    \u001b[39m | \u001b[39m38.17    \u001b[39m | \u001b[39m33.87    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 100, 'lambda_l1': 0.990466424750161, 'lambda_l2': 0.16829669635015088, 'feature_fraction': 0.9524226079424127, 'bagging_fraction': 0.7149661215609143, 'min_child_samples': 6, 'min_child_weight': 26.11922403877653, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1306]\tvalid_0's binary_logloss: 0.489058\n",
      "roc-auc : 0.7415631280471549\n",
      "\n",
      "| \u001b[39m47       \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.715    \u001b[39m | \u001b[39m0.9524   \u001b[39m | \u001b[39m0.9905   \u001b[39m | \u001b[39m0.1683   \u001b[39m | \u001b[39m5.551    \u001b[39m | \u001b[39m26.12    \u001b[39m | \u001b[39m99.77    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 91, 'lambda_l1': 0.23556989013167695, 'lambda_l2': 1.8242217524915645, 'feature_fraction': 0.9681697288529094, 'bagging_fraction': 0.6836774224205865, 'min_child_samples': 50, 'min_child_weight': 48.908721566240544, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1339]\tvalid_0's binary_logloss: 0.48898\n",
      "roc-auc : 0.7418178319949176\n",
      "\n",
      "| \u001b[39m48       \u001b[39m | \u001b[39m0.7418   \u001b[39m | \u001b[39m0.6837   \u001b[39m | \u001b[39m0.9682   \u001b[39m | \u001b[39m0.2356   \u001b[39m | \u001b[39m1.824    \u001b[39m | \u001b[39m49.96    \u001b[39m | \u001b[39m48.91    \u001b[39m | \u001b[39m91.28    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.8303505965234461, 'lambda_l2': 0.8570159289828161, 'feature_fraction': 0.9102513905860432, 'bagging_fraction': 0.7565409776504575, 'min_child_samples': 40, 'min_child_weight': 48.90155397871263, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\tvalid_0's binary_logloss: 0.488703\n",
      "roc-auc : 0.7422727440271276\n",
      "\n",
      "| \u001b[39m49       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.7565   \u001b[39m | \u001b[39m0.9103   \u001b[39m | \u001b[39m0.8304   \u001b[39m | \u001b[39m0.857    \u001b[39m | \u001b[39m39.78    \u001b[39m | \u001b[39m48.9     \u001b[39m | \u001b[39m30.01    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 42, 'lambda_l1': 0.15139803014995457, 'lambda_l2': 0.6913372123339458, 'feature_fraction': 0.9358889443338769, 'bagging_fraction': 0.567428630643829, 'min_child_samples': 49, 'min_child_weight': 49.418873335832416, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2050]\tvalid_0's binary_logloss: 0.488741\n",
      "roc-auc : 0.7422921392871069\n",
      "\n",
      "| \u001b[39m50       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.5674   \u001b[39m | \u001b[39m0.9359   \u001b[39m | \u001b[39m0.1514   \u001b[39m | \u001b[39m0.6913   \u001b[39m | \u001b[39m49.01    \u001b[39m | \u001b[39m49.42    \u001b[39m | \u001b[39m42.14    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 53, 'lambda_l1': 0.007347983792812096, 'lambda_l2': 0.5468908502933645, 'feature_fraction': 0.8849590340877258, 'bagging_fraction': 0.7213087070272148, 'min_child_samples': 50, 'min_child_weight': 49.76706572275451, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1594]\tvalid_0's binary_logloss: 0.488796\n",
      "roc-auc : 0.7421984679205578\n",
      "\n",
      "| \u001b[39m51       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.7213   \u001b[39m | \u001b[39m0.885    \u001b[39m | \u001b[39m0.007348 \u001b[39m | \u001b[39m0.5469   \u001b[39m | \u001b[39m49.58    \u001b[39m | \u001b[39m49.77    \u001b[39m | \u001b[39m53.2     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 100, 'lambda_l1': 0.7383166753920174, 'lambda_l2': 0.9186400331311104, 'feature_fraction': 0.7707612351538675, 'bagging_fraction': 0.7831676073560045, 'min_child_samples': 49, 'min_child_weight': 25.55120772366561, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1312]\tvalid_0's binary_logloss: 0.489013\n",
      "roc-auc : 0.7417124956351288\n",
      "\n",
      "| \u001b[39m52       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.7832   \u001b[39m | \u001b[39m0.7708   \u001b[39m | \u001b[39m0.7383   \u001b[39m | \u001b[39m0.9186   \u001b[39m | \u001b[39m49.45    \u001b[39m | \u001b[39m25.55    \u001b[39m | \u001b[39m99.68    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 65, 'lambda_l1': 0.1846968460313022, 'lambda_l2': 1.190993848796646, 'feature_fraction': 0.7192100511627545, 'bagging_fraction': 0.7185141154524602, 'min_child_samples': 26, 'min_child_weight': 25.015264242197926, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1831]\tvalid_0's binary_logloss: 0.488918\n",
      "roc-auc : 0.7418392281807915\n",
      "\n",
      "| \u001b[39m53       \u001b[39m | \u001b[39m0.7418   \u001b[39m | \u001b[39m0.7185   \u001b[39m | \u001b[39m0.7192   \u001b[39m | \u001b[39m0.1847   \u001b[39m | \u001b[39m1.191    \u001b[39m | \u001b[39m26.35    \u001b[39m | \u001b[39m25.02    \u001b[39m | \u001b[39m65.04    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 52, 'lambda_l1': 0.1704035813169703, 'lambda_l2': 1.10352160181243, 'feature_fraction': 0.7099129150361737, 'bagging_fraction': 0.6241141816106658, 'min_child_samples': 50, 'min_child_weight': 40.3207621135555, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1939]\tvalid_0's binary_logloss: 0.488855\n",
      "roc-auc : 0.7420079693117394\n",
      "\n",
      "| \u001b[39m54       \u001b[39m | \u001b[39m0.742    \u001b[39m | \u001b[39m0.6241   \u001b[39m | \u001b[39m0.7099   \u001b[39m | \u001b[39m0.1704   \u001b[39m | \u001b[39m1.104    \u001b[39m | \u001b[39m49.82    \u001b[39m | \u001b[39m40.32    \u001b[39m | \u001b[39m51.94    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.3465698371871525, 'lambda_l2': 1.839362361400739, 'feature_fraction': 0.9581372279421587, 'bagging_fraction': 0.5863913416418778, 'min_child_samples': 49, 'min_child_weight': 41.152903682697854, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2451]\tvalid_0's binary_logloss: 0.488678\n",
      "roc-auc : 0.7423502184562918\n",
      "\n",
      "| \u001b[35m55       \u001b[39m | \u001b[35m0.7424   \u001b[39m | \u001b[35m0.5864   \u001b[39m | \u001b[35m0.9581   \u001b[39m | \u001b[35m0.3466   \u001b[39m | \u001b[35m1.839    \u001b[39m | \u001b[35m49.23    \u001b[39m | \u001b[35m41.15    \u001b[39m | \u001b[35m30.95    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 35, 'lambda_l1': 0.6382214490972757, 'lambda_l2': 1.755497283736861, 'feature_fraction': 0.9358552169947765, 'bagging_fraction': 0.5491382538193293, 'min_child_samples': 45, 'min_child_weight': 44.17574797516555, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2185]\tvalid_0's binary_logloss: 0.48875\n",
      "roc-auc : 0.742251489001788\n",
      "\n",
      "| \u001b[39m56       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.5491   \u001b[39m | \u001b[39m0.9359   \u001b[39m | \u001b[39m0.6382   \u001b[39m | \u001b[39m1.755    \u001b[39m | \u001b[39m45.36    \u001b[39m | \u001b[39m44.18    \u001b[39m | \u001b[39m35.05    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 57, 'lambda_l1': 0.02319299923978846, 'lambda_l2': 0.27785583905542777, 'feature_fraction': 0.824558890396402, 'bagging_fraction': 0.7217390267855796, 'min_child_samples': 5, 'min_child_weight': 35.249444103875, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1593]\tvalid_0's binary_logloss: 0.48885\n",
      "roc-auc : 0.7420404540030768\n",
      "\n",
      "| \u001b[39m57       \u001b[39m | \u001b[39m0.742    \u001b[39m | \u001b[39m0.7217   \u001b[39m | \u001b[39m0.8246   \u001b[39m | \u001b[39m0.02319  \u001b[39m | \u001b[39m0.2779   \u001b[39m | \u001b[39m5.476    \u001b[39m | \u001b[39m35.25    \u001b[39m | \u001b[39m56.6     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.236457497819626, 'lambda_l2': 0.6631638946916221, 'feature_fraction': 0.747787109487759, 'bagging_fraction': 0.6953091856333263, 'min_child_samples': 44, 'min_child_weight': 38.78223292083542, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2498]\tvalid_0's binary_logloss: 0.488677\n",
      "roc-auc : 0.7423082148066898\n",
      "\n",
      "| \u001b[39m58       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.6953   \u001b[39m | \u001b[39m0.7478   \u001b[39m | \u001b[39m0.2365   \u001b[39m | \u001b[39m0.6632   \u001b[39m | \u001b[39m44.4     \u001b[39m | \u001b[39m38.78    \u001b[39m | \u001b[39m30.3     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 32, 'lambda_l1': 0.3146211326510635, 'lambda_l2': 1.8519494639422556, 'feature_fraction': 0.7063285568509464, 'bagging_fraction': 0.5514854004537441, 'min_child_samples': 14, 'min_child_weight': 25.24168399329628, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2285]\tvalid_0's binary_logloss: 0.488775\n",
      "roc-auc : 0.7421457143533472\n",
      "\n",
      "| \u001b[39m59       \u001b[39m | \u001b[39m0.7421   \u001b[39m | \u001b[39m0.5515   \u001b[39m | \u001b[39m0.7063   \u001b[39m | \u001b[39m0.3146   \u001b[39m | \u001b[39m1.852    \u001b[39m | \u001b[39m13.68    \u001b[39m | \u001b[39m25.24    \u001b[39m | \u001b[39m32.36    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.17139996007801073, 'lambda_l2': 0.022410519861283618, 'feature_fraction': 0.7622174162054587, 'bagging_fraction': 0.654726188102714, 'min_child_samples': 6, 'min_child_weight': 46.254633975774, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2429]\tvalid_0's binary_logloss: 0.488734\n",
      "roc-auc : 0.7422994983904836\n",
      "\n",
      "| \u001b[39m60       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.6547   \u001b[39m | \u001b[39m0.7622   \u001b[39m | \u001b[39m0.1714   \u001b[39m | \u001b[39m0.02241  \u001b[39m | \u001b[39m6.009    \u001b[39m | \u001b[39m46.25    \u001b[39m | \u001b[39m30.01    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.040172391777245076, 'lambda_l2': 0.015305353221612306, 'feature_fraction': 0.7043281148507796, 'bagging_fraction': 0.7207299631333366, 'min_child_samples': 49, 'min_child_weight': 40.65766720976239, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2494]\tvalid_0's binary_logloss: 0.488743\n",
      "roc-auc : 0.7422192007506345\n",
      "\n",
      "| \u001b[39m61       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.7207   \u001b[39m | \u001b[39m0.7043   \u001b[39m | \u001b[39m0.04017  \u001b[39m | \u001b[39m0.01531  \u001b[39m | \u001b[39m48.96    \u001b[39m | \u001b[39m40.66    \u001b[39m | \u001b[39m31.24    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.32439607265772874, 'lambda_l2': 1.7552112112029232, 'feature_fraction': 0.8645749113418263, 'bagging_fraction': 0.5883499723481477, 'min_child_samples': 41, 'min_child_weight': 35.28304101094871, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2471]\tvalid_0's binary_logloss: 0.488717\n",
      "roc-auc : 0.7422623830413406\n",
      "\n",
      "| \u001b[39m62       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.5883   \u001b[39m | \u001b[39m0.8646   \u001b[39m | \u001b[39m0.3244   \u001b[39m | \u001b[39m1.755    \u001b[39m | \u001b[39m40.74    \u001b[39m | \u001b[39m35.28    \u001b[39m | \u001b[39m31.15    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.909969674860535, 'lambda_l2': 0.7605266880916173, 'feature_fraction': 0.7673352986682498, 'bagging_fraction': 0.5453384502287996, 'min_child_samples': 9, 'min_child_weight': 49.9012833155256, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2470]\tvalid_0's binary_logloss: 0.488756\n",
      "roc-auc : 0.7423153142931399\n",
      "\n",
      "| \u001b[39m63       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.5453   \u001b[39m | \u001b[39m0.7673   \u001b[39m | \u001b[39m0.91     \u001b[39m | \u001b[39m0.7605   \u001b[39m | \u001b[39m9.467    \u001b[39m | \u001b[39m49.9     \u001b[39m | \u001b[39m30.21    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 38, 'lambda_l1': 0.19263587818551864, 'lambda_l2': 0.12439426675513543, 'feature_fraction': 0.8731687486921874, 'bagging_fraction': 0.697381413609205, 'min_child_samples': 5, 'min_child_weight': 26.02399003768401, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2399]\tvalid_0's binary_logloss: 0.488733\n",
      "roc-auc : 0.7421758822350771\n",
      "\n",
      "| \u001b[39m64       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.6974   \u001b[39m | \u001b[39m0.8732   \u001b[39m | \u001b[39m0.1926   \u001b[39m | \u001b[39m0.1244   \u001b[39m | \u001b[39m5.206    \u001b[39m | \u001b[39m26.02    \u001b[39m | \u001b[39m37.91    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 37, 'lambda_l1': 0.6249966842626042, 'lambda_l2': 1.8688830990076637, 'feature_fraction': 0.9441151522129813, 'bagging_fraction': 0.5108461447742426, 'min_child_samples': 49, 'min_child_weight': 49.77351994341383, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2169]\tvalid_0's binary_logloss: 0.4888\n",
      "roc-auc : 0.7421841129800743\n",
      "\n",
      "| \u001b[39m65       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.5108   \u001b[39m | \u001b[39m0.9441   \u001b[39m | \u001b[39m0.625    \u001b[39m | \u001b[39m1.869    \u001b[39m | \u001b[39m49.24    \u001b[39m | \u001b[39m49.77    \u001b[39m | \u001b[39m37.0     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 49, 'lambda_l1': 0.7103396930490311, 'lambda_l2': 1.6723643208692431, 'feature_fraction': 0.9060038228990875, 'bagging_fraction': 0.5985903868836966, 'min_child_samples': 5, 'min_child_weight': 49.75216373676362, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1836]\tvalid_0's binary_logloss: 0.48881\n",
      "roc-auc : 0.7421898620636512\n",
      "\n",
      "| \u001b[39m66       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.5986   \u001b[39m | \u001b[39m0.906    \u001b[39m | \u001b[39m0.7103   \u001b[39m | \u001b[39m1.672    \u001b[39m | \u001b[39m5.368    \u001b[39m | \u001b[39m49.75    \u001b[39m | \u001b[39m49.23    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.6680631689493993, 'lambda_l2': 1.7590251745769299, 'feature_fraction': 0.729524746347557, 'bagging_fraction': 0.6144987663003835, 'min_child_samples': 37, 'min_child_weight': 42.83298114623607, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2499]\tvalid_0's binary_logloss: 0.488764\n",
      "roc-auc : 0.7422087963308369\n",
      "\n",
      "| \u001b[39m67       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.6145   \u001b[39m | \u001b[39m0.7295   \u001b[39m | \u001b[39m0.6681   \u001b[39m | \u001b[39m1.759    \u001b[39m | \u001b[39m36.81    \u001b[39m | \u001b[39m42.83    \u001b[39m | \u001b[39m30.15    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 47, 'lambda_l1': 0.39707842518924863, 'lambda_l2': 1.6357421087541308, 'feature_fraction': 0.8936093876024424, 'bagging_fraction': 0.698723023826566, 'min_child_samples': 50, 'min_child_weight': 49.71966599920353, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2074]\tvalid_0's binary_logloss: 0.488724\n",
      "roc-auc : 0.7423060796302171\n",
      "\n",
      "| \u001b[39m68       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.6987   \u001b[39m | \u001b[39m0.8936   \u001b[39m | \u001b[39m0.3971   \u001b[39m | \u001b[39m1.636    \u001b[39m | \u001b[39m49.95    \u001b[39m | \u001b[39m49.72    \u001b[39m | \u001b[39m46.72    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 35, 'lambda_l1': 0.5127110640485082, 'lambda_l2': 0.6052544687775532, 'feature_fraction': 0.8898213921811774, 'bagging_fraction': 0.7045187712218935, 'min_child_samples': 34, 'min_child_weight': 49.989938255689125, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2354]\tvalid_0's binary_logloss: 0.488688\n",
      "roc-auc : 0.7423317688731782\n",
      "\n",
      "| \u001b[39m69       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.7045   \u001b[39m | \u001b[39m0.8898   \u001b[39m | \u001b[39m0.5127   \u001b[39m | \u001b[39m0.6053   \u001b[39m | \u001b[39m33.53    \u001b[39m | \u001b[39m49.99    \u001b[39m | \u001b[39m35.02    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 39, 'lambda_l1': 0.5680326577676342, 'lambda_l2': 1.6057427297117501, 'feature_fraction': 0.8118526712842804, 'bagging_fraction': 0.757082301648279, 'min_child_samples': 45, 'min_child_weight': 31.13806315330401, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2210]\tvalid_0's binary_logloss: 0.488756\n",
      "roc-auc : 0.7421868039144546\n",
      "\n",
      "| \u001b[39m70       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.7571   \u001b[39m | \u001b[39m0.8119   \u001b[39m | \u001b[39m0.568    \u001b[39m | \u001b[39m1.606    \u001b[39m | \u001b[39m44.73    \u001b[39m | \u001b[39m31.14    \u001b[39m | \u001b[39m39.1     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.3431685979019764, 'lambda_l2': 1.8537114285219505, 'feature_fraction': 0.8615444821924962, 'bagging_fraction': 0.7336798020894122, 'min_child_samples': 44, 'min_child_weight': 44.42271522159855, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2493]\tvalid_0's binary_logloss: 0.488719\n",
      "roc-auc : 0.7422726690047459\n",
      "\n",
      "| \u001b[39m71       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.7337   \u001b[39m | \u001b[39m0.8615   \u001b[39m | \u001b[39m0.3432   \u001b[39m | \u001b[39m1.854    \u001b[39m | \u001b[39m44.01    \u001b[39m | \u001b[39m44.42    \u001b[39m | \u001b[39m30.2     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 79, 'lambda_l1': 0.5386267314533443, 'lambda_l2': 1.992511727726199, 'feature_fraction': 0.8626714123928089, 'bagging_fraction': 0.6049044369844022, 'min_child_samples': 6, 'min_child_weight': 49.24861810024068, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1322]\tvalid_0's binary_logloss: 0.488961\n",
      "roc-auc : 0.7419529117676968\n",
      "\n",
      "| \u001b[39m72       \u001b[39m | \u001b[39m0.742    \u001b[39m | \u001b[39m0.6049   \u001b[39m | \u001b[39m0.8627   \u001b[39m | \u001b[39m0.5386   \u001b[39m | \u001b[39m1.993    \u001b[39m | \u001b[39m5.835    \u001b[39m | \u001b[39m49.25    \u001b[39m | \u001b[39m78.67    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 33, 'lambda_l1': 0.05270153156588997, 'lambda_l2': 1.9696027953868775, 'feature_fraction': 0.913594871015373, 'bagging_fraction': 0.6494387719429233, 'min_child_samples': 24, 'min_child_weight': 43.57438952078644, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2433]\tvalid_0's binary_logloss: 0.488676\n",
      "roc-auc : 0.7423177179707685\n",
      "\n",
      "| \u001b[39m73       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.6494   \u001b[39m | \u001b[39m0.9136   \u001b[39m | \u001b[39m0.0527   \u001b[39m | \u001b[39m1.97     \u001b[39m | \u001b[39m23.57    \u001b[39m | \u001b[39m43.57    \u001b[39m | \u001b[39m33.41    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.49250726675937495, 'lambda_l2': 1.426018148460123, 'feature_fraction': 0.883530769777119, 'bagging_fraction': 0.5876435199862244, 'min_child_samples': 24, 'min_child_weight': 37.85400482551284, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2456]\tvalid_0's binary_logloss: 0.488721\n",
      "roc-auc : 0.7422623554015157\n",
      "\n",
      "| \u001b[39m74       \u001b[39m | \u001b[39m0.7423   \u001b[39m | \u001b[39m0.5876   \u001b[39m | \u001b[39m0.8835   \u001b[39m | \u001b[39m0.4925   \u001b[39m | \u001b[39m1.426    \u001b[39m | \u001b[39m23.98    \u001b[39m | \u001b[39m37.85    \u001b[39m | \u001b[39m30.3     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 40, 'lambda_l1': 0.071785210417326, 'lambda_l2': 1.3393725165474641, 'feature_fraction': 0.9172812538830696, 'bagging_fraction': 0.6089488987418582, 'min_child_samples': 24, 'min_child_weight': 25.293604093270496, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 951\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 221\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1908]\tvalid_0's binary_logloss: 0.488759\n",
      "roc-auc : 0.7421810054740475\n",
      "\n",
      "| \u001b[39m75       \u001b[39m | \u001b[39m0.7422   \u001b[39m | \u001b[39m0.6089   \u001b[39m | \u001b[39m0.9173   \u001b[39m | \u001b[39m0.07179  \u001b[39m | \u001b[39m1.339    \u001b[39m | \u001b[39m24.1     \u001b[39m | \u001b[39m25.29    \u001b[39m | \u001b[39m39.67    \u001b[39m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 베이지안 최적화 수행\n",
    "# TODO: init_points 10~15, n_iter 30~70\n",
    "optimizer.maximize(init_points=15, n_iter=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "107aa4ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T18:16:38.914948Z",
     "iopub.status.busy": "2025-02-18T18:16:38.914590Z",
     "iopub.status.idle": "2025-02-18T18:16:38.920381Z",
     "shell.execute_reply": "2025-02-18T18:16:38.919689Z"
    },
    "papermill": {
     "duration": 0.022544,
     "end_time": "2025-02-18T18:16:38.921572",
     "exception": false,
     "start_time": "2025-02-18T18:16:38.899028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.5863913416418778,\n",
       " 'feature_fraction': 0.9581372279421587,\n",
       " 'lambda_l1': 0.3465698371871525,\n",
       " 'lambda_l2': 1.839362361400739,\n",
       " 'min_child_samples': 49.23130194543698,\n",
       " 'min_child_weight': 41.152903682697854,\n",
       " 'num_leaves': 30.952677923264346}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가함수 점수가 최대일 때 하이퍼파라미터\n",
    "max_params = optimizer.max['params']\n",
    "max_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4caccec1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T18:16:38.952943Z",
     "iopub.status.busy": "2025-02-18T18:16:38.952585Z",
     "iopub.status.idle": "2025-02-18T18:16:38.956434Z",
     "shell.execute_reply": "2025-02-18T18:16:38.955628Z"
    },
    "papermill": {
     "duration": 0.020879,
     "end_time": "2025-02-18T18:16:38.957772",
     "exception": false,
     "start_time": "2025-02-18T18:16:38.936893",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 정수형 하이퍼파라미터 변환\n",
    "max_params['num_leaves'] = int(round(max_params['num_leaves']))\n",
    "max_params['min_child_samples'] = int(round(max_params['min_child_samples']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c071f253",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T18:16:38.989388Z",
     "iopub.status.busy": "2025-02-18T18:16:38.989078Z",
     "iopub.status.idle": "2025-02-18T18:16:38.992615Z",
     "shell.execute_reply": "2025-02-18T18:16:38.991790Z"
    },
    "papermill": {
     "duration": 0.020914,
     "end_time": "2025-02-18T18:16:38.994015",
     "exception": false,
     "start_time": "2025-02-18T18:16:38.973101",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 값이 고정된 하이퍼파라미터 추가\n",
    "max_params.update(fixed_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2a7b9fd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T18:16:39.025674Z",
     "iopub.status.busy": "2025-02-18T18:16:39.025368Z",
     "iopub.status.idle": "2025-02-18T18:16:39.030143Z",
     "shell.execute_reply": "2025-02-18T18:16:39.029408Z"
    },
    "papermill": {
     "duration": 0.022051,
     "end_time": "2025-02-18T18:16:39.031360",
     "exception": false,
     "start_time": "2025-02-18T18:16:39.009309",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.5863913416418778,\n",
       " 'feature_fraction': 0.9581372279421587,\n",
       " 'lambda_l1': 0.3465698371871525,\n",
       " 'lambda_l2': 1.839362361400739,\n",
       " 'min_child_samples': 49,\n",
       " 'min_child_weight': 41.152903682697854,\n",
       " 'num_leaves': 31,\n",
       " 'objective': 'binary',\n",
       " 'learning_rate': 0.005,\n",
       " 'bagging_freq': 1,\n",
       " 'force_row_wise': True,\n",
       " 'random_state': 1991}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe958e8",
   "metadata": {
    "papermill": {
     "duration": 0.01527,
     "end_time": "2025-02-18T18:16:39.062286",
     "exception": false,
     "start_time": "2025-02-18T18:16:39.047016",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f1fddfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T18:16:39.094373Z",
     "iopub.status.busy": "2025-02-18T18:16:39.094082Z",
     "iopub.status.idle": "2025-02-18T18:16:39.097589Z",
     "shell.execute_reply": "2025-02-18T18:16:39.096917Z"
    },
    "papermill": {
     "duration": 0.020989,
     "end_time": "2025-02-18T18:16:39.098961",
     "exception": false,
     "start_time": "2025-02-18T18:16:39.077972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 층화 K 폴드 교차 검증기\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=1991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6ac5507",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T18:16:39.131937Z",
     "iopub.status.busy": "2025-02-18T18:16:39.131602Z",
     "iopub.status.idle": "2025-02-18T18:16:39.135437Z",
     "shell.execute_reply": "2025-02-18T18:16:39.134785Z"
    },
    "papermill": {
     "duration": 0.021394,
     "end_time": "2025-02-18T18:16:39.136624",
     "exception": false,
     "start_time": "2025-02-18T18:16:39.115230",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OOF 방식으로 훈련된 모델로 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
    "oof_val_preds = np.zeros(X.shape[0]) \n",
    "# OOF 방식으로 훈련된 모델로 테스트 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
    "oof_test_preds = np.zeros(X_test.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4aab880a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T18:16:39.168765Z",
     "iopub.status.busy": "2025-02-18T18:16:39.168462Z",
     "iopub.status.idle": "2025-02-18T18:28:17.436650Z",
     "shell.execute_reply": "2025-02-18T18:28:17.435209Z"
    },
    "papermill": {
     "duration": 698.2867,
     "end_time": "2025-02-18T18:28:17.438962",
     "exception": false,
     "start_time": "2025-02-18T18:16:39.152262",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## 폴드 1 / 폴드 10 ########################################\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171110\n",
      "[LightGBM] [Info] Total Bins 883\n",
      "[LightGBM] [Info] Number of data points in the train set: 230715, number of used features: 187\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258349 -> initscore=-1.054567\n",
      "[LightGBM] [Info] Start training from score -1.054567\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2389]\tvalid_0's binary_logloss: 0.487666\tvalid_0's roc_auc: 0.740225\n",
      "폴드 1 roc-auc : 0.7402252385799367\n",
      "\n",
      "######################################## 폴드 2 / 폴드 10 ########################################\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[LightGBM] [Info] Number of positive: 59606, number of negative: 171110\n",
      "[LightGBM] [Info] Total Bins 884\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 187\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258352 -> initscore=-1.054550\n",
      "[LightGBM] [Info] Start training from score -1.054550\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2358]\tvalid_0's binary_logloss: 0.487016\tvalid_0's roc_auc: 0.739779\n",
      "폴드 2 roc-auc : 0.739778961581914\n",
      "\n",
      "######################################## 폴드 3 / 폴드 10 ########################################\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[LightGBM] [Info] Number of positive: 59606, number of negative: 171110\n",
      "[LightGBM] [Info] Total Bins 888\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 186\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258352 -> initscore=-1.054550\n",
      "[LightGBM] [Info] Start training from score -1.054550\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2484]\tvalid_0's binary_logloss: 0.489732\tvalid_0's roc_auc: 0.734934\n",
      "폴드 3 roc-auc : 0.734933630350964\n",
      "\n",
      "######################################## 폴드 4 / 폴드 10 ########################################\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 880\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 186\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1943]\tvalid_0's binary_logloss: 0.488257\tvalid_0's roc_auc: 0.739376\n",
      "폴드 4 roc-auc : 0.739376187751633\n",
      "\n",
      "######################################## 폴드 5 / 폴드 10 ########################################\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 887\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 186\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1958]\tvalid_0's binary_logloss: 0.486852\tvalid_0's roc_auc: 0.742261\n",
      "폴드 5 roc-auc : 0.7422605442039213\n",
      "\n",
      "######################################## 폴드 6 / 폴드 10 ########################################\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 886\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 186\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2310]\tvalid_0's binary_logloss: 0.489021\tvalid_0's roc_auc: 0.736742\n",
      "폴드 6 roc-auc : 0.7367415166542622\n",
      "\n",
      "######################################## 폴드 7 / 폴드 10 ########################################\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 886\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 186\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1624]\tvalid_0's binary_logloss: 0.486388\tvalid_0's roc_auc: 0.744286\n",
      "폴드 7 roc-auc : 0.744286045616461\n",
      "\n",
      "######################################## 폴드 8 / 폴드 10 ########################################\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 886\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 186\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1513]\tvalid_0's binary_logloss: 0.488071\tvalid_0's roc_auc: 0.740538\n",
      "폴드 8 roc-auc : 0.7405378069824636\n",
      "\n",
      "######################################## 폴드 9 / 폴드 10 ########################################\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 882\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 186\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1772]\tvalid_0's binary_logloss: 0.484757\tvalid_0's roc_auc: 0.745692\n",
      "폴드 9 roc-auc : 0.745692462041266\n",
      "\n",
      "######################################## 폴드 10 / 폴드 10 ########################################\n",
      "<class 'scipy.sparse._csr.csr_matrix'>\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 889\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 186\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1978]\tvalid_0's binary_logloss: 0.487648\tvalid_0's roc_auc: 0.741565\n",
      "폴드 10 roc-auc : 0.7415650831905428\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OOF 방식으로 모델 훈련, 검증, 예측\n",
    "for idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
    "    # 각 폴드를 구분하는 문구 출력\n",
    "    print('#'*40, f'폴드 {idx+1} / 폴드 {folds.n_splits}', '#'*40)\n",
    "    print(type(X))  # DataFrame인지 확인\n",
    "    \n",
    "    # 훈련용 데이터, 검증용 데이터 설정\n",
    "    # X_train, y_train = X[train_idx], y[train_idx] # 훈련용 데이터\n",
    "    # X_valid, y_valid = X[valid_idx], y[valid_idx] # 검증용 데이터\n",
    "\n",
    "    # 데이터가 DataFrame인지 확인 후 인덱싱 방식 결정\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    else:  # numpy.ndarray일 경우\n",
    "        X_train, X_valid = X[train_idx], X[valid_idx]\n",
    "\n",
    "    y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "    # LightGBM 전용 데이터셋 생성\n",
    "    dtrain = lgb.Dataset(X_train, y_train) # LightGBM 전용 훈련 데이터셋\n",
    "    dvalid = lgb.Dataset(X_valid, y_valid) # LightGBM 전용 검증 데이터셋\n",
    "                          \n",
    "    # LightGBM 모델 훈련\n",
    "    lgb_model = lgb.train(params=max_params,    # 최적 하이퍼파라미터\n",
    "                          train_set=dtrain,     # 훈련 데이터셋\n",
    "                          num_boost_round=2500, # 부스팅 반복 횟수\n",
    "                          valid_sets=dvalid,    # 성능 평가용 검증 데이터셋\n",
    "                          feval = lgb_roc_auc,\n",
    "                          callbacks=[early_stopping(stopping_rounds=200)])\n",
    "    \n",
    "    # 테스트 데이터를 활용해 OOF 예측\n",
    "    oof_test_preds += lgb_model.predict(X_test)/folds.n_splits\n",
    "    # 모델 성능 평가를 위한 검증 데이터 타깃값 예측 \n",
    "    oof_val_preds[valid_idx] += lgb_model.predict(X_valid)\n",
    "    \n",
    "    # 검증 데이터 예측 확률에 대한 ROC-AUC\n",
    "    roc_auc = roc_auc_score(y_valid, oof_val_preds[valid_idx])\n",
    "    print(f'폴드 {idx+1} roc-auc : {roc_auc}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fa0620",
   "metadata": {
    "papermill": {
     "duration": 0.017031,
     "end_time": "2025-02-18T18:28:17.480715",
     "exception": false,
     "start_time": "2025-02-18T18:28:17.463684",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 7. 최종 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9805d6c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T18:28:17.515290Z",
     "iopub.status.busy": "2025-02-18T18:28:17.514964Z",
     "iopub.status.idle": "2025-02-18T18:28:17.628691Z",
     "shell.execute_reply": "2025-02-18T18:28:17.627823Z"
    },
    "papermill": {
     "duration": 0.133173,
     "end_time": "2025-02-18T18:28:17.630607",
     "exception": false,
     "start_time": "2025-02-18T18:28:17.497434",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF 검증 데이터 roc-auc : 0.7404986919647051\n"
     ]
    }
   ],
   "source": [
    "print('OOF 검증 데이터 roc-auc :', roc_auc_score(y, oof_val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "36af8300",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-18T18:28:17.673920Z",
     "iopub.status.busy": "2025-02-18T18:28:17.673536Z",
     "iopub.status.idle": "2025-02-18T18:28:17.840623Z",
     "shell.execute_reply": "2025-02-18T18:28:17.839659Z"
    },
    "papermill": {
     "duration": 0.186822,
     "end_time": "2025-02-18T18:28:17.842552",
     "exception": false,
     "start_time": "2025-02-18T18:28:17.655730",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission['probability'] = oof_test_preds\n",
    "submission.to_csv('baseline_onehot_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6583998,
     "sourceId": 10634121,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3995.843138,
   "end_time": "2025-02-18T18:28:19.193935",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-18T17:21:43.350797",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
