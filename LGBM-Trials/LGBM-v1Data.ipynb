{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e735436",
   "metadata": {
    "papermill": {
     "duration": 0.004588,
     "end_time": "2025-02-19T23:44:04.701330",
     "exception": false,
     "start_time": "2025-02-19T23:44:04.696742",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# 데이터셋 비교 (LGBM) - v1 버전"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "736c4496",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-19T23:44:04.710304Z",
     "iopub.status.busy": "2025-02-19T23:44:04.709974Z",
     "iopub.status.idle": "2025-02-19T23:44:05.397369Z",
     "shell.execute_reply": "2025-02-19T23:44:05.396387Z"
    },
    "papermill": {
     "duration": 0.693467,
     "end_time": "2025-02-19T23:44:05.398785",
     "exception": false,
     "start_time": "2025-02-19T23:44:04.705318",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/lg-aimers-v1/sample_submission.csv\n",
      "/kaggle/input/lg-aimers-v1/train.csv\n",
      "/kaggle/input/lg-aimers-v1/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af1012cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T23:44:05.407724Z",
     "iopub.status.busy": "2025-02-19T23:44:05.407399Z",
     "iopub.status.idle": "2025-02-19T23:44:08.029843Z",
     "shell.execute_reply": "2025-02-19T23:44:08.028626Z"
    },
    "papermill": {
     "duration": 2.628931,
     "end_time": "2025-02-19T23:44:08.031848",
     "exception": false,
     "start_time": "2025-02-19T23:44:05.402917",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission = pd.read_csv('/kaggle/input/lg-aimers-v1/sample_submission.csv', index_col= 'ID')\n",
    "train_v1 = pd.read_csv('/kaggle/input/lg-aimers-v1/train.csv', index_col=None)\n",
    "test_v1 = pd.read_csv('/kaggle/input/lg-aimers-v1/test.csv', index_col = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f1d9989",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T23:44:08.044671Z",
     "iopub.status.busy": "2025-02-19T23:44:08.044244Z",
     "iopub.status.idle": "2025-02-19T23:44:08.049232Z",
     "shell.execute_reply": "2025-02-19T23:44:08.048190Z"
    },
    "papermill": {
     "duration": 0.013599,
     "end_time": "2025-02-19T23:44:08.051020",
     "exception": false,
     "start_time": "2025-02-19T23:44:08.037421",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_v1 = pd.concat([train_v1, eval_v1, validation_v1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5b83bd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T23:44:08.062125Z",
     "iopub.status.busy": "2025-02-19T23:44:08.061891Z",
     "iopub.status.idle": "2025-02-19T23:44:08.085697Z",
     "shell.execute_reply": "2025-02-19T23:44:08.084899Z"
    },
    "papermill": {
     "duration": 0.030435,
     "end_time": "2025-02-19T23:44:08.086954",
     "exception": false,
     "start_time": "2025-02-19T23:44:08.056519",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>임신 성공 여부</th>\n",
       "      <th>임신 시도 또는 마지막 임신 경과 연수</th>\n",
       "      <th>총 시술 횟수</th>\n",
       "      <th>클리닉 내 총 시술 횟수</th>\n",
       "      <th>IVF 시술 횟수</th>\n",
       "      <th>DI 시술 횟수</th>\n",
       "      <th>총 임신 횟수</th>\n",
       "      <th>IVF 임신 횟수</th>\n",
       "      <th>DI 임신 횟수</th>\n",
       "      <th>총 출산 횟수</th>\n",
       "      <th>...</th>\n",
       "      <th>난자 기증자 나이_만26-30세</th>\n",
       "      <th>난자 기증자 나이_만31-35세</th>\n",
       "      <th>난자 기증자 나이_알 수 없음</th>\n",
       "      <th>정자 기증자 나이_만20세 이하</th>\n",
       "      <th>정자 기증자 나이_만21-25세</th>\n",
       "      <th>정자 기증자 나이_만26-30세</th>\n",
       "      <th>정자 기증자 나이_만31-35세</th>\n",
       "      <th>정자 기증자 나이_만36-40세</th>\n",
       "      <th>정자 기증자 나이_만41-45세</th>\n",
       "      <th>정자 기증자 나이_알 수 없음</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 120 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   임신 성공 여부  임신 시도 또는 마지막 임신 경과 연수  총 시술 횟수  클리닉 내 총 시술 횟수  IVF 시술 횟수  \\\n",
       "0         0                      0        3              3          3   \n",
       "1         0                      0        2              2          2   \n",
       "2         0                      0        0              0          0   \n",
       "3         1                      0        2              1          2   \n",
       "4         0                      0        3              3          3   \n",
       "\n",
       "   DI 시술 횟수  총 임신 횟수  IVF 임신 횟수  DI 임신 횟수  총 출산 횟수  ...  난자 기증자 나이_만26-30세  \\\n",
       "0         0        0          0         0        0  ...                  0   \n",
       "1         0        1          1         0        1  ...                  0   \n",
       "2         0        0          0         0        0  ...                  0   \n",
       "3         0        1          1         0        1  ...                  0   \n",
       "4         0        2          2         0        2  ...                  0   \n",
       "\n",
       "   난자 기증자 나이_만31-35세  난자 기증자 나이_알 수 없음  정자 기증자 나이_만20세 이하  정자 기증자 나이_만21-25세  \\\n",
       "0                  0                 1                  0                  0   \n",
       "1                  0                 1                  0                  0   \n",
       "2                  0                 1                  0                  0   \n",
       "3                  0                 1                  0                  0   \n",
       "4                  0                 1                  0                  0   \n",
       "\n",
       "   정자 기증자 나이_만26-30세  정자 기증자 나이_만31-35세  정자 기증자 나이_만36-40세  정자 기증자 나이_만41-45세  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  0                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   정자 기증자 나이_알 수 없음  \n",
       "0                 1  \n",
       "1                 1  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "\n",
       "[5 rows x 120 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_v1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67cfcd16",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T23:44:08.096464Z",
     "iopub.status.busy": "2025-02-19T23:44:08.096244Z",
     "iopub.status.idle": "2025-02-19T23:44:08.107778Z",
     "shell.execute_reply": "2025-02-19T23:44:08.106954Z"
    },
    "papermill": {
     "duration": 0.017667,
     "end_time": "2025-02-19T23:44:08.108950",
     "exception": false,
     "start_time": "2025-02-19T23:44:08.091283",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>임신 시도 또는 마지막 임신 경과 연수</th>\n",
       "      <th>총 시술 횟수</th>\n",
       "      <th>클리닉 내 총 시술 횟수</th>\n",
       "      <th>IVF 시술 횟수</th>\n",
       "      <th>DI 시술 횟수</th>\n",
       "      <th>총 임신 횟수</th>\n",
       "      <th>IVF 임신 횟수</th>\n",
       "      <th>DI 임신 횟수</th>\n",
       "      <th>총 출산 횟수</th>\n",
       "      <th>IVF 출산 횟수</th>\n",
       "      <th>...</th>\n",
       "      <th>난자 기증자 나이_만26-30세</th>\n",
       "      <th>난자 기증자 나이_만31-35세</th>\n",
       "      <th>난자 기증자 나이_알 수 없음</th>\n",
       "      <th>정자 기증자 나이_만20세 이하</th>\n",
       "      <th>정자 기증자 나이_만21-25세</th>\n",
       "      <th>정자 기증자 나이_만26-30세</th>\n",
       "      <th>정자 기증자 나이_만31-35세</th>\n",
       "      <th>정자 기증자 나이_만36-40세</th>\n",
       "      <th>정자 기증자 나이_만41-45세</th>\n",
       "      <th>정자 기증자 나이_알 수 없음</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 119 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   임신 시도 또는 마지막 임신 경과 연수  총 시술 횟수  클리닉 내 총 시술 횟수  IVF 시술 횟수  DI 시술 횟수  \\\n",
       "0                      0        1              1          1         0   \n",
       "1                      0        0              0          0         0   \n",
       "2                      0        0              0          0         0   \n",
       "3                      0        0              0          0         0   \n",
       "4                      0        1              1          1         0   \n",
       "\n",
       "   총 임신 횟수  IVF 임신 횟수  DI 임신 횟수  총 출산 횟수  IVF 출산 횟수  ...  난자 기증자 나이_만26-30세  \\\n",
       "0        0          0         0        0          0  ...                  0   \n",
       "1        0          0         0        0          0  ...                  0   \n",
       "2        0          0         0        0          0  ...                  0   \n",
       "3        0          0         0        0          0  ...                  0   \n",
       "4        0          0         0        0          0  ...                  0   \n",
       "\n",
       "   난자 기증자 나이_만31-35세  난자 기증자 나이_알 수 없음  정자 기증자 나이_만20세 이하  정자 기증자 나이_만21-25세  \\\n",
       "0                  0                 1                  0                  0   \n",
       "1                  0                 1                  0                  0   \n",
       "2                  0                 1                  0                  0   \n",
       "3                  0                 1                  0                  0   \n",
       "4                  0                 1                  0                  0   \n",
       "\n",
       "   정자 기증자 나이_만26-30세  정자 기증자 나이_만31-35세  정자 기증자 나이_만36-40세  정자 기증자 나이_만41-45세  \\\n",
       "0                  0                  0                  0                  0   \n",
       "1                  0                  0                  1                  0   \n",
       "2                  0                  0                  0                  0   \n",
       "3                  0                  0                  0                  0   \n",
       "4                  0                  0                  0                  0   \n",
       "\n",
       "   정자 기증자 나이_알 수 없음  \n",
       "0                 1  \n",
       "1                 0  \n",
       "2                 1  \n",
       "3                 1  \n",
       "4                 1  \n",
       "\n",
       "[5 rows x 119 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_v1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dff3dc93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T23:44:08.118576Z",
     "iopub.status.busy": "2025-02-19T23:44:08.118367Z",
     "iopub.status.idle": "2025-02-19T23:44:08.121319Z",
     "shell.execute_reply": "2025-02-19T23:44:08.120480Z"
    },
    "papermill": {
     "duration": 0.009161,
     "end_time": "2025-02-19T23:44:08.122580",
     "exception": false,
     "start_time": "2025-02-19T23:44:08.113419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# all_data = pd.concat([test_v1, train_v1], ignore_index = True)\n",
    "# all_data = all_data.drop('임신 성공 여부', axis= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16716815",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T23:44:08.132287Z",
     "iopub.status.busy": "2025-02-19T23:44:08.132050Z",
     "iopub.status.idle": "2025-02-19T23:44:08.221043Z",
     "shell.execute_reply": "2025-02-19T23:44:08.219798Z"
    },
    "papermill": {
     "duration": 0.096347,
     "end_time": "2025-02-19T23:44:08.223456",
     "exception": false,
     "start_time": "2025-02-19T23:44:08.127109",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = train_v1.drop('임신 성공 여부', axis= 1)\n",
    "X_test = test_v1\n",
    "\n",
    "y = train_v1['임신 성공 여부'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8313ecfe",
   "metadata": {
    "papermill": {
     "duration": 0.006648,
     "end_time": "2025-02-19T23:44:08.237889",
     "exception": false,
     "start_time": "2025-02-19T23:44:08.231241",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. 평가 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6c357949",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T23:44:08.254866Z",
     "iopub.status.busy": "2025-02-19T23:44:08.254587Z",
     "iopub.status.idle": "2025-02-19T23:44:08.258311Z",
     "shell.execute_reply": "2025-02-19T23:44:08.257475Z"
    },
    "papermill": {
     "duration": 0.013117,
     "end_time": "2025-02-19T23:44:08.259676",
     "exception": false,
     "start_time": "2025-02-19T23:44:08.246559",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lgb_roc_auc(y_pred, dataset):\n",
    "    y_true = dataset.get_label()\n",
    "    return \"roc_auc\", roc_auc_score(y_true, y_pred), True  # (지표 이름, 값, 높은 값이 더 좋은지 여부)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1492fb8c",
   "metadata": {
    "papermill": {
     "duration": 0.004298,
     "end_time": "2025-02-19T23:44:08.268654",
     "exception": false,
     "start_time": "2025-02-19T23:44:08.264356",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. 파라미터 최적화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "542a7778",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T23:44:08.278628Z",
     "iopub.status.busy": "2025-02-19T23:44:08.278401Z",
     "iopub.status.idle": "2025-02-19T23:44:13.684274Z",
     "shell.execute_reply": "2025-02-19T23:44:13.683501Z"
    },
    "papermill": {
     "duration": 5.412539,
     "end_time": "2025-02-19T23:44:13.685943",
     "exception": false,
     "start_time": "2025-02-19T23:44:08.273404",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import lightgbm as lgb\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 8:2 비율로 훈련 데이터, 검증 데이터 분리\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "                                                      test_size=0.2, \n",
    "                                                      random_state=0)\n",
    "\n",
    "def clean_feature_names(feature_names):\n",
    "    \"\"\"\n",
    "    LightGBM이 허용하지 않는 특수 문자를 제거하고, 중복된 feature name을 방지하는 함수\n",
    "    \"\"\"\n",
    "    cleaned_names = [re.sub(r'[^가-힣a-zA-Z0-9_]', '_', col) for col in feature_names]  # 특수 문자 제거\n",
    "    name_counts = Counter(cleaned_names)  # feature name 개수 확인\n",
    "    \n",
    "    unique_names = {}\n",
    "    final_names = []\n",
    "    \n",
    "    for name in cleaned_names:\n",
    "        if name_counts[name] > 1:  # 중복된 feature 이름이 있다면\n",
    "            if name not in unique_names:\n",
    "                unique_names[name] = 1\n",
    "            else:\n",
    "                unique_names[name] += 1\n",
    "            new_name = f\"{name}_{unique_names[name]}\"  # 숫자 추가해서 구분\n",
    "        else:\n",
    "            new_name = name\n",
    "        final_names.append(new_name)\n",
    "    \n",
    "    return final_names\n",
    "    \n",
    "# feature 이름을 정리\n",
    "cleaned_feature_names = clean_feature_names(list(X_train.columns))  \n",
    "\n",
    "# LightGBM Dataset 생성 (feature_pre_filter=False 추가)\n",
    "bayes_dtrain = lgb.Dataset(X_train, y_train, feature_name=cleaned_feature_names, params={'feature_pre_filter': False})\n",
    "bayes_dvalid = lgb.Dataset(X_valid, y_valid, feature_name=cleaned_feature_names, params={'feature_pre_filter': False})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5accb7f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T23:44:13.696603Z",
     "iopub.status.busy": "2025-02-19T23:44:13.696123Z",
     "iopub.status.idle": "2025-02-19T23:44:13.700821Z",
     "shell.execute_reply": "2025-02-19T23:44:13.699975Z"
    },
    "papermill": {
     "duration": 0.011085,
     "end_time": "2025-02-19T23:44:13.702060",
     "exception": false,
     "start_time": "2025-02-19T23:44:13.690975",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 베이지안 최적화를 위한 하이퍼파라미터 범위\n",
    "# TODO: 점점 줄여나가자!!!!\n",
    "param_bounds = {\n",
    "    'num_leaves': (30, 100),  \n",
    "    'lambda_l1': (0, 1),  \n",
    "    'lambda_l2': (0, 2),  \n",
    "    'feature_fraction': (0.7, 1),  \n",
    "    'bagging_fraction': (0.5, 0.8),  \n",
    "    'min_child_samples': (5, 50),  \n",
    "    'min_child_weight': (25, 50)  \n",
    "}\n",
    "\n",
    "# 값이 고정된 하이퍼파라미터\n",
    "fixed_params = {'objective': 'binary', # binary classification\n",
    "                'learning_rate': 0.005, # 0.01~0.001\n",
    "                'bagging_freq': 1, # 0 or 1\n",
    "                'force_row_wise': True,\n",
    "                'random_state': 1991}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "96461aa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T23:44:13.711783Z",
     "iopub.status.busy": "2025-02-19T23:44:13.711561Z",
     "iopub.status.idle": "2025-02-19T23:44:13.716757Z",
     "shell.execute_reply": "2025-02-19T23:44:13.716130Z"
    },
    "papermill": {
     "duration": 0.011412,
     "end_time": "2025-02-19T23:44:13.717957",
     "exception": false,
     "start_time": "2025-02-19T23:44:13.706545",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import early_stopping\n",
    "\n",
    "def eval_function(num_leaves, lambda_l1, lambda_l2, feature_fraction,\n",
    "                  bagging_fraction, min_child_samples, min_child_weight):\n",
    "    '''최적화하려는 평가지표 계산 함수'''\n",
    "    \n",
    "    # 베이지안 최적화를 수행할 하이퍼파라미터 \n",
    "    params = {'num_leaves': int(round(num_leaves)),\n",
    "              'lambda_l1': lambda_l1,\n",
    "              'lambda_l2': lambda_l2,\n",
    "              'feature_fraction': feature_fraction,\n",
    "              'bagging_fraction': bagging_fraction,\n",
    "              'min_child_samples': int(round(min_child_samples)),\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'feature_pre_filter': False}\n",
    "    # 고정된 하이퍼파라미터도 추가\n",
    "    params.update(fixed_params)\n",
    "    \n",
    "    print('하이퍼파라미터:', params)    \n",
    "    \n",
    "    # LightGBM 모델 훈련\n",
    "    lgb_model = lgb.train(params=params, \n",
    "                           train_set=bayes_dtrain,\n",
    "                           num_boost_round=2500,\n",
    "                           valid_sets=bayes_dvalid,\n",
    "                           callbacks=[early_stopping(stopping_rounds=200)])\n",
    "    # 검증 데이터로 예측 수행\n",
    "    preds = lgb_model.predict(X_valid) \n",
    "    # roc-auc 계산\n",
    "    roc_auc = roc_auc_score(y_valid, preds)\n",
    "    print(f'roc-auc : {roc_auc}\\n')\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a77b3d6b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T23:44:13.727960Z",
     "iopub.status.busy": "2025-02-19T23:44:13.727759Z",
     "iopub.status.idle": "2025-02-19T23:44:13.780538Z",
     "shell.execute_reply": "2025-02-19T23:44:13.779894Z"
    },
    "papermill": {
     "duration": 0.059313,
     "end_time": "2025-02-19T23:44:13.781980",
     "exception": false,
     "start_time": "2025-02-19T23:44:13.722667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# 베이지안 최적화 객체 생성\n",
    "optimizer = BayesianOptimization(f=eval_function,      # 평가지표 계산 함수\n",
    "                                 pbounds=param_bounds, # 하이퍼파라미터 범위\n",
    "                                 random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "511f9d08",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T23:44:13.792291Z",
     "iopub.status.busy": "2025-02-19T23:44:13.792035Z",
     "iopub.status.idle": "2025-02-19T23:44:13.797380Z",
     "shell.execute_reply": "2025-02-19T23:44:13.796643Z"
    },
    "papermill": {
     "duration": 0.011682,
     "end_time": "2025-02-19T23:44:13.798559",
     "exception": false,
     "start_time": "2025-02-19T23:44:13.786877",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['임신_시도_또는_마지막_임신_경과_연수',\n",
       " '총_시술_횟수',\n",
       " '클리닉_내_총_시술_횟수',\n",
       " 'IVF_시술_횟수',\n",
       " 'DI_시술_횟수',\n",
       " '총_임신_횟수',\n",
       " 'IVF_임신_횟수',\n",
       " 'DI_임신_횟수',\n",
       " '총_출산_횟수',\n",
       " 'IVF_출산_횟수',\n",
       " 'DI_출산_횟수',\n",
       " '총_생성_배아_수',\n",
       " '미세주입된_난자_수',\n",
       " '미세주입에서_생성된_배아_수',\n",
       " '이식된_배아_수',\n",
       " '미세주입_배아_이식_수',\n",
       " '저장된_배아_수',\n",
       " '미세주입_후_저장된_배아_수',\n",
       " '해동된_배아_수',\n",
       " '해동_난자_수',\n",
       " '수집된_신선_난자_수',\n",
       " '저장된_신선_난자_수',\n",
       " '혼합된_난자_수',\n",
       " '파트너_정자와_혼합된_난자_수',\n",
       " '기증자_정자와_혼합된_난자_수',\n",
       " '난자_혼합_경과일',\n",
       " '배아_이식_경과일',\n",
       " '배아_해동_경과일',\n",
       " '특정_시술_유형_IVF',\n",
       " '특정_시술_유형_ICSI',\n",
       " '특정_시술_유형_IUI',\n",
       " '특정_시술_유형_ICI',\n",
       " '특정_시술_유형_GIFT',\n",
       " '특정_시술_유형_FER',\n",
       " '특정_시술_유형_Generic_DI',\n",
       " '특정_시술_유형_IVI',\n",
       " '특정_시술_유형_BLASTOCYST',\n",
       " '특정_시술_유형_AH',\n",
       " '특정_시술_유형_Unknown',\n",
       " '복합_시술_횟수',\n",
       " '세부_조합_횟수',\n",
       " '배란_자극_여부',\n",
       " '단일_배아_이식_여부',\n",
       " '착상_전_유전_검사_사용_여부',\n",
       " '착상_전_유전_진단_사용_여부',\n",
       " '남성_주_불임_원인',\n",
       " '남성_부_불임_원인',\n",
       " '여성_주_불임_원인',\n",
       " '여성_부_불임_원인',\n",
       " '부부_주_불임_원인',\n",
       " '부부_부_불임_원인',\n",
       " '불명확_불임_원인',\n",
       " '불임_원인___난관_질환',\n",
       " '불임_원인___남성_요인',\n",
       " '불임_원인___배란_장애',\n",
       " '불임_원인___자궁경부_문제',\n",
       " '불임_원인___자궁내막증',\n",
       " '불임_원인___정자_농도',\n",
       " '불임_원인___정자_면역학적_요인',\n",
       " '불임_원인___정자_운동성',\n",
       " '불임_원인___정자_형태',\n",
       " '동결_배아_사용_여부',\n",
       " '신선_배아_사용_여부',\n",
       " '기증_배아_사용_여부',\n",
       " '대리모_여부',\n",
       " 'PGD_시술_여부',\n",
       " 'PGS_시술_여부',\n",
       " 'DI_시술_여부',\n",
       " '임신_시도_또는_마지막_임신_경과_연수_1',\n",
       " '난자_혼합_경과일_1',\n",
       " '배아_이식_경과일_1',\n",
       " '배아_해동_경과일_1',\n",
       " '시술_시기_코드_TRCMWS',\n",
       " '시술_시기_코드_TRDQAZ',\n",
       " '시술_시기_코드_TRJXFG',\n",
       " '시술_시기_코드_TRVNRY',\n",
       " '시술_시기_코드_TRXQMD',\n",
       " '시술_시기_코드_TRYBLT',\n",
       " '시술_시기_코드_TRZKPL',\n",
       " '시술_당시_나이_만18_34세',\n",
       " '시술_당시_나이_만35_37세',\n",
       " '시술_당시_나이_만38_39세',\n",
       " '시술_당시_나이_만40_42세',\n",
       " '시술_당시_나이_만43_44세',\n",
       " '시술_당시_나이_만45_50세',\n",
       " '시술_당시_나이_알_수_없음',\n",
       " '배아_생성_주요_이유_Unknown',\n",
       " '배아_생성_주요_이유_기증용',\n",
       " '배아_생성_주요_이유_기증용__난자_저장용',\n",
       " '배아_생성_주요_이유_기증용__배아_저장용',\n",
       " '배아_생성_주요_이유_기증용__배아_저장용__현재_시술용',\n",
       " '배아_생성_주요_이유_기증용__현재_시술용',\n",
       " '배아_생성_주요_이유_난자_저장용',\n",
       " '배아_생성_주요_이유_난자_저장용__배아_저장용',\n",
       " '배아_생성_주요_이유_난자_저장용__배아_저장용__연구용',\n",
       " '배아_생성_주요_이유_난자_저장용__현재_시술용',\n",
       " '배아_생성_주요_이유_배아_저장용',\n",
       " '배아_생성_주요_이유_배아_저장용__현재_시술용',\n",
       " '배아_생성_주요_이유_연구용__현재_시술용',\n",
       " '배아_생성_주요_이유_현재_시술용',\n",
       " '난자_출처_기증_제공',\n",
       " '난자_출처_본인_제공',\n",
       " '난자_출처_알_수_없음',\n",
       " '정자_출처_기증_제공',\n",
       " '정자_출처_미할당',\n",
       " '정자_출처_배우자_및_기증_제공',\n",
       " '정자_출처_배우자_제공',\n",
       " '난자_기증자_나이_만20세_이하',\n",
       " '난자_기증자_나이_만21_25세',\n",
       " '난자_기증자_나이_만26_30세',\n",
       " '난자_기증자_나이_만31_35세',\n",
       " '난자_기증자_나이_알_수_없음',\n",
       " '정자_기증자_나이_만20세_이하',\n",
       " '정자_기증자_나이_만21_25세',\n",
       " '정자_기증자_나이_만26_30세',\n",
       " '정자_기증자_나이_만31_35세',\n",
       " '정자_기증자_나이_만36_40세',\n",
       " '정자_기증자_나이_만41_45세',\n",
       " '정자_기증자_나이_알_수_없음']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93173194",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-19T23:44:13.809066Z",
     "iopub.status.busy": "2025-02-19T23:44:13.808853Z",
     "iopub.status.idle": "2025-02-20T00:26:33.427974Z",
     "shell.execute_reply": "2025-02-20T00:26:33.426979Z"
    },
    "papermill": {
     "duration": 2539.625759,
     "end_time": "2025-02-20T00:26:33.429388",
     "exception": false,
     "start_time": "2025-02-19T23:44:13.803629",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | lambda_l1 | lambda_l2 | min_ch... | min_ch... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "하이퍼파라미터: {'num_leaves': 61, 'lambda_l1': 0.6027633760716439, 'lambda_l2': 1.0897663659937937, 'feature_fraction': 0.9145568099117258, 'bagging_fraction': 0.6646440511781975, 'min_child_samples': 24, 'min_child_weight': 41.147352826666406, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1398]\tvalid_0's binary_logloss: 0.485899\n",
      "roc-auc : 0.7392308708106443\n",
      "\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.7392   \u001b[39m | \u001b[39m0.6646   \u001b[39m | \u001b[39m0.9146   \u001b[39m | \u001b[39m0.6028   \u001b[39m | \u001b[39m1.09     \u001b[39m | \u001b[39m24.06    \u001b[39m | \u001b[39m41.15    \u001b[39m | \u001b[39m60.63    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 95, 'lambda_l1': 0.3834415188257777, 'lambda_l2': 1.5834500761653292, 'feature_fraction': 0.9890988281503088, 'bagging_fraction': 0.7675319002346239, 'min_child_samples': 29, 'min_child_weight': 39.20111402734831, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1237]\tvalid_0's binary_logloss: 0.48608\n",
      "roc-auc : 0.7388483020755344\n",
      "\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m0.7388   \u001b[39m | \u001b[39m0.7675   \u001b[39m | \u001b[39m0.9891   \u001b[39m | \u001b[39m0.3834   \u001b[39m | \u001b[39m1.583    \u001b[39m | \u001b[39m28.8     \u001b[39m | \u001b[39m39.2     \u001b[39m | \u001b[39m94.79    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 99, 'lambda_l1': 0.02021839744032572, 'lambda_l2': 1.665239691095876, 'feature_fraction': 0.7261387899104622, 'bagging_fraction': 0.5213108174593661, 'min_child_samples': 40, 'min_child_weight': 46.75030370617048, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1214]\tvalid_0's binary_logloss: 0.486583\n",
      "roc-auc : 0.7382584514725974\n",
      "\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.7383   \u001b[39m | \u001b[39m0.5213   \u001b[39m | \u001b[39m0.7261   \u001b[39m | \u001b[39m0.02022  \u001b[39m | \u001b[39m1.665    \u001b[39m | \u001b[39m40.02    \u001b[39m | \u001b[39m46.75    \u001b[39m | \u001b[39m98.5     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 96, 'lambda_l1': 0.7805291762864555, 'lambda_l2': 0.23654885173786644, 'feature_fraction': 0.8384438086758795, 'bagging_fraction': 0.7397475692650171, 'min_child_samples': 34, 'min_child_weight': 28.58383218522616, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1287]\tvalid_0's binary_logloss: 0.486145\n",
      "roc-auc : 0.7387526069199017\n",
      "\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.7388   \u001b[39m | \u001b[39m0.7397   \u001b[39m | \u001b[39m0.8384   \u001b[39m | \u001b[39m0.7805   \u001b[39m | \u001b[39m0.2365   \u001b[39m | \u001b[39m33.8     \u001b[39m | \u001b[39m28.58    \u001b[39m | \u001b[39m96.13    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.26455561210462697, 'lambda_l2': 1.5484673788684333, 'feature_fraction': 0.8243985819971571, 'bagging_fraction': 0.6565544965250215, 'min_child_samples': 26, 'min_child_weight': 39.21084872171621, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2141]\tvalid_0's binary_logloss: 0.485761\n",
      "roc-auc : 0.7394521112620527\n",
      "\n",
      "| \u001b[35m5        \u001b[39m | \u001b[35m0.7395   \u001b[39m | \u001b[35m0.6566   \u001b[39m | \u001b[35m0.8244   \u001b[39m | \u001b[35m0.2646   \u001b[39m | \u001b[35m1.548    \u001b[39m | \u001b[35m25.53    \u001b[39m | \u001b[35m39.21    \u001b[39m | \u001b[35m31.32    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 61, 'lambda_l1': 0.6169339968747569, 'lambda_l2': 1.8874961570292483, 'feature_fraction': 0.8836287168167264, 'bagging_fraction': 0.6852906491227632, 'min_child_samples': 36, 'min_child_weight': 33.987697514344646, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1375]\tvalid_0's binary_logloss: 0.485898\n",
      "roc-auc : 0.739243839919949\n",
      "\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.7392   \u001b[39m | \u001b[39m0.6853   \u001b[39m | \u001b[39m0.8836   \u001b[39m | \u001b[39m0.6169   \u001b[39m | \u001b[39m1.887    \u001b[39m | \u001b[39m35.68    \u001b[39m | \u001b[39m33.99    \u001b[39m | \u001b[39m60.59    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 52, 'lambda_l1': 0.6667667154456677, 'lambda_l2': 1.3412757392363188, 'feature_fraction': 0.7180676414887809, 'bagging_fraction': 0.7092893587781794, 'min_child_samples': 14, 'min_child_weight': 28.223157441371335, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1689]\tvalid_0's binary_logloss: 0.485896\n",
      "roc-auc : 0.7392293796029468\n",
      "\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.7392   \u001b[39m | \u001b[39m0.7093   \u001b[39m | \u001b[39m0.7181   \u001b[39m | \u001b[39m0.6668   \u001b[39m | \u001b[39m1.341    \u001b[39m | \u001b[39m14.47    \u001b[39m | \u001b[39m28.22    \u001b[39m | \u001b[39m52.08    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 41, 'lambda_l1': 0.43860151346232035, 'lambda_l2': 1.9767476761184524, 'feature_fraction': 0.8710590311253639, 'bagging_fraction': 0.6091132312827868, 'min_child_samples': 10, 'min_child_weight': 30.221918902370867, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1761]\tvalid_0's binary_logloss: 0.485798\n",
      "roc-auc : 0.7394269146494161\n",
      "\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.7394   \u001b[39m | \u001b[39m0.6091   \u001b[39m | \u001b[39m0.8711   \u001b[39m | \u001b[39m0.4386   \u001b[39m | \u001b[39m1.977    \u001b[39m | \u001b[39m9.592    \u001b[39m | \u001b[39m30.22    \u001b[39m | \u001b[39m41.29    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 76, 'lambda_l1': 0.4663107728563063, 'lambda_l2': 0.4888511840032055, 'feature_fraction': 0.7759874807619346, 'bagging_fraction': 0.6959324976396195, 'min_child_samples': 12, 'min_child_weight': 27.75937852910763, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1306]\tvalid_0's binary_logloss: 0.486084\n",
      "roc-auc : 0.7389175592780746\n",
      "\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.7389   \u001b[39m | \u001b[39m0.6959   \u001b[39m | \u001b[39m0.776    \u001b[39m | \u001b[39m0.4663   \u001b[39m | \u001b[39m0.4889   \u001b[39m | \u001b[39m12.15    \u001b[39m | \u001b[39m27.76    \u001b[39m | \u001b[39m75.94    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 37, 'lambda_l1': 0.3687251706609641, 'lambda_l2': 1.6419864596958702, 'feature_fraction': 0.758974708504016, 'bagging_fraction': 0.5414548854045842, 'min_child_samples': 9, 'min_child_weight': 45.9486226874701, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1665]\tvalid_0's binary_logloss: 0.486058\n",
      "roc-auc : 0.7391334425758244\n",
      "\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.7391   \u001b[39m | \u001b[39m0.5415   \u001b[39m | \u001b[39m0.759    \u001b[39m | \u001b[39m0.3687   \u001b[39m | \u001b[39m1.642    \u001b[39m | \u001b[39m9.37     \u001b[39m | \u001b[39m45.95    \u001b[39m | \u001b[39m36.73    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 50, 'lambda_l1': 0.9767610881903371, 'lambda_l2': 1.209691039490092, 'feature_fraction': 0.8405953604943104, 'bagging_fraction': 0.7929378395040187, 'min_child_samples': 38, 'min_child_weight': 25.979694806358015, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1643]\tvalid_0's binary_logloss: 0.485819\n",
      "roc-auc : 0.7392940392482428\n",
      "\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.7393   \u001b[39m | \u001b[39m0.7929   \u001b[39m | \u001b[39m0.8406   \u001b[39m | \u001b[39m0.9768   \u001b[39m | \u001b[39m1.21     \u001b[39m | \u001b[39m38.27    \u001b[39m | \u001b[39m25.98    \u001b[39m | \u001b[39m49.8     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 78, 'lambda_l1': 0.11872771895424405, 'lambda_l2': 0.635966358787952, 'feature_fraction': 0.7888420592566434, 'bagging_fraction': 0.5360589683639507, 'min_child_samples': 24, 'min_child_weight': 26.60368740871961, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1277]\tvalid_0's binary_logloss: 0.486076\n",
      "roc-auc : 0.7389864166930283\n",
      "\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.739    \u001b[39m | \u001b[39m0.5361   \u001b[39m | \u001b[39m0.7888   \u001b[39m | \u001b[39m0.1187   \u001b[39m | \u001b[39m0.636    \u001b[39m | \u001b[39m23.64    \u001b[39m | \u001b[39m26.6     \u001b[39m | \u001b[39m78.47    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 52, 'lambda_l1': 0.5232480534666997, 'lambda_l2': 0.18788102151688335, 'feature_fraction': 0.7796168472818336, 'bagging_fraction': 0.6699804362619726, 'min_child_samples': 31, 'min_child_weight': 48.232404939405356, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1510]\tvalid_0's binary_logloss: 0.485993\n",
      "roc-auc : 0.7391304261784846\n",
      "\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.7391   \u001b[39m | \u001b[39m0.67     \u001b[39m | \u001b[39m0.7796   \u001b[39m | \u001b[39m0.5232   \u001b[39m | \u001b[39m0.1879   \u001b[39m | \u001b[39m30.92    \u001b[39m | \u001b[39m48.23    \u001b[39m | \u001b[39m52.3     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.7163272041185655, 'lambda_l2': 0.5788121858944022, 'feature_fraction': 0.7395393587213176, 'bagging_fraction': 0.7002231139891045, 'min_child_samples': 13, 'min_child_weight': 39.66282337025208, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2119]\tvalid_0's binary_logloss: 0.485798\n",
      "roc-auc : 0.739362288986065\n",
      "\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.7394   \u001b[39m | \u001b[39m0.7002   \u001b[39m | \u001b[39m0.7395   \u001b[39m | \u001b[39m0.7163   \u001b[39m | \u001b[39m0.5788   \u001b[39m | \u001b[39m13.24    \u001b[39m | \u001b[39m39.66    \u001b[39m | \u001b[39m31.41    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 47, 'lambda_l1': 0.6778165367962301, 'lambda_l2': 0.5400159463843297, 'feature_fraction': 0.701408642857764, 'bagging_fraction': 0.748682008765209, 'min_child_samples': 38, 'min_child_weight': 49.05471362793595, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1652]\tvalid_0's binary_logloss: 0.486044\n",
      "roc-auc : 0.7389959576237792\n",
      "\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m0.739    \u001b[39m | \u001b[39m0.7487   \u001b[39m | \u001b[39m0.7014   \u001b[39m | \u001b[39m0.6778   \u001b[39m | \u001b[39m0.54     \u001b[39m | \u001b[39m38.08    \u001b[39m | \u001b[39m49.05    \u001b[39m | \u001b[39m47.41    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.21722738429951605, 'lambda_l2': 1.376178284163054, 'feature_fraction': 0.7256923277302051, 'bagging_fraction': 0.5607571210487496, 'min_child_samples': 26, 'min_child_weight': 25.114724814766294, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2300]\tvalid_0's binary_logloss: 0.485829\n",
      "roc-auc : 0.7393189899915137\n",
      "\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m0.7393   \u001b[39m | \u001b[39m0.5608   \u001b[39m | \u001b[39m0.7257   \u001b[39m | \u001b[39m0.2172   \u001b[39m | \u001b[39m1.376    \u001b[39m | \u001b[39m26.0     \u001b[39m | \u001b[39m25.11    \u001b[39m | \u001b[39m30.8     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.7571336688782256, 'lambda_l2': 0.7447221021823707, 'feature_fraction': 0.7098396115326306, 'bagging_fraction': 0.7846894441039947, 'min_child_samples': 6, 'min_child_weight': 25.23322887640176, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2485]\tvalid_0's binary_logloss: 0.485734\n",
      "roc-auc : 0.7393657351550603\n",
      "\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m0.7394   \u001b[39m | \u001b[39m0.7847   \u001b[39m | \u001b[39m0.7098   \u001b[39m | \u001b[39m0.7571   \u001b[39m | \u001b[39m0.7447   \u001b[39m | \u001b[39m5.991    \u001b[39m | \u001b[39m25.23    \u001b[39m | \u001b[39m30.94    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.011448646090072012, 'lambda_l2': 0.5115733934835727, 'feature_fraction': 0.8811883712429, 'bagging_fraction': 0.5045304468764921, 'min_child_samples': 50, 'min_child_weight': 26.778956402852167, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2001]\tvalid_0's binary_logloss: 0.485728\n",
      "roc-auc : 0.7395609434377763\n",
      "\n",
      "| \u001b[35m18       \u001b[39m | \u001b[35m0.7396   \u001b[39m | \u001b[35m0.5045   \u001b[39m | \u001b[35m0.8812   \u001b[39m | \u001b[35m0.01145  \u001b[39m | \u001b[35m0.5116   \u001b[39m | \u001b[35m49.68    \u001b[39m | \u001b[35m26.78    \u001b[39m | \u001b[35m30.73    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.15413711310351597, 'lambda_l2': 0.5902937796519678, 'feature_fraction': 0.9312564547290068, 'bagging_fraction': 0.7452049254627654, 'min_child_samples': 49, 'min_child_weight': 26.821949325390005, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1866]\tvalid_0's binary_logloss: 0.485688\n",
      "roc-auc : 0.7395896811689601\n",
      "\n",
      "| \u001b[35m19       \u001b[39m | \u001b[35m0.7396   \u001b[39m | \u001b[35m0.7452   \u001b[39m | \u001b[35m0.9313   \u001b[39m | \u001b[35m0.1541   \u001b[39m | \u001b[35m0.5903   \u001b[39m | \u001b[35m48.53    \u001b[39m | \u001b[35m26.82    \u001b[39m | \u001b[35m31.18    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.7800008521151433, 'lambda_l2': 1.8754505404426882, 'feature_fraction': 0.8442804227195165, 'bagging_fraction': 0.5329001227896915, 'min_child_samples': 45, 'min_child_weight': 36.002649824954794, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1905]\tvalid_0's binary_logloss: 0.485828\n",
      "roc-auc : 0.739439408011493\n",
      "\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m0.7394   \u001b[39m | \u001b[39m0.5329   \u001b[39m | \u001b[39m0.8443   \u001b[39m | \u001b[39m0.78     \u001b[39m | \u001b[39m1.875    \u001b[39m | \u001b[39m44.96    \u001b[39m | \u001b[39m36.0     \u001b[39m | \u001b[39m30.26    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 94, 'lambda_l1': 0.12344227607134628, 'lambda_l2': 1.087055317784374, 'feature_fraction': 0.9636041309586523, 'bagging_fraction': 0.6917141266172799, 'min_child_samples': 6, 'min_child_weight': 49.33679712196881, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1143]\tvalid_0's binary_logloss: 0.486196\n",
      "roc-auc : 0.7387263608648507\n",
      "\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m0.7387   \u001b[39m | \u001b[39m0.6917   \u001b[39m | \u001b[39m0.9636   \u001b[39m | \u001b[39m0.1234   \u001b[39m | \u001b[39m1.087    \u001b[39m | \u001b[39m6.093    \u001b[39m | \u001b[39m49.34    \u001b[39m | \u001b[39m94.35    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 40, 'lambda_l1': 0.03509448831471462, 'lambda_l2': 1.6941654296686852, 'feature_fraction': 0.7856887356272404, 'bagging_fraction': 0.7549325594416859, 'min_child_samples': 49, 'min_child_weight': 25.424398589999917, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2007]\tvalid_0's binary_logloss: 0.485826\n",
      "roc-auc : 0.739268141008392\n",
      "\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m0.7393   \u001b[39m | \u001b[39m0.7549   \u001b[39m | \u001b[39m0.7857   \u001b[39m | \u001b[39m0.03509  \u001b[39m | \u001b[39m1.694    \u001b[39m | \u001b[39m49.29    \u001b[39m | \u001b[39m25.42    \u001b[39m | \u001b[39m40.26    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.8159385911395326, 'lambda_l2': 0.5764923708029106, 'feature_fraction': 0.7499130109720031, 'bagging_fraction': 0.754702042396219, 'min_child_samples': 39, 'min_child_weight': 26.52240290958315, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2279]\tvalid_0's binary_logloss: 0.485771\n",
      "roc-auc : 0.739345048146399\n",
      "\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m0.7393   \u001b[39m | \u001b[39m0.7547   \u001b[39m | \u001b[39m0.7499   \u001b[39m | \u001b[39m0.8159   \u001b[39m | \u001b[39m0.5765   \u001b[39m | \u001b[39m39.32    \u001b[39m | \u001b[39m26.52    \u001b[39m | \u001b[39m30.89    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 42, 'lambda_l1': 0.04536747343576686, 'lambda_l2': 0.501383555334272, 'feature_fraction': 0.9706369670861186, 'bagging_fraction': 0.5154964711930657, 'min_child_samples': 23, 'min_child_weight': 34.11434787101216, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1634]\tvalid_0's binary_logloss: 0.485826\n",
      "roc-auc : 0.7394363136555737\n",
      "\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m0.7394   \u001b[39m | \u001b[39m0.5155   \u001b[39m | \u001b[39m0.9706   \u001b[39m | \u001b[39m0.04537  \u001b[39m | \u001b[39m0.5014   \u001b[39m | \u001b[39m23.15    \u001b[39m | \u001b[39m34.11    \u001b[39m | \u001b[39m42.32    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 71, 'lambda_l1': 0.5899776996785181, 'lambda_l2': 0.22325231029348935, 'feature_fraction': 0.9674939557449346, 'bagging_fraction': 0.7868847204230853, 'min_child_samples': 49, 'min_child_weight': 25.927470797647448, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1404]\tvalid_0's binary_logloss: 0.485959\n",
      "roc-auc : 0.7390486656191777\n",
      "\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m0.739    \u001b[39m | \u001b[39m0.7869   \u001b[39m | \u001b[39m0.9675   \u001b[39m | \u001b[39m0.59     \u001b[39m | \u001b[39m0.2233   \u001b[39m | \u001b[39m49.33    \u001b[39m | \u001b[39m25.93    \u001b[39m | \u001b[39m70.62    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 60, 'lambda_l1': 0.8635862454372898, 'lambda_l2': 1.6436524027476567, 'feature_fraction': 0.7834696272829715, 'bagging_fraction': 0.7657494847105608, 'min_child_samples': 6, 'min_child_weight': 49.22639710785235, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1456]\tvalid_0's binary_logloss: 0.48604\n",
      "roc-auc : 0.7389970450460143\n",
      "\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m0.739    \u001b[39m | \u001b[39m0.7657   \u001b[39m | \u001b[39m0.7835   \u001b[39m | \u001b[39m0.8636   \u001b[39m | \u001b[39m1.644    \u001b[39m | \u001b[39m5.65     \u001b[39m | \u001b[39m49.23    \u001b[39m | \u001b[39m60.27    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 38, 'lambda_l1': 0.1436670280316079, 'lambda_l2': 1.0305403466021212, 'feature_fraction': 0.9411267827242303, 'bagging_fraction': 0.6794418222285341, 'min_child_samples': 17, 'min_child_weight': 26.088904890205093, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1789]\tvalid_0's binary_logloss: 0.485706\n",
      "roc-auc : 0.7395446281063731\n",
      "\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m0.7395   \u001b[39m | \u001b[39m0.6794   \u001b[39m | \u001b[39m0.9411   \u001b[39m | \u001b[39m0.1437   \u001b[39m | \u001b[39m1.031    \u001b[39m | \u001b[39m17.07    \u001b[39m | \u001b[39m26.09    \u001b[39m | \u001b[39m38.27    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.4161413105541085, 'lambda_l2': 1.1267019877638518, 'feature_fraction': 0.918775067173644, 'bagging_fraction': 0.6351006440024269, 'min_child_samples': 30, 'min_child_weight': 49.53429637381792, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1982]\tvalid_0's binary_logloss: 0.485764\n",
      "roc-auc : 0.7395231934949249\n",
      "\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m0.7395   \u001b[39m | \u001b[39m0.6351   \u001b[39m | \u001b[39m0.9188   \u001b[39m | \u001b[39m0.4161   \u001b[39m | \u001b[39m1.127    \u001b[39m | \u001b[39m29.93    \u001b[39m | \u001b[39m49.53    \u001b[39m | \u001b[39m30.21    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.8476725906662935, 'lambda_l2': 0.8491710508751693, 'feature_fraction': 0.9742807429514212, 'bagging_fraction': 0.5871141121821395, 'min_child_samples': 49, 'min_child_weight': 49.52956452543523, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1906]\tvalid_0's binary_logloss: 0.485789\n",
      "roc-auc : 0.7395424712523442\n",
      "\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m0.7395   \u001b[39m | \u001b[39m0.5871   \u001b[39m | \u001b[39m0.9743   \u001b[39m | \u001b[39m0.8477   \u001b[39m | \u001b[39m0.8492   \u001b[39m | \u001b[39m49.49    \u001b[39m | \u001b[39m49.53    \u001b[39m | \u001b[39m30.09    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.28455968345633076, 'lambda_l2': 0.9490710321716498, 'feature_fraction': 0.9907624946680764, 'bagging_fraction': 0.5796964252459716, 'min_child_samples': 39, 'min_child_weight': 49.65278132748314, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1660]\tvalid_0's binary_logloss: 0.485756\n",
      "roc-auc : 0.7396805978634655\n",
      "\n",
      "| \u001b[35m30       \u001b[39m | \u001b[35m0.7397   \u001b[39m | \u001b[35m0.5797   \u001b[39m | \u001b[35m0.9908   \u001b[39m | \u001b[35m0.2846   \u001b[39m | \u001b[35m0.9491   \u001b[39m | \u001b[35m38.66    \u001b[39m | \u001b[35m49.65    \u001b[39m | \u001b[35m30.99    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.7896142958252157, 'lambda_l2': 0.35427501988874965, 'feature_fraction': 0.7308500364070337, 'bagging_fraction': 0.519694311024439, 'min_child_samples': 38, 'min_child_weight': 44.38684899244847, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2200]\tvalid_0's binary_logloss: 0.486074\n",
      "roc-auc : 0.7389797022605138\n",
      "\n",
      "| \u001b[39m31       \u001b[39m | \u001b[39m0.739    \u001b[39m | \u001b[39m0.5197   \u001b[39m | \u001b[39m0.7309   \u001b[39m | \u001b[39m0.7896   \u001b[39m | \u001b[39m0.3543   \u001b[39m | \u001b[39m37.52    \u001b[39m | \u001b[39m44.39    \u001b[39m | \u001b[39m30.77    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 35, 'lambda_l1': 0.3461485313892567, 'lambda_l2': 1.844204947356659, 'feature_fraction': 0.8416627958840254, 'bagging_fraction': 0.6262159965873146, 'min_child_samples': 44, 'min_child_weight': 49.80084904718479, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1868]\tvalid_0's binary_logloss: 0.485878\n",
      "roc-auc : 0.7393367285667249\n",
      "\n",
      "| \u001b[39m32       \u001b[39m | \u001b[39m0.7393   \u001b[39m | \u001b[39m0.6262   \u001b[39m | \u001b[39m0.8417   \u001b[39m | \u001b[39m0.3461   \u001b[39m | \u001b[39m1.844    \u001b[39m | \u001b[39m44.22    \u001b[39m | \u001b[39m49.8     \u001b[39m | \u001b[39m34.69    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 33, 'lambda_l1': 0.09523954604018248, 'lambda_l2': 1.5335314661335873, 'feature_fraction': 0.7226719546254465, 'bagging_fraction': 0.7850117123455906, 'min_child_samples': 19, 'min_child_weight': 32.296324210541115, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2075]\tvalid_0's binary_logloss: 0.485795\n",
      "roc-auc : 0.7393315393238526\n",
      "\n",
      "| \u001b[39m33       \u001b[39m | \u001b[39m0.7393   \u001b[39m | \u001b[39m0.785    \u001b[39m | \u001b[39m0.7227   \u001b[39m | \u001b[39m0.09524  \u001b[39m | \u001b[39m1.534    \u001b[39m | \u001b[39m18.87    \u001b[39m | \u001b[39m32.3     \u001b[39m | \u001b[39m32.96    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 32, 'lambda_l1': 0.926628878200459, 'lambda_l2': 1.1126197479936413, 'feature_fraction': 0.750117375715685, 'bagging_fraction': 0.6043269863131862, 'min_child_samples': 22, 'min_child_weight': 49.91939004290347, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2146]\tvalid_0's binary_logloss: 0.485999\n",
      "roc-auc : 0.7391147804912885\n",
      "\n",
      "| \u001b[39m34       \u001b[39m | \u001b[39m0.7391   \u001b[39m | \u001b[39m0.6043   \u001b[39m | \u001b[39m0.7501   \u001b[39m | \u001b[39m0.9266   \u001b[39m | \u001b[39m1.113    \u001b[39m | \u001b[39m21.71    \u001b[39m | \u001b[39m49.92    \u001b[39m | \u001b[39m31.65    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 35, 'lambda_l1': 0.3144308090372061, 'lambda_l2': 1.5396273525534625, 'feature_fraction': 0.8707683667854909, 'bagging_fraction': 0.6414452356645978, 'min_child_samples': 50, 'min_child_weight': 33.642174788634776, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1905]\tvalid_0's binary_logloss: 0.485688\n",
      "roc-auc : 0.7395874153728138\n",
      "\n",
      "| \u001b[39m35       \u001b[39m | \u001b[39m0.7396   \u001b[39m | \u001b[39m0.6414   \u001b[39m | \u001b[39m0.8708   \u001b[39m | \u001b[39m0.3144   \u001b[39m | \u001b[39m1.54     \u001b[39m | \u001b[39m49.96    \u001b[39m | \u001b[39m33.64    \u001b[39m | \u001b[39m34.62    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 46, 'lambda_l1': 0.5464430916798355, 'lambda_l2': 1.5965457829971175, 'feature_fraction': 0.9975701369177807, 'bagging_fraction': 0.718592449297555, 'min_child_samples': 25, 'min_child_weight': 25.13960544252445, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1552]\tvalid_0's binary_logloss: 0.48573\n",
      "roc-auc : 0.7395535073886683\n",
      "\n",
      "| \u001b[39m36       \u001b[39m | \u001b[39m0.7396   \u001b[39m | \u001b[39m0.7186   \u001b[39m | \u001b[39m0.9976   \u001b[39m | \u001b[39m0.5464   \u001b[39m | \u001b[39m1.597    \u001b[39m | \u001b[39m24.65    \u001b[39m | \u001b[39m25.14    \u001b[39m | \u001b[39m46.48    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 41, 'lambda_l1': 0.4421126628839993, 'lambda_l2': 0.40506362580093125, 'feature_fraction': 0.9092984141058932, 'bagging_fraction': 0.7686283433025529, 'min_child_samples': 29, 'min_child_weight': 26.34766227422051, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1614]\tvalid_0's binary_logloss: 0.485767\n",
      "roc-auc : 0.7394628645486596\n",
      "\n",
      "| \u001b[39m37       \u001b[39m | \u001b[39m0.7395   \u001b[39m | \u001b[39m0.7686   \u001b[39m | \u001b[39m0.9093   \u001b[39m | \u001b[39m0.4421   \u001b[39m | \u001b[39m0.4051   \u001b[39m | \u001b[39m29.36    \u001b[39m | \u001b[39m26.35    \u001b[39m | \u001b[39m40.83    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 72, 'lambda_l1': 0.18421958268693905, 'lambda_l2': 1.703093939989758, 'feature_fraction': 0.9901654360428502, 'bagging_fraction': 0.607647708518937, 'min_child_samples': 50, 'min_child_weight': 49.91546585794761, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1236]\tvalid_0's binary_logloss: 0.486009\n",
      "roc-auc : 0.7391463157361083\n",
      "\n",
      "| \u001b[39m38       \u001b[39m | \u001b[39m0.7391   \u001b[39m | \u001b[39m0.6076   \u001b[39m | \u001b[39m0.9902   \u001b[39m | \u001b[39m0.1842   \u001b[39m | \u001b[39m1.703    \u001b[39m | \u001b[39m49.68    \u001b[39m | \u001b[39m49.92    \u001b[39m | \u001b[39m71.68    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 56, 'lambda_l1': 0.2147413466604996, 'lambda_l2': 0.6646868066554299, 'feature_fraction': 0.9588433635064318, 'bagging_fraction': 0.5771445352299044, 'min_child_samples': 27, 'min_child_weight': 25.58250373739864, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1377]\tvalid_0's binary_logloss: 0.485865\n",
      "roc-auc : 0.739326094216925\n",
      "\n",
      "| \u001b[39m39       \u001b[39m | \u001b[39m0.7393   \u001b[39m | \u001b[39m0.5771   \u001b[39m | \u001b[39m0.9588   \u001b[39m | \u001b[39m0.2147   \u001b[39m | \u001b[39m0.6647   \u001b[39m | \u001b[39m27.43    \u001b[39m | \u001b[39m25.58    \u001b[39m | \u001b[39m56.48    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 98, 'lambda_l1': 0.7862974688962294, 'lambda_l2': 1.7245314488600172, 'feature_fraction': 0.9640858943045487, 'bagging_fraction': 0.6743054572447139, 'min_child_samples': 6, 'min_child_weight': 25.664516063705808, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1227]\tvalid_0's binary_logloss: 0.486115\n",
      "roc-auc : 0.7388112897407801\n",
      "\n",
      "| \u001b[39m40       \u001b[39m | \u001b[39m0.7388   \u001b[39m | \u001b[39m0.6743   \u001b[39m | \u001b[39m0.9641   \u001b[39m | \u001b[39m0.7863   \u001b[39m | \u001b[39m1.725    \u001b[39m | \u001b[39m6.379    \u001b[39m | \u001b[39m25.66    \u001b[39m | \u001b[39m98.24    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 48, 'lambda_l1': 0.14960321571148916, 'lambda_l2': 1.8544538783879079, 'feature_fraction': 0.9879116589506696, 'bagging_fraction': 0.6618733658530529, 'min_child_samples': 30, 'min_child_weight': 32.419517577845426, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1392]\tvalid_0's binary_logloss: 0.485702\n",
      "roc-auc : 0.739666057588946\n",
      "\n",
      "| \u001b[39m41       \u001b[39m | \u001b[39m0.7397   \u001b[39m | \u001b[39m0.6619   \u001b[39m | \u001b[39m0.9879   \u001b[39m | \u001b[39m0.1496   \u001b[39m | \u001b[39m1.854    \u001b[39m | \u001b[39m30.12    \u001b[39m | \u001b[39m32.42    \u001b[39m | \u001b[39m48.0     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 51, 'lambda_l1': 0.9502238160688734, 'lambda_l2': 0.3773329060128292, 'feature_fraction': 0.9901558983799348, 'bagging_fraction': 0.7805487165453704, 'min_child_samples': 25, 'min_child_weight': 34.58597480590337, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1392]\tvalid_0's binary_logloss: 0.48583\n",
      "roc-auc : 0.7393859624079971\n",
      "\n",
      "| \u001b[39m42       \u001b[39m | \u001b[39m0.7394   \u001b[39m | \u001b[39m0.7805   \u001b[39m | \u001b[39m0.9902   \u001b[39m | \u001b[39m0.9502   \u001b[39m | \u001b[39m0.3773   \u001b[39m | \u001b[39m25.2     \u001b[39m | \u001b[39m34.59    \u001b[39m | \u001b[39m50.79    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 44, 'lambda_l1': 0.2954653161063313, 'lambda_l2': 1.8072933157059252, 'feature_fraction': 0.8156884316335837, 'bagging_fraction': 0.610683744050746, 'min_child_samples': 35, 'min_child_weight': 33.33839972282095, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1649]\tvalid_0's binary_logloss: 0.485811\n",
      "roc-auc : 0.7393833477971817\n",
      "\n",
      "| \u001b[39m43       \u001b[39m | \u001b[39m0.7394   \u001b[39m | \u001b[39m0.6107   \u001b[39m | \u001b[39m0.8157   \u001b[39m | \u001b[39m0.2955   \u001b[39m | \u001b[39m1.807    \u001b[39m | \u001b[39m35.28    \u001b[39m | \u001b[39m33.34    \u001b[39m | \u001b[39m44.28    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 73, 'lambda_l1': 0.9931698633941952, 'lambda_l2': 0.20196383869993606, 'feature_fraction': 0.9134325769107094, 'bagging_fraction': 0.6566919312868704, 'min_child_samples': 28, 'min_child_weight': 49.88394597503101, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1301]\tvalid_0's binary_logloss: 0.486085\n",
      "roc-auc : 0.7389199440110278\n",
      "\n",
      "| \u001b[39m44       \u001b[39m | \u001b[39m0.7389   \u001b[39m | \u001b[39m0.6567   \u001b[39m | \u001b[39m0.9134   \u001b[39m | \u001b[39m0.9932   \u001b[39m | \u001b[39m0.202    \u001b[39m | \u001b[39m27.91    \u001b[39m | \u001b[39m49.88    \u001b[39m | \u001b[39m72.67    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.3940568183187394, 'lambda_l2': 1.1444079488659142, 'feature_fraction': 0.9441908286051297, 'bagging_fraction': 0.5678468180727039, 'min_child_samples': 5, 'min_child_weight': 33.664263324292605, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1910]\tvalid_0's binary_logloss: 0.485707\n",
      "roc-auc : 0.7396173814513567\n",
      "\n",
      "| \u001b[39m45       \u001b[39m | \u001b[39m0.7396   \u001b[39m | \u001b[39m0.5678   \u001b[39m | \u001b[39m0.9442   \u001b[39m | \u001b[39m0.3941   \u001b[39m | \u001b[39m1.144    \u001b[39m | \u001b[39m5.037    \u001b[39m | \u001b[39m33.66    \u001b[39m | \u001b[39m31.14    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.2420486331120698, 'lambda_l2': 1.7907573694235361, 'feature_fraction': 0.8093592593961003, 'bagging_fraction': 0.7935268491470542, 'min_child_samples': 5, 'min_child_weight': 39.42032401960492, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2138]\tvalid_0's binary_logloss: 0.485745\n",
      "roc-auc : 0.7394493697186786\n",
      "\n",
      "| \u001b[39m46       \u001b[39m | \u001b[39m0.7394   \u001b[39m | \u001b[39m0.7935   \u001b[39m | \u001b[39m0.8094   \u001b[39m | \u001b[39m0.242    \u001b[39m | \u001b[39m1.791    \u001b[39m | \u001b[39m5.301    \u001b[39m | \u001b[39m39.42    \u001b[39m | \u001b[39m30.39    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 36, 'lambda_l1': 0.909075503383371, 'lambda_l2': 0.09482919481771668, 'feature_fraction': 0.9186864906061981, 'bagging_fraction': 0.5467701547672661, 'min_child_samples': 5, 'min_child_weight': 34.21855443853844, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1771]\tvalid_0's binary_logloss: 0.485782\n",
      "roc-auc : 0.7394758806330056\n",
      "\n",
      "| \u001b[39m47       \u001b[39m | \u001b[39m0.7395   \u001b[39m | \u001b[39m0.5468   \u001b[39m | \u001b[39m0.9187   \u001b[39m | \u001b[39m0.9091   \u001b[39m | \u001b[39m0.09483  \u001b[39m | \u001b[39m5.25     \u001b[39m | \u001b[39m34.22    \u001b[39m | \u001b[39m36.05    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 55, 'lambda_l1': 0.2392869224525639, 'lambda_l2': 0.25034507203577205, 'feature_fraction': 0.8110823604299773, 'bagging_fraction': 0.7363631126891892, 'min_child_samples': 50, 'min_child_weight': 40.413418207047755, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1458]\tvalid_0's binary_logloss: 0.485886\n",
      "roc-auc : 0.7392800466827167\n",
      "\n",
      "| \u001b[39m48       \u001b[39m | \u001b[39m0.7393   \u001b[39m | \u001b[39m0.7364   \u001b[39m | \u001b[39m0.8111   \u001b[39m | \u001b[39m0.2393   \u001b[39m | \u001b[39m0.2503   \u001b[39m | \u001b[39m49.94    \u001b[39m | \u001b[39m40.41    \u001b[39m | \u001b[39m54.54    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 33, 'lambda_l1': 0.2590137368823551, 'lambda_l2': 1.9499346388394974, 'feature_fraction': 0.7732837893857748, 'bagging_fraction': 0.6908377071644854, 'min_child_samples': 36, 'min_child_weight': 49.87647051065184, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1853]\tvalid_0's binary_logloss: 0.485907\n",
      "roc-auc : 0.7392139617946751\n",
      "\n",
      "| \u001b[39m49       \u001b[39m | \u001b[39m0.7392   \u001b[39m | \u001b[39m0.6908   \u001b[39m | \u001b[39m0.7733   \u001b[39m | \u001b[39m0.259    \u001b[39m | \u001b[39m1.95     \u001b[39m | \u001b[39m35.96    \u001b[39m | \u001b[39m49.88    \u001b[39m | \u001b[39m32.89    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 48, 'lambda_l1': 0.9709820108107896, 'lambda_l2': 0.4690713621952327, 'feature_fraction': 0.8816106558046031, 'bagging_fraction': 0.6957100797727003, 'min_child_samples': 29, 'min_child_weight': 27.699273181455734, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1654]\tvalid_0's binary_logloss: 0.485785\n",
      "roc-auc : 0.7393722137128991\n",
      "\n",
      "| \u001b[39m50       \u001b[39m | \u001b[39m0.7394   \u001b[39m | \u001b[39m0.6957   \u001b[39m | \u001b[39m0.8816   \u001b[39m | \u001b[39m0.971    \u001b[39m | \u001b[39m0.4691   \u001b[39m | \u001b[39m28.99    \u001b[39m | \u001b[39m27.7     \u001b[39m | \u001b[39m47.95    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 41, 'lambda_l1': 0.8476060853879586, 'lambda_l2': 0.14021361179064984, 'feature_fraction': 0.9762801818282724, 'bagging_fraction': 0.5256602362146501, 'min_child_samples': 22, 'min_child_weight': 25.24152409381187, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1537]\tvalid_0's binary_logloss: 0.48577\n",
      "roc-auc : 0.7395388871566315\n",
      "\n",
      "| \u001b[39m51       \u001b[39m | \u001b[39m0.7395   \u001b[39m | \u001b[39m0.5257   \u001b[39m | \u001b[39m0.9763   \u001b[39m | \u001b[39m0.8476   \u001b[39m | \u001b[39m0.1402   \u001b[39m | \u001b[39m22.39    \u001b[39m | \u001b[39m25.24    \u001b[39m | \u001b[39m41.36    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.007014206165546488, 'lambda_l2': 1.7964894433674392, 'feature_fraction': 0.7034808501959812, 'bagging_fraction': 0.5156165565825939, 'min_child_samples': 43, 'min_child_weight': 49.78946517432914, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2166]\tvalid_0's binary_logloss: 0.486148\n",
      "roc-auc : 0.7389559129001815\n",
      "\n",
      "| \u001b[39m52       \u001b[39m | \u001b[39m0.739    \u001b[39m | \u001b[39m0.5156   \u001b[39m | \u001b[39m0.7035   \u001b[39m | \u001b[39m0.007014 \u001b[39m | \u001b[39m1.796    \u001b[39m | \u001b[39m42.66    \u001b[39m | \u001b[39m49.79    \u001b[39m | \u001b[39m30.6     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 33, 'lambda_l1': 0.3252104113905476, 'lambda_l2': 1.4883606682481234, 'feature_fraction': 0.8323196617049129, 'bagging_fraction': 0.5519709493542766, 'min_child_samples': 48, 'min_child_weight': 30.118422813058807, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2020]\tvalid_0's binary_logloss: 0.485809\n",
      "roc-auc : 0.7393830959310025\n",
      "\n",
      "| \u001b[39m53       \u001b[39m | \u001b[39m0.7394   \u001b[39m | \u001b[39m0.552    \u001b[39m | \u001b[39m0.8323   \u001b[39m | \u001b[39m0.3252   \u001b[39m | \u001b[39m1.488    \u001b[39m | \u001b[39m48.28    \u001b[39m | \u001b[39m30.12    \u001b[39m | \u001b[39m32.68    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 47, 'lambda_l1': 0.5816204529565926, 'lambda_l2': 1.0158661052225395, 'feature_fraction': 0.8879218879765232, 'bagging_fraction': 0.7240778125594741, 'min_child_samples': 27, 'min_child_weight': 31.353960646825506, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1548]\tvalid_0's binary_logloss: 0.485769\n",
      "roc-auc : 0.7394536904230191\n",
      "\n",
      "| \u001b[39m54       \u001b[39m | \u001b[39m0.7395   \u001b[39m | \u001b[39m0.7241   \u001b[39m | \u001b[39m0.8879   \u001b[39m | \u001b[39m0.5816   \u001b[39m | \u001b[39m1.016    \u001b[39m | \u001b[39m27.36    \u001b[39m | \u001b[39m31.35    \u001b[39m | \u001b[39m47.43    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 46, 'lambda_l1': 0.45469532393777856, 'lambda_l2': 1.7226450250221015, 'feature_fraction': 0.9568759429838867, 'bagging_fraction': 0.509989194106186, 'min_child_samples': 30, 'min_child_weight': 34.61937609617415, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1538]\tvalid_0's binary_logloss: 0.485901\n",
      "roc-auc : 0.7392925700288626\n",
      "\n",
      "| \u001b[39m55       \u001b[39m | \u001b[39m0.7393   \u001b[39m | \u001b[39m0.51     \u001b[39m | \u001b[39m0.9569   \u001b[39m | \u001b[39m0.4547   \u001b[39m | \u001b[39m1.723    \u001b[39m | \u001b[39m29.92    \u001b[39m | \u001b[39m34.62    \u001b[39m | \u001b[39m45.94    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 43, 'lambda_l1': 0.49436733536194377, 'lambda_l2': 0.9179847957693168, 'feature_fraction': 0.737447566654208, 'bagging_fraction': 0.6165967626599265, 'min_child_samples': 25, 'min_child_weight': 26.104246795659193, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1642]\tvalid_0's binary_logloss: 0.485901\n",
      "roc-auc : 0.7392905910803096\n",
      "\n",
      "| \u001b[39m56       \u001b[39m | \u001b[39m0.7393   \u001b[39m | \u001b[39m0.6166   \u001b[39m | \u001b[39m0.7374   \u001b[39m | \u001b[39m0.4944   \u001b[39m | \u001b[39m0.918    \u001b[39m | \u001b[39m25.4     \u001b[39m | \u001b[39m26.1     \u001b[39m | \u001b[39m43.3     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 50, 'lambda_l1': 0.4417636607751647, 'lambda_l2': 1.5966745398956415, 'feature_fraction': 0.9126894267944067, 'bagging_fraction': 0.5848605477834633, 'min_child_samples': 29, 'min_child_weight': 31.899578520216405, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1541]\tvalid_0's binary_logloss: 0.485876\n",
      "roc-auc : 0.7392614305737534\n",
      "\n",
      "| \u001b[39m57       \u001b[39m | \u001b[39m0.7393   \u001b[39m | \u001b[39m0.5849   \u001b[39m | \u001b[39m0.9127   \u001b[39m | \u001b[39m0.4418   \u001b[39m | \u001b[39m1.597    \u001b[39m | \u001b[39m29.27    \u001b[39m | \u001b[39m31.9     \u001b[39m | \u001b[39m50.2     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 32, 'lambda_l1': 0.7221615279214574, 'lambda_l2': 0.6649959780261794, 'feature_fraction': 0.7468874497452712, 'bagging_fraction': 0.5914249357471003, 'min_child_samples': 5, 'min_child_weight': 35.941769343110046, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2000]\tvalid_0's binary_logloss: 0.485903\n",
      "roc-auc : 0.7392400019591191\n",
      "\n",
      "| \u001b[39m58       \u001b[39m | \u001b[39m0.7392   \u001b[39m | \u001b[39m0.5914   \u001b[39m | \u001b[39m0.7469   \u001b[39m | \u001b[39m0.7222   \u001b[39m | \u001b[39m0.665    \u001b[39m | \u001b[39m5.055    \u001b[39m | \u001b[39m35.94    \u001b[39m | \u001b[39m32.17    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 47, 'lambda_l1': 0.48864684434111727, 'lambda_l2': 0.9644363986309565, 'feature_fraction': 0.7592657529081706, 'bagging_fraction': 0.7062106444031733, 'min_child_samples': 30, 'min_child_weight': 32.48456532372812, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1686]\tvalid_0's binary_logloss: 0.485894\n",
      "roc-auc : 0.7392325159365627\n",
      "\n",
      "| \u001b[39m59       \u001b[39m | \u001b[39m0.7392   \u001b[39m | \u001b[39m0.7062   \u001b[39m | \u001b[39m0.7593   \u001b[39m | \u001b[39m0.4886   \u001b[39m | \u001b[39m0.9644   \u001b[39m | \u001b[39m30.14    \u001b[39m | \u001b[39m32.48    \u001b[39m | \u001b[39m46.81    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.8798025643031906, 'lambda_l2': 0.16249901157711388, 'feature_fraction': 0.7742794161189789, 'bagging_fraction': 0.5431780255230184, 'min_child_samples': 38, 'min_child_weight': 49.8730370563414, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2121]\tvalid_0's binary_logloss: 0.486081\n",
      "roc-auc : 0.7390264774081294\n",
      "\n",
      "| \u001b[39m60       \u001b[39m | \u001b[39m0.739    \u001b[39m | \u001b[39m0.5432   \u001b[39m | \u001b[39m0.7743   \u001b[39m | \u001b[39m0.8798   \u001b[39m | \u001b[39m0.1625   \u001b[39m | \u001b[39m38.33    \u001b[39m | \u001b[39m49.87    \u001b[39m | \u001b[39m30.44    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 89, 'lambda_l1': 0.8917012714201686, 'lambda_l2': 0.8665402922611376, 'feature_fraction': 0.972215634872859, 'bagging_fraction': 0.6837096262122895, 'min_child_samples': 43, 'min_child_weight': 36.70121497138267, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1233]\tvalid_0's binary_logloss: 0.486039\n",
      "roc-auc : 0.7389985042707049\n",
      "\n",
      "| \u001b[39m61       \u001b[39m | \u001b[39m0.739    \u001b[39m | \u001b[39m0.6837   \u001b[39m | \u001b[39m0.9722   \u001b[39m | \u001b[39m0.8917   \u001b[39m | \u001b[39m0.8665   \u001b[39m | \u001b[39m42.89    \u001b[39m | \u001b[39m36.7     \u001b[39m | \u001b[39m89.49    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 85, 'lambda_l1': 0.4405404398126288, 'lambda_l2': 0.5775788762355425, 'feature_fraction': 0.7204810621783189, 'bagging_fraction': 0.6294330262499519, 'min_child_samples': 46, 'min_child_weight': 35.58800584886126, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1293]\tvalid_0's binary_logloss: 0.486157\n",
      "roc-auc : 0.7389078104577788\n",
      "\n",
      "| \u001b[39m62       \u001b[39m | \u001b[39m0.7389   \u001b[39m | \u001b[39m0.6294   \u001b[39m | \u001b[39m0.7205   \u001b[39m | \u001b[39m0.4405   \u001b[39m | \u001b[39m0.5776   \u001b[39m | \u001b[39m45.68    \u001b[39m | \u001b[39m35.59    \u001b[39m | \u001b[39m85.07    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 76, 'lambda_l1': 0.6788795972671222, 'lambda_l2': 1.8137798964955956, 'feature_fraction': 0.9105562071202508, 'bagging_fraction': 0.505271564655831, 'min_child_samples': 28, 'min_child_weight': 27.46211583382531, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1311]\tvalid_0's binary_logloss: 0.486051\n",
      "roc-auc : 0.739049225321799\n",
      "\n",
      "| \u001b[39m63       \u001b[39m | \u001b[39m0.739    \u001b[39m | \u001b[39m0.5053   \u001b[39m | \u001b[39m0.9106   \u001b[39m | \u001b[39m0.6789   \u001b[39m | \u001b[39m1.814    \u001b[39m | \u001b[39m28.24    \u001b[39m | \u001b[39m27.46    \u001b[39m | \u001b[39m75.54    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 46, 'lambda_l1': 0.848601164737293, 'lambda_l2': 0.27398602292985164, 'feature_fraction': 0.7602427549558691, 'bagging_fraction': 0.7362678314625575, 'min_child_samples': 21, 'min_child_weight': 44.10347479381592, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1649]\tvalid_0's binary_logloss: 0.485905\n",
      "roc-auc : 0.7392325499185075\n",
      "\n",
      "| \u001b[39m64       \u001b[39m | \u001b[39m0.7392   \u001b[39m | \u001b[39m0.7363   \u001b[39m | \u001b[39m0.7602   \u001b[39m | \u001b[39m0.8486   \u001b[39m | \u001b[39m0.274    \u001b[39m | \u001b[39m21.13    \u001b[39m | \u001b[39m44.1     \u001b[39m | \u001b[39m45.95    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 31, 'lambda_l1': 0.8742286490397031, 'lambda_l2': 1.9213708775138554, 'feature_fraction': 0.9930153443385332, 'bagging_fraction': 0.6033451989713122, 'min_child_samples': 45, 'min_child_weight': 27.479329470498726, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1958]\tvalid_0's binary_logloss: 0.485657\n",
      "roc-auc : 0.7396843398752748\n",
      "\n",
      "| \u001b[35m65       \u001b[39m | \u001b[35m0.7397   \u001b[39m | \u001b[35m0.6033   \u001b[39m | \u001b[35m0.993    \u001b[39m | \u001b[35m0.8742   \u001b[39m | \u001b[35m1.921    \u001b[39m | \u001b[35m45.46    \u001b[39m | \u001b[35m27.48    \u001b[39m | \u001b[35m31.21    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 71, 'lambda_l1': 0.3594338587618463, 'lambda_l2': 1.413065016576255, 'feature_fraction': 0.9371293142620679, 'bagging_fraction': 0.5705701648093844, 'min_child_samples': 5, 'min_child_weight': 46.34998746650814, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1210]\tvalid_0's binary_logloss: 0.486069\n",
      "roc-auc : 0.739078687667983\n",
      "\n",
      "| \u001b[39m66       \u001b[39m | \u001b[39m0.7391   \u001b[39m | \u001b[39m0.5706   \u001b[39m | \u001b[39m0.9371   \u001b[39m | \u001b[39m0.3594   \u001b[39m | \u001b[39m1.413    \u001b[39m | \u001b[39m5.423    \u001b[39m | \u001b[39m46.35    \u001b[39m | \u001b[39m70.67    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 45, 'lambda_l1': 0.018265377712030295, 'lambda_l2': 1.830834668590727, 'feature_fraction': 0.9358795318016, 'bagging_fraction': 0.5764404545705497, 'min_child_samples': 27, 'min_child_weight': 49.8462930549505, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1551]\tvalid_0's binary_logloss: 0.48591\n",
      "roc-auc : 0.7393258983210076\n",
      "\n",
      "| \u001b[39m67       \u001b[39m | \u001b[39m0.7393   \u001b[39m | \u001b[39m0.5764   \u001b[39m | \u001b[39m0.9359   \u001b[39m | \u001b[39m0.01827  \u001b[39m | \u001b[39m1.831    \u001b[39m | \u001b[39m26.73    \u001b[39m | \u001b[39m49.85    \u001b[39m | \u001b[39m45.26    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 63, 'lambda_l1': 0.9530840415787656, 'lambda_l2': 0.49576830086692825, 'feature_fraction': 0.8766351578091269, 'bagging_fraction': 0.5743174889807824, 'min_child_samples': 42, 'min_child_weight': 33.208454469671246, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1358]\tvalid_0's binary_logloss: 0.486024\n",
      "roc-auc : 0.739058346475584\n",
      "\n",
      "| \u001b[39m68       \u001b[39m | \u001b[39m0.7391   \u001b[39m | \u001b[39m0.5743   \u001b[39m | \u001b[39m0.8766   \u001b[39m | \u001b[39m0.9531   \u001b[39m | \u001b[39m0.4958   \u001b[39m | \u001b[39m41.92    \u001b[39m | \u001b[39m33.21    \u001b[39m | \u001b[39m62.56    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 55, 'lambda_l1': 0.9357670965595871, 'lambda_l2': 0.24813051975548905, 'feature_fraction': 0.8974234106526707, 'bagging_fraction': 0.7191530693330829, 'min_child_samples': 11, 'min_child_weight': 30.879922790605537, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1375]\tvalid_0's binary_logloss: 0.485845\n",
      "roc-auc : 0.7393522643123347\n",
      "\n",
      "| \u001b[39m69       \u001b[39m | \u001b[39m0.7394   \u001b[39m | \u001b[39m0.7192   \u001b[39m | \u001b[39m0.8974   \u001b[39m | \u001b[39m0.9358   \u001b[39m | \u001b[39m0.2481   \u001b[39m | \u001b[39m11.2     \u001b[39m | \u001b[39m30.88    \u001b[39m | \u001b[39m55.28    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 37, 'lambda_l1': 0.4239361222068718, 'lambda_l2': 0.8959230288440532, 'feature_fraction': 0.7886329752904959, 'bagging_fraction': 0.7025788485326744, 'min_child_samples': 37, 'min_child_weight': 27.060542451685276, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1916]\tvalid_0's binary_logloss: 0.4858\n",
      "roc-auc : 0.739366960504013\n",
      "\n",
      "| \u001b[39m70       \u001b[39m | \u001b[39m0.7394   \u001b[39m | \u001b[39m0.7026   \u001b[39m | \u001b[39m0.7886   \u001b[39m | \u001b[39m0.4239   \u001b[39m | \u001b[39m0.8959   \u001b[39m | \u001b[39m36.73    \u001b[39m | \u001b[39m27.06    \u001b[39m | \u001b[39m36.81    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 39, 'lambda_l1': 0.4405914740708746, 'lambda_l2': 1.6597852428190307, 'feature_fraction': 0.8622474988376232, 'bagging_fraction': 0.5298661661769396, 'min_child_samples': 33, 'min_child_weight': 34.83287270094506, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1571]\tvalid_0's binary_logloss: 0.485899\n",
      "roc-auc : 0.7393461375675723\n",
      "\n",
      "| \u001b[39m71       \u001b[39m | \u001b[39m0.7393   \u001b[39m | \u001b[39m0.5299   \u001b[39m | \u001b[39m0.8622   \u001b[39m | \u001b[39m0.4406   \u001b[39m | \u001b[39m1.66     \u001b[39m | \u001b[39m32.68    \u001b[39m | \u001b[39m34.83    \u001b[39m | \u001b[39m38.61    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 42, 'lambda_l1': 0.8136568743021815, 'lambda_l2': 0.06655993965337448, 'feature_fraction': 0.7204982229423179, 'bagging_fraction': 0.7556176746619239, 'min_child_samples': 35, 'min_child_weight': 28.76846575056883, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1777]\tvalid_0's binary_logloss: 0.485893\n",
      "roc-auc : 0.7392216756961558\n",
      "\n",
      "| \u001b[39m72       \u001b[39m | \u001b[39m0.7392   \u001b[39m | \u001b[39m0.7556   \u001b[39m | \u001b[39m0.7205   \u001b[39m | \u001b[39m0.8137   \u001b[39m | \u001b[39m0.06656  \u001b[39m | \u001b[39m35.31    \u001b[39m | \u001b[39m28.77    \u001b[39m | \u001b[39m41.56    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 61, 'lambda_l1': 0.8627668635772631, 'lambda_l2': 1.2346056964769208, 'feature_fraction': 0.8696952697400554, 'bagging_fraction': 0.5141739192161918, 'min_child_samples': 14, 'min_child_weight': 47.429646004253726, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1393]\tvalid_0's binary_logloss: 0.48616\n",
      "roc-auc : 0.738929269056482\n",
      "\n",
      "| \u001b[39m73       \u001b[39m | \u001b[39m0.7389   \u001b[39m | \u001b[39m0.5142   \u001b[39m | \u001b[39m0.8697   \u001b[39m | \u001b[39m0.8628   \u001b[39m | \u001b[39m1.235    \u001b[39m | \u001b[39m14.36    \u001b[39m | \u001b[39m47.43    \u001b[39m | \u001b[39m60.68    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 34, 'lambda_l1': 0.12779220526941126, 'lambda_l2': 1.7215192242460966, 'feature_fraction': 0.7135765843171423, 'bagging_fraction': 0.5403814844448807, 'min_child_samples': 16, 'min_child_weight': 36.82684706496041, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2288]\tvalid_0's binary_logloss: 0.486015\n",
      "roc-auc : 0.7389685182027825\n",
      "\n",
      "| \u001b[39m74       \u001b[39m | \u001b[39m0.739    \u001b[39m | \u001b[39m0.5404   \u001b[39m | \u001b[39m0.7136   \u001b[39m | \u001b[39m0.1278   \u001b[39m | \u001b[39m1.722    \u001b[39m | \u001b[39m16.17    \u001b[39m | \u001b[39m36.83    \u001b[39m | \u001b[39m34.26    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 51, 'lambda_l1': 0.5254268482803882, 'lambda_l2': 1.9325817949477044, 'feature_fraction': 0.8283994514982524, 'bagging_fraction': 0.5929979039586151, 'min_child_samples': 30, 'min_child_weight': 35.59764691425934, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 53119, number of negative: 151961\n",
      "[LightGBM] [Info] Total Bins 814\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.259016 -> initscore=-1.051089\n",
      "[LightGBM] [Info] Start training from score -1.051089\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1493]\tvalid_0's binary_logloss: 0.485929\n",
      "roc-auc : 0.7392039431177584\n",
      "\n",
      "| \u001b[39m75       \u001b[39m | \u001b[39m0.7392   \u001b[39m | \u001b[39m0.593    \u001b[39m | \u001b[39m0.8284   \u001b[39m | \u001b[39m0.5254   \u001b[39m | \u001b[39m1.933    \u001b[39m | \u001b[39m29.61    \u001b[39m | \u001b[39m35.6     \u001b[39m | \u001b[39m50.97    \u001b[39m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 베이지안 최적화 수행\n",
    "# TODO: init_points 10~15, n_iter 30~70\n",
    "optimizer.maximize(init_points=15, n_iter=60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad327f97",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T00:26:33.459135Z",
     "iopub.status.busy": "2025-02-20T00:26:33.458886Z",
     "iopub.status.idle": "2025-02-20T00:26:33.462410Z",
     "shell.execute_reply": "2025-02-20T00:26:33.461767Z"
    },
    "papermill": {
     "duration": 0.019484,
     "end_time": "2025-02-20T00:26:33.463547",
     "exception": false,
     "start_time": "2025-02-20T00:26:33.444063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 평가함수 점수가 최대일 때 하이퍼파라미터\n",
    "max_params = optimizer.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "edb353bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T00:26:33.492072Z",
     "iopub.status.busy": "2025-02-20T00:26:33.491856Z",
     "iopub.status.idle": "2025-02-20T00:26:33.494940Z",
     "shell.execute_reply": "2025-02-20T00:26:33.494371Z"
    },
    "papermill": {
     "duration": 0.018737,
     "end_time": "2025-02-20T00:26:33.496078",
     "exception": false,
     "start_time": "2025-02-20T00:26:33.477341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 정수형 하이퍼파라미터 변환\n",
    "max_params['num_leaves'] = int(round(max_params['num_leaves']))\n",
    "max_params['min_child_samples'] = int(round(max_params['min_child_samples']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0e742380",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T00:26:33.524492Z",
     "iopub.status.busy": "2025-02-20T00:26:33.524252Z",
     "iopub.status.idle": "2025-02-20T00:26:33.527427Z",
     "shell.execute_reply": "2025-02-20T00:26:33.526650Z"
    },
    "papermill": {
     "duration": 0.018589,
     "end_time": "2025-02-20T00:26:33.528624",
     "exception": false,
     "start_time": "2025-02-20T00:26:33.510035",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 값이 고정된 하이퍼파라미터 추가\n",
    "max_params.update(fixed_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cb208e5a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T00:26:33.558512Z",
     "iopub.status.busy": "2025-02-20T00:26:33.558241Z",
     "iopub.status.idle": "2025-02-20T00:26:33.562866Z",
     "shell.execute_reply": "2025-02-20T00:26:33.562217Z"
    },
    "papermill": {
     "duration": 0.021293,
     "end_time": "2025-02-20T00:26:33.564073",
     "exception": false,
     "start_time": "2025-02-20T00:26:33.542780",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.6033451989713122,\n",
       " 'feature_fraction': 0.9930153443385332,\n",
       " 'lambda_l1': 0.8742286490397031,\n",
       " 'lambda_l2': 1.9213708775138554,\n",
       " 'min_child_samples': 45,\n",
       " 'min_child_weight': 27.479329470498726,\n",
       " 'num_leaves': 31,\n",
       " 'objective': 'binary',\n",
       " 'learning_rate': 0.005,\n",
       " 'bagging_freq': 1,\n",
       " 'force_row_wise': True,\n",
       " 'random_state': 1991}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e761e7bf",
   "metadata": {
    "papermill": {
     "duration": 0.013577,
     "end_time": "2025-02-20T00:26:33.591578",
     "exception": false,
     "start_time": "2025-02-20T00:26:33.578001",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. 모델 훈련"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d143651d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T00:26:33.620550Z",
     "iopub.status.busy": "2025-02-20T00:26:33.620269Z",
     "iopub.status.idle": "2025-02-20T00:26:33.623706Z",
     "shell.execute_reply": "2025-02-20T00:26:33.623013Z"
    },
    "papermill": {
     "duration": 0.019358,
     "end_time": "2025-02-20T00:26:33.625013",
     "exception": false,
     "start_time": "2025-02-20T00:26:33.605655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 층화 K 폴드 교차 검증기\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=1991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "99115828",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T00:26:33.654686Z",
     "iopub.status.busy": "2025-02-20T00:26:33.654408Z",
     "iopub.status.idle": "2025-02-20T00:26:33.658170Z",
     "shell.execute_reply": "2025-02-20T00:26:33.657493Z"
    },
    "papermill": {
     "duration": 0.019999,
     "end_time": "2025-02-20T00:26:33.659338",
     "exception": false,
     "start_time": "2025-02-20T00:26:33.639339",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# OOF 방식으로 훈련된 모델로 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
    "oof_val_preds = np.zeros(X.shape[0]) \n",
    "# OOF 방식으로 훈련된 모델로 테스트 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
    "oof_test_preds = np.zeros(X_test.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5831cd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T00:26:33.688771Z",
     "iopub.status.busy": "2025-02-20T00:26:33.688522Z",
     "iopub.status.idle": "2025-02-20T00:37:20.627656Z",
     "shell.execute_reply": "2025-02-20T00:37:20.626698Z"
    },
    "papermill": {
     "duration": 646.95586,
     "end_time": "2025-02-20T00:37:20.629672",
     "exception": false,
     "start_time": "2025-02-20T00:26:33.673812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## 폴드 1 / 폴드 10 ########################################\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171110\n",
      "[LightGBM] [Info] Total Bins 812\n",
      "[LightGBM] [Info] Number of data points in the train set: 230715, number of used features: 117\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258349 -> initscore=-1.054567\n",
      "[LightGBM] [Info] Start training from score -1.054567\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1391]\tvalid_0's binary_logloss: 0.489311\tvalid_0's roc_auc: 0.736317\n",
      "폴드 1 roc-auc : 0.7363168214276556\n",
      "\n",
      "######################################## 폴드 2 / 폴드 10 ########################################\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[LightGBM] [Info] Number of positive: 59606, number of negative: 171110\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258352 -> initscore=-1.054550\n",
      "[LightGBM] [Info] Start training from score -1.054550\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1681]\tvalid_0's binary_logloss: 0.488847\tvalid_0's roc_auc: 0.738109\n",
      "폴드 2 roc-auc : 0.7381092619980578\n",
      "\n",
      "######################################## 폴드 3 / 폴드 10 ########################################\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[LightGBM] [Info] Number of positive: 59606, number of negative: 171110\n",
      "[LightGBM] [Info] Total Bins 817\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 119\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258352 -> initscore=-1.054550\n",
      "[LightGBM] [Info] Start training from score -1.054550\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2164]\tvalid_0's binary_logloss: 0.486582\tvalid_0's roc_auc: 0.742848\n",
      "폴드 3 roc-auc : 0.7428484449662738\n",
      "\n",
      "######################################## 폴드 4 / 폴드 10 ########################################\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 817\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2095]\tvalid_0's binary_logloss: 0.48662\tvalid_0's roc_auc: 0.74236\n",
      "폴드 4 roc-auc : 0.7423602610987938\n",
      "\n",
      "######################################## 폴드 5 / 폴드 10 ########################################\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 818\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2478]\tvalid_0's binary_logloss: 0.486235\tvalid_0's roc_auc: 0.74138\n",
      "폴드 5 roc-auc : 0.7413801232810868\n",
      "\n",
      "######################################## 폴드 6 / 폴드 10 ########################################\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 816\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\tvalid_0's binary_logloss: 0.486693\tvalid_0's roc_auc: 0.741155\n",
      "폴드 6 roc-auc : 0.7411547238663192\n",
      "\n",
      "######################################## 폴드 7 / 폴드 10 ########################################\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 819\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 118\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2009]\tvalid_0's binary_logloss: 0.489758\tvalid_0's roc_auc: 0.736549\n",
      "폴드 7 roc-auc : 0.7365492582559251\n",
      "\n",
      "######################################## 폴드 8 / 폴드 10 ########################################\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 821\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 119\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1248]\tvalid_0's binary_logloss: 0.48737\tvalid_0's roc_auc: 0.742356\n",
      "폴드 8 roc-auc : 0.742355559569504\n",
      "\n",
      "######################################## 폴드 9 / 폴드 10 ########################################\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 820\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 119\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2366]\tvalid_0's binary_logloss: 0.486632\tvalid_0's roc_auc: 0.743941\n",
      "폴드 9 roc-auc : 0.7439411185554463\n",
      "\n",
      "######################################## 폴드 10 / 폴드 10 ########################################\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 822\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 119\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 200 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2177]\tvalid_0's binary_logloss: 0.488299\tvalid_0's roc_auc: 0.738759\n",
      "폴드 10 roc-auc : 0.7387592549842324\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OOF 방식으로 모델 훈련, 검증, 예측\n",
    "for idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
    "    # 각 폴드를 구분하는 문구 출력\n",
    "    print('#'*40, f'폴드 {idx+1} / 폴드 {folds.n_splits}', '#'*40)\n",
    "    print(type(X))  # DataFrame인지 확인\n",
    "    \n",
    "    # 훈련용 데이터, 검증용 데이터 설정\n",
    "    # X_train, y_train = X[train_idx], y[train_idx] # 훈련용 데이터\n",
    "    # X_valid, y_valid = X[valid_idx], y[valid_idx] # 검증용 데이터\n",
    "\n",
    "    # 데이터가 DataFrame인지 확인 후 인덱싱 방식 결정\n",
    "    if isinstance(X, pd.DataFrame):\n",
    "        X_train, X_valid = X.iloc[train_idx], X.iloc[valid_idx]\n",
    "    else:  # numpy.ndarray일 경우\n",
    "        X_train, X_valid = X[train_idx], X[valid_idx]\n",
    "\n",
    "    y_train, y_valid = y[train_idx], y[valid_idx]\n",
    "\n",
    "    # LightGBM 전용 데이터셋 생성\n",
    "    dtrain = lgb.Dataset(X_train, y_train, feature_name=cleaned_feature_names, params={'feature_pre_filter': False})\n",
    "    dvalid = lgb.Dataset(X_valid, y_valid, feature_name=cleaned_feature_names, params={'feature_pre_filter': False})\n",
    "                          \n",
    "    # LightGBM 모델 훈련\n",
    "    lgb_model = lgb.train(params=max_params,    # 최적 하이퍼파라미터\n",
    "                          train_set=dtrain,     # 훈련 데이터셋\n",
    "                          num_boost_round=2500, # 부스팅 반복 횟수\n",
    "                          valid_sets=dvalid,    # 성능 평가용 검증 데이터셋\n",
    "                          feval = lgb_roc_auc,\n",
    "                          callbacks=[early_stopping(stopping_rounds=200)])\n",
    "    \n",
    "    # 테스트 데이터를 활용해 OOF 예측\n",
    "    oof_test_preds += lgb_model.predict(X_test)/folds.n_splits\n",
    "    # 모델 성능 평가를 위한 검증 데이터 타깃값 예측 \n",
    "    oof_val_preds[valid_idx] += lgb_model.predict(X_valid)\n",
    "    \n",
    "    # 검증 데이터 예측 확률에 대한 ROC-AUC\n",
    "    roc_auc = roc_auc_score(y_valid, oof_val_preds[valid_idx])\n",
    "    print(f'폴드 {idx+1} roc-auc : {roc_auc}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5763426",
   "metadata": {
    "papermill": {
     "duration": 0.015571,
     "end_time": "2025-02-20T00:37:20.664954",
     "exception": false,
     "start_time": "2025-02-20T00:37:20.649383",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. 최종 결과"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b9e0d013",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T00:37:20.697997Z",
     "iopub.status.busy": "2025-02-20T00:37:20.697717Z",
     "iopub.status.idle": "2025-02-20T00:37:20.809290Z",
     "shell.execute_reply": "2025-02-20T00:37:20.808254Z"
    },
    "papermill": {
     "duration": 0.129783,
     "end_time": "2025-02-20T00:37:20.810745",
     "exception": false,
     "start_time": "2025-02-20T00:37:20.680962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF 검증 데이터 roc-auc : 0.740340231425398\n"
     ]
    }
   ],
   "source": [
    "print('OOF 검증 데이터 roc-auc :', roc_auc_score(y, oof_val_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8599cc5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-20T00:37:20.847190Z",
     "iopub.status.busy": "2025-02-20T00:37:20.846895Z",
     "iopub.status.idle": "2025-02-20T00:37:21.011191Z",
     "shell.execute_reply": "2025-02-20T00:37:21.010235Z"
    },
    "papermill": {
     "duration": 0.182506,
     "end_time": "2025-02-20T00:37:21.012904",
     "exception": false,
     "start_time": "2025-02-20T00:37:20.830398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission['probability'] = oof_test_preds\n",
    "submission.to_csv('v1_submission.csv')"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6693018,
     "sourceId": 10798733,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30886,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3199.986282,
   "end_time": "2025-02-20T00:37:22.053610",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-19T23:44:02.067328",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
