{"cells":[{"cell_type":"markdown","metadata":{},"source":["# LG Aimers 온라인 해커톤\n"]},{"cell_type":"markdown","metadata":{},"source":["목차\n","1. [개발 환경 및 버전 정보](#1-개발-환경-및-버전-정보)\n","2. [라이브러리 및 초기 세팅](#2-라이브러리-및-초기-세팅)\n","3. [데이터 전처리](#3-데이터-전처리)\n","4. [LGBM](#)\n","5. [CatBoost](#)\n","6. [NN 모델](#)\n","7. [앙상블](#)\n","8. [Submission 파일 생성](#)"]},{"cell_type":"markdown","metadata":{},"source":["## 1. 개발 환경 및 버전 정보"]},{"cell_type":"markdown","metadata":{},"source":["개발환경\n","|개발 환경|버전|비고|\n","|:---|:---:|:---|\n","|OS|22.04.3 LTS||\n","|CPU|Intel(R) Xeon(R) CPU @ 2.00GHz||\n","|RAM|32GB||\n","|GPU|P100||\n","|Python|3.10.12||\n","\n","라이브러리\n","|라이브러리|버전|비고|\n","|:---|:---:|:---|\n","|jupyter|3.6.8||\n","|numpy|1.26.4||\n","|pandas|2.2.3||\n","|scikit-learn|1.2.2||\n","|scipy|1.13.1||\n","|lightgbm|4.5.0||\n","|catboost|1.2.7||\n","|torch|2.5.1+cu121||"]},{"cell_type":"markdown","metadata":{},"source":["## 2. 라이브러리 및 초기 세팅"]},{"cell_type":"code","execution_count":1,"id":"e5c37149-d8c0-4cab-92d5-1115da062baa","metadata":{"trusted":true},"outputs":[],"source":["import os\n","import random\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.metrics import roc_auc_score\n","from sklearn.model_selection import StratifiedKFold\n","from scipy import sparse\n","\n","import lightgbm as lgb\n","from lightgbm import early_stopping\n","\n","from catboost import CatBoostClassifier, Pool\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.backends.cudnn as cudnn\n","from torch.utils.data import DataLoader\n","from torch.optim.lr_scheduler import OneCycleLR"]},{"cell_type":"code","execution_count":2,"id":"8b41a301-5126-453d-9869-368462aac1c8","metadata":{"trusted":true},"outputs":[],"source":["def seed_everything(seed: int=42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    cudnn.deterministic = True\n","    cudnn.benchmark = False\n","\n","seed_everything()"]},{"cell_type":"code","execution_count":3,"id":"e1016b78","metadata":{"papermill":{"duration":4.003699,"end_time":"2025-02-25T10:02:26.987206","exception":false,"start_time":"2025-02-25T10:02:22.983507","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["data_path = './data'\n","\n","train_df = pd.read_csv(os.path.join(data_path, 'train.csv'), index_col= 'ID')\n","test_df = pd.read_csv(os.path.join(data_path, 'test.csv'), index_col= 'ID')\n","submission_df = pd.read_csv(os.path.join(data_path, 'sample_submission.csv'), index_col= 'ID')"]},{"cell_type":"markdown","id":"9d37c538-1b78-45c0-ba15-9dae5fd325e2","metadata":{},"source":["## 3. 데이터 전처리"]},{"cell_type":"markdown","metadata":{},"source":["데이터 전처리의 경우 크게 2가지 방식으로 진행이 되었습니다.\n","1. baseline_dataset\n","- Baseline 코드 기반 데이터 전처리 방식에서 Ordinal Encoding 대신 One-Hot Encoding 방식으로 전처리된 데이터\n","- LGBM 학습에 사용\n","\n","2. kiwi_dataset\n","- 결측값 처리와 변수 \"특정 시술 유형\" 및 \"배아 생성 주요 이유\"를 변환하고 One-Hot Encoding 방식으로 전처리된 데이터\n","- CatBoost 및 NN 모델에 사용"]},{"cell_type":"markdown","metadata":{},"source":["### 1) baseline_dataset"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["class BaselineDataset():\n","    def __init__(self):\n","        self._set_parameters()\n","        self.train = True\n","    \n","    def _set_parameters(self):\n","        # 전처리에 사용될 변수명\n","        self.CATEGORICAL_COLUMN_LIST = [\n","            \"시술 시기 코드\",\n","            \"시술 당시 나이\",\n","            \"시술 유형\",\n","            \"특정 시술 유형\",\n","            \"배란 자극 여부\",\n","            \"배란 유도 유형\",\n","            \"단일 배아 이식 여부\",\n","            \"착상 전 유전 검사 사용 여부\",\n","            \"착상 전 유전 진단 사용 여부\",\n","            \"남성 주 불임 원인\",\n","            \"남성 부 불임 원인\",\n","            \"여성 주 불임 원인\",\n","            \"여성 부 불임 원인\",\n","            \"부부 주 불임 원인\",\n","            \"부부 부 불임 원인\",\n","            \"불명확 불임 원인\",\n","            \"불임 원인 - 난관 질환\",\n","            \"불임 원인 - 남성 요인\",\n","            \"불임 원인 - 배란 장애\",\n","            \"불임 원인 - 여성 요인\",\n","            \"불임 원인 - 자궁경부 문제\",\n","            \"불임 원인 - 자궁내막증\",\n","            \"불임 원인 - 정자 농도\",\n","            \"불임 원인 - 정자 면역학적 요인\",\n","            \"불임 원인 - 정자 운동성\",\n","            \"불임 원인 - 정자 형태\",\n","            \"배아 생성 주요 이유\",\n","            \"총 시술 횟수\",\n","            \"클리닉 내 총 시술 횟수\",\n","            \"IVF 시술 횟수\",\n","            \"DI 시술 횟수\",\n","            \"총 임신 횟수\",\n","            \"IVF 임신 횟수\",\n","            \"DI 임신 횟수\",\n","            \"총 출산 횟수\",\n","            \"IVF 출산 횟수\",\n","            \"DI 출산 횟수\",\n","            \"난자 출처\",\n","            \"정자 출처\",\n","            \"난자 기증자 나이\",\n","            \"정자 기증자 나이\",\n","            \"동결 배아 사용 여부\",\n","            \"신선 배아 사용 여부\",\n","            \"기증 배아 사용 여부\",\n","            \"대리모 여부\",\n","            \"PGD 시술 여부\",\n","            \"PGS 시술 여부\"\n","        ]\n","        self.QUANTITATIVE_COLUMN_LIST = [\n","            \"임신 시도 또는 마지막 임신 경과 연수\",\n","            \"총 생성 배아 수\",\n","            \"미세주입된 난자 수\",\n","            \"미세주입에서 생성된 배아 수\",\n","            \"이식된 배아 수\",\n","            \"미세주입 배아 이식 수\",\n","            \"저장된 배아 수\",\n","            \"미세주입 후 저장된 배아 수\",\n","            \"해동된 배아 수\",\n","            \"해동 난자 수\",\n","            \"수집된 신선 난자 수\",\n","            \"저장된 신선 난자 수\",\n","            \"혼합된 난자 수\",\n","            \"파트너 정자와 혼합된 난자 수\",\n","            \"기증자 정자와 혼합된 난자 수\",\n","            \"난자 채취 경과일\",\n","            \"난자 해동 경과일\",\n","            \"난자 혼합 경과일\",\n","            \"배아 이식 경과일\",\n","            \"배아 해동 경과일\"\n","        ]\n","\n","    def set_data(self, data:pd.DataFrame):\n","        '''\n","        전처리할 데이터를 설정하는 함수\n","        input:\n","        ---------------\n","        - data: 전처리할 데이터 (type: pd.DataFrame(판다스 데이터 프레임))\n","        '''\n","        self.data = data.copy()\n","\n","    def set_train_mode(self, train:bool=True):\n","        '''\n","        전처리할 데이터가 학습데이터인지 아닌지를 구분하는 함수\n","        input:\n","        ---------------\n","        - train: 학습데이터인지 아닌지 구분 (True = 학습데이터)\n","        '''\n","        self.train = train\n","\n","    def one_hot_encode(self):\n","        '''\n","        범주형 변수에 대한 One-Hot Encoding 진행\n","        '''\n","        for col in self.CATEGORICAL_COLUMN_LIST:\n","            self.data[col] = self.data[col].astype(str)\n","\n","        if self.train:\n","            self.ohe = OneHotEncoder(handle_unknown='ignore')\n","            self.ohe.fit(self.data[self.CATEGORICAL_COLUMN_LIST])\n","        else:\n","            assert self.ohe\n","            \n","        self.encoded_cat_matrix = self.ohe.transform(self.data[self.CATEGORICAL_COLUMN_LIST])\n","\n","    def get_data(self):\n","        '''\n","        전처리된 범주형, 연속형 변수들을 합쳐 데이터셋 생성\n","        '''\n","        if self.train:\n","            return sparse.hstack([sparse.csr_matrix(self.data[self.QUANTITATIVE_COLUMN_LIST]),\n","                               self.encoded_cat_matrix], format='csr'), self.data['임신 성공 여부'].values\n","        return sparse.hstack([sparse.csr_matrix(self.data[self.QUANTITATIVE_COLUMN_LIST]),\n","                               self.encoded_cat_matrix], format='csr')"]},{"cell_type":"markdown","metadata":{},"source":["### 2) kiwi_dataset"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["class KiwiDataset():\n","    def __init__(self):\n","        self._set_parameters()\n","        self.train = True\n","    \n","    def _set_parameters(self):\n","        # 전처리에 사용될 변수명\n","        self.TARGET_COLUMN = '임신 성공 여부'\n","        self.CATEGORICAL_COLUMN_LIST = ['시술 시기 코드', '시술 당시 나이', '배아 생성 주요 이유', '난자 출처', '정자 출처', '난자 기증자 나이', '정자 기증자 나이']\n","        self.QUANTITATIVE_COLUMN_LIST = ['임신 시도 또는 마지막 임신 경과 연수', '총 시술 횟수', '클리닉 내 총 시술 횟수', 'IVF 시술 횟수', 'DI 시술 횟수', '총 임신 횟수', 'IVF 임신 횟수', 'DI 임신 횟수', '총 출산 횟수', 'IVF 출산 횟수', 'DI 출산 횟수', '총 생성 배아 수', '미세주입된 난자 수', '미세주입에서 생성된 배아 수', '이식된 배아 수', '미세주입 배아 이식 수', '저장된 배아 수', '미세주입 후 저장된 배아 수', '해동된 배아 수', '해동 난자 수', '수집된 신선 난자 수', '저장된 신선 난자 수', '혼합된 난자 수', '파트너 정자와 혼합된 난자 수', '기증자 정자와 혼합된 난자 수', '난자 혼합 경과일', '배아 이식 경과일', '배아 해동 경과일']\n","        self.BINARY_COLUMN_LIST = ['배란 자극 여부', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부', '남성 주 불임 원인', '남성 부 불임 원인', '여성 주 불임 원인', '여성 부 불임 원인', '부부 주 불임 원인', '부부 부 불임 원인', '불명확 불임 원인', '불임 원인 - 난관 질환', '불임 원인 - 남성 요인', '불임 원인 - 배란 장애', '불임 원인 - 자궁경부 문제', '불임 원인 - 자궁내막증', '불임 원인 - 정자 농도', '불임 원인 - 정자 면역학적 요인', '불임 원인 - 정자 운동성', '불임 원인 - 정자 형태', '동결 배아 사용 여부', '신선 배아 사용 여부', '기증 배아 사용 여부', '대리모 여부', 'PGD 시술 여부', 'PGS 시술 여부']\n","        \n","        # 결측값 처리에 사용될 변수명과 처리 방식 dictionary\n","        self.MISSING_VALUE_RULE_DICT = {\n","            '특정 시술 유형': 'Unknown',\n","            '총 생성 배아 수': 0,\n","            '미세주입된 난자 수': 0,\n","            '미세주입에서 생성된 배아 수': 0,\n","            '이식된 배아 수': 0,\n","            '미세주입 배아 이식 수': 0,\n","            '저장된 배아 수': 0,\n","            '미세주입 후 저장된 배아 수': 0,\n","            '해동된 배아 수': 0,\n","            '해동 난자 수': 0,\n","            '수집된 신선 난자 수': 0,\n","            '저장된 신선 난자 수': 0,\n","            '혼합된 난자 수': 0,\n","            '파트너 정자와 혼합된 난자 수': 0,\n","            '기증자 정자와 혼합된 난자 수': 0, \n","            '단일 배아 이식 여부': 0,\n","            '착상 전 유전 검사 사용 여부': 0,\n","            '착상 전 유전 진단 사용 여부': 0,\n","            '동결 배아 사용 여부': 0,\n","            '신선 배아 사용 여부': 0,\n","            '기증 배아 사용 여부': 0,\n","            '대리모 여부': 0,\n","            'PGD 시술 여부': 0,\n","            'PGS 시술 여부': 0,\n","        }\n","\n","        # 교차 선택되어 있는 변수들의 고유값들\n","        ## 특정 시술 유형 변수에 대한 고유값\n","        self.SPECIFIC_PROCEDURE_LIST = ['IVF', 'ICSI', 'IUI', 'ICI', 'GIFT', 'FER', 'Generic DI', 'IVI', 'BLASTOCYST', 'AH', 'Unknown']\n","        ## 배아 생성 주요 이유 변수에 대한 고유값\n","        self.MAIN_PURPOSE_LIST =  '기증용, 난자 저장용, 배아 저장용, 연구용, 현재 시술용'.split(\", \")\n","\n","    def set_data(self, data:pd.DataFrame):\n","        '''\n","        전처리할 데이터를 설정하는 함수\n","        input:\n","        ---------------\n","        - data: 전처리할 데이터 (type: pd.DataFrame(판다스 데이터 프레임))\n","        '''\n","        self.data = data.copy()\n","\n","    def set_train_mode(self, train:bool=True):\n","        '''\n","        전처리할 데이터가 학습데이터인지 아닌지를 구분하는 함수\n","        input:\n","        ---------------\n","        - train: 학습데이터인지 아닌지 구분 (True = 학습데이터)\n","        '''\n","        self.train = train\n","\n","    def generate_dummy_variable(self, columns:list=['임신 시도 또는 마지막 임신 경과 연수', '난자 혼합 경과일', '배아 이식 경과일', '배아 해동 경과일']):\n","        '''\n","        결측값이 존재하는 변수들에 대한 결측값임을 나타내는 더미 변수 생성\n","        input:\n","        ---------------\n","        - columns: 더미 변수 생성할 결측값이 존재하는 변수명\n","        '''\n","        \n","        # 시술 유형이 DI에 따른 결측값 발생 변수들을 위한 더미 변수 생성\n","        self.data[\"DI 시술 여부\"] = self.data[\"시술 유형\"]==\"DI\"\n","        self.data[\"DI 시술 여부\"] = self.data[\"DI 시술 여부\"].astype(int)\n","        if self.train:\n","            self.BINARY_COLUMN_LIST.append(\"DI 시술 여부\")\n","\n","        # 그 외 원인 불명의 결측값 발생 변수들을 위한 더미 변수 생성\n","        for col in columns:\n","            dummy_column = f\"{col} 결측 여부\"\n","            self.data[dummy_column] = self.data[col].isnull().astype(int)\n","            \n","            if self.train:\n","                self.MISSING_VALUE_RULE_DICT[col] = 0\n","                self.BINARY_COLUMN_LIST.append(dummy_column)\n","\n","    def missing_value_imputation(self, rule_dict:dict=None):\n","        '''\n","        결측값이 존재하는 변수들에 대한 결측값임을 나타내는 더미 변수 생성\n","        input:\n","        ---------------\n","        - rule_dict: 결측값을 처리할 변수 규칙 (dict) 없을 경우 기존에 세팅한 규칙(MISSING_VALUE_RULE_DICT)을 따름\n","        '''\n","\n","        if rule_dict == None:\n","            rule_dict = self.MISSING_VALUE_RULE_DICT\n","        \n","        self.data.fillna(self.MISSING_VALUE_RULE_DICT, inplace=True)\n","    \n","    def transform_specific_procedure(self):\n","        '''\n","        변수 중 \"특정 시술 유형\"을 세분화 및 일반화를 통한 추가 변수 생성\n","        '''\n","\n","        procedure_columns_list = [f\"특정 시술 유형_{x}\" for x in self.SPECIFIC_PROCEDURE_LIST]\n","        self.data[procedure_columns_list] = 0\n","\n","        # 톡정 시술 복합 or 조합 여부\n","        self.data[\"복합 시술 횟수\"] = 0\n","        self.data[\"세부 조합 횟수\"] = 0\n","\n","        for index in self.data.index:\n","            if type(self.data.loc[index, '특정 시술 유형']) == float:\n","                continue\n","            procedure_list = self.data.loc[index, '특정 시술 유형'].split(\" / \")\n","            self.data.loc[index, \"복합 시술 횟수\"] = len(procedure_list)\n","            if len(procedure_list) == 0:\n","                continue\n","            for procedure in procedure_list:\n","                if \":\" in procedure:\n","                    p_list = procedure.split(\":\")\n","                    # if len(p_list) != 2:\n","                    #     raise ValueError(f\"{p_list}\")\n","                    for p in p_list:\n","                        if p[0] == \" \": p = p[1:]\n","                        if p[-1] == \" \": p = p[:-1]\n","                    \n","                        self.data.loc[index, f'특정 시술 유형_{p}'] += 1\n","                    self.data.loc[index, '세부 조합 횟수'] += 1\n","                else:\n","                    a = procedure\n","                    if procedure[0] == \" \": procedure = procedure[1:]\n","                    if procedure[-1] == \" \": procedure = procedure[:-1]\n","                    \n","                    self.data.loc[index, f\"특정 시술 유형_{procedure}\"] += 1\n","\n","        if self.train:\n","            self.QUANTITATIVE_COLUMN_LIST = self.QUANTITATIVE_COLUMN_LIST + procedure_columns_list\n","            self.QUANTITATIVE_COLUMN_LIST.append(\"복합 시술 횟수\")\n","            self.QUANTITATIVE_COLUMN_LIST.append(\"세부 조합 횟수\")\n","        \n","    \n","    def transform_main_purpose(self):\n","        '''\n","        변수 중 \"배아 생성 주요 이유\"을 세분화 및 일반화를 통한 추가 변수 생성\n","        '''\n","\n","        purpose_columns_list = [f\"배아 생성 주요 이유_{x}\" for x in self.MAIN_PURPOSE_LIST]\n","        self.data[purpose_columns_list] = 0\n","\n","        except_index_list = []\n","        for index in self.data.index:\n","            if type(self.data.loc[index, '배아 생성 주요 이유']) == float:\n","                except_index_list.append(index)\n","                continue\n","            purpose_list = self.data.loc[index, '배아 생성 주요 이유'].split(\", \")\n","            # self.data.loc[index, \"배아 생성 주요 이유\"] = len(purpose_list)\n","            if len(purpose_list) == 0:\n","                continue\n","            for procedure in purpose_list:\n","                self.data.loc[index, f'배아 생성 주요 이유_{procedure}'] += 1\n","\n","        if self.train:\n","            self.BINARY_COLUMN_LIST = self.BINARY_COLUMN_LIST + purpose_columns_list\n","            self.CATEGORICAL_COLUMN_LIST.remove(\"배아 생성 주요 이유\")\n","\n","    def one_hot_encode(self):\n","        '''\n","        범주형 변수에 대한 One-Hot Encoding 진행\n","        '''\n","\n","        if self.train:\n","            self.ohe = OneHotEncoder()\n","            self.ohe.fit(self.data[self.CATEGORICAL_COLUMN_LIST])\n","        else:\n","            assert self.ohe\n","            \n","        self.categorical_df = pd.DataFrame(self.ohe.transform(self.data[self.CATEGORICAL_COLUMN_LIST]).toarray(), columns=self.ohe.get_feature_names_out(), index = self.data.index)\n","\n","    def select_data(self):\n","        '''\n","        전처리된 변수들을 기반으로 학습 or 예측용 데이터셋 생성\n","        '''\n","\n","        selected_column_list = self.QUANTITATIVE_COLUMN_LIST + self.BINARY_COLUMN_LIST\n","        transformed_df = self.data[selected_column_list]\n","        transformed_df\n","        \n","        for i in range(1, 11):\n","            transformed_df.loc[:, self.QUANTITATIVE_COLUMN_LIST[i]] = transformed_df.loc[:, self.QUANTITATIVE_COLUMN_LIST[i]].str.split(\"회\").str[0]\n","        \n","        transformed_df = pd.concat((transformed_df, self.categorical_df), axis=1)\n","        self.transformed_df = transformed_df.astype(int)\n","\n","    def get_data(self):\n","        if self.train:\n","            return self.transformed_df, self.data[self.TARGET_COLUMN]\n","    \n","        else:\n","            return self.transformed_df"]},{"cell_type":"markdown","metadata":{},"source":["## 4. LGBM"]},{"cell_type":"markdown","metadata":{},"source":["### 1) LGBM 데이터 - baseline_dataset"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["baseline_dataset = BaselineDataset()\n","baseline_dataset.set_data(train_df)\n","baseline_dataset.one_hot_encode()\n","X_lgbm, y_lgbm = baseline_dataset.get_data()"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[],"source":["baseline_dataset.set_train_mode(False)\n","baseline_dataset.set_data(test_df)\n","baseline_dataset.one_hot_encode()\n","X_test_lgbm = baseline_dataset.get_data()"]},{"cell_type":"markdown","metadata":{},"source":["### 2) 파라미터 최적화"]},{"cell_type":"markdown","id":"271f75df-299d-4103-ab69-7a5a1bd47cf0","metadata":{},"source":["※ 해당 부분은 최적 파라미터를 추출하는 코드이므로 주석 처리 되었습니다."]},{"cell_type":"code","execution_count":8,"id":"296aeeba-eced-4366-9381-9681c4f89369","metadata":{"trusted":true},"outputs":[],"source":["# import lightgbm as lgb\n","# from sklearn.model_selection import train_test_split\n","\n","# # 8:2 비율로 훈련 데이터, 검증 데이터 분리 (베이지안 최적화 수행용)\n","# X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n","#                                                       test_size=0.2, \n","#                                                       random_state=0)\n","\n","# # 베이지안 최적화용 데이터셋\n","# bayes_dtrain = lgb.Dataset(X_train, y_train)\n","# bayes_dvalid = lgb.Dataset(X_valid, y_valid)"]},{"cell_type":"code","execution_count":9,"id":"b0e0512a-865a-4ba3-b0bb-784c63edd657","metadata":{"trusted":true},"outputs":[],"source":["# # 베이지안 최적화를 위한 하이퍼파라미터 범위\n","# param_bounds = {\n","#     'num_leaves': (30, 100),  \n","#     'lambda_l1': (0, 1),  \n","#     'lambda_l2': (0, 2),  \n","#     'feature_fraction': (0.7, 1),  \n","#     'bagging_fraction': (0.5, 0.8),  \n","#     'min_child_samples': (5, 50),  \n","#     'min_child_weight': (25, 50)  \n","# }\n","\n","# # 값이 고정된 하이퍼파라미터\n","# fixed_params_lgbm = {'objective': 'binary', # binary classification\n","#                 'learning_rate': 0.005, # 0.01~0.001\n","#                 'bagging_freq': 1, # 0 or 1\n","#                 'force_row_wise': True,\n","#                 'random_state': 1991}"]},{"cell_type":"code","execution_count":10,"id":"8c4a31cd-70c7-4e9b-9a74-03da6a4e66cc","metadata":{"trusted":true},"outputs":[],"source":["# from sklearn.metrics import roc_auc_score\n","# from lightgbm import early_stopping\n","\n","# def eval_function(num_leaves, lambda_l1, lambda_l2, feature_fraction,\n","#                   bagging_fraction, min_child_samples, min_child_weight):\n","#     '''최적화하려는 평가지표 계산 함수'''\n","    \n","#     # 베이지안 최적화를 수행할 하이퍼파라미터 \n","#     params = {'num_leaves': int(round(num_leaves)),\n","#               'lambda_l1': lambda_l1,\n","#               'lambda_l2': lambda_l2,\n","#               'feature_fraction': feature_fraction,\n","#               'bagging_fraction': bagging_fraction,\n","#               'min_child_samples': int(round(min_child_samples)),\n","#               'min_child_weight': min_child_weight,\n","#               'feature_pre_filter': False}\n","#     # 고정된 하이퍼파라미터도 추가\n","#     params.update(fixed_params_lgbm)\n","    \n","#     print('하이퍼파라미터:', params)    \n","    \n","#     # LightGBM 모델 훈련\n","#     lgb_model = lgb.train(params=params, \n","#                            train_set=bayes_dtrain,\n","#                            num_boost_round=2500,\n","#                            valid_sets=bayes_dvalid,\n","#                            callbacks=[early_stopping(stopping_rounds=200)])\n","#     # 검증 데이터로 예측 수행\n","#     preds = lgb_model.predict(X_valid) \n","#     # roc-auc 계산\n","#     roc_auc = roc_auc_score(y_valid, preds)\n","#     print(f'roc-auc : {roc_auc}\\n')\n","    \n","#     return roc_auc"]},{"cell_type":"code","execution_count":11,"id":"c3fe100c-06bd-4408-8837-315dcdcbbc05","metadata":{"trusted":true},"outputs":[],"source":["# from bayes_opt import BayesianOptimization\n","\n","# # 베이지안 최적화 객체 생성\n","# optimizer = BayesianOptimization(f=eval_function,      # 평가지표 계산 함수\n","#                                  pbounds=param_bounds, # 하이퍼파라미터 범위\n","#                                  random_state=0)"]},{"cell_type":"code","execution_count":12,"id":"72496894-9355-4f58-aee1-a138328e79b9","metadata":{"trusted":true},"outputs":[],"source":["# # 베이지안 최적화 수행\n","# optimizer.maximize(init_points=15, n_iter=60)"]},{"cell_type":"code","execution_count":13,"id":"4a731da4-e6ec-421a-ae6a-0a3b500524a9","metadata":{"trusted":true},"outputs":[],"source":["# # 평가함수 점수가 최대일 때 하이퍼파라미터\n","# max_params_lgbm = optimizer.max['params']"]},{"cell_type":"code","execution_count":14,"id":"98aa3c06-6587-4c1c-9cf6-5aa6095f03d3","metadata":{"trusted":true},"outputs":[],"source":["# # 정수형 하이퍼파라미터 변환\n","# max_params_lgbm['num_leaves'] = int(round(max_params_lgbm['num_leaves']))\n","# max_params_lgbm['min_child_samples'] = int(round(max_params_lgbm['min_child_samples']))\n","\n","# # 값이 고정된 하이퍼파라미터 추가\n","# max_params_lgbm.update(fixed_params_lgbm)"]},{"cell_type":"code","execution_count":15,"id":"72de3066-3fcf-47f5-9bf6-82e8c0fe5827","metadata":{"trusted":true},"outputs":[],"source":["# max_params_lgbm"]},{"cell_type":"markdown","metadata":{},"source":["### 3) 층화 K-Fold 모델 학습 및 테스트 데이터 예측"]},{"cell_type":"code","execution_count":16,"metadata":{},"outputs":[],"source":["# lgbm roc auc score 계산 함수\n","def lgb_roc_auc(y_pred, dataset):\n","    y_true = dataset.get_label()\n","    return \"roc_auc\", roc_auc_score(y_true, y_pred), True  # (지표 이름, 값, 높은 값이 더 좋은지 여부)"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["max_params_lgbm = {\n","\t'bagging_fraction': 0.5863913416418778,\n","\t'feature_fraction': 0.9581372279421587,\n","\t'lambda_l1': 0.3465698371871525,\n","\t'lambda_l2': 1.839362361400739,\n","\t'min_child_samples': 49,\n","\t'min_child_weight': 41.152903682697854,\n","\t'num_leaves': 31,\n","\t'objective': 'binary',\n","\t'learning_rate': 0.005,\n","\t'bagging_freq': 1,\n","\t'force_row_wise': True,\n","\t'random_state': 1991\n"," }"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[],"source":["# 층화 K 폴드 교차 검증기\n","folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=1991)"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[],"source":["# OOF 방식으로 훈련된 모델로 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n","oof_val_preds_lgbm = np.zeros(X_lgbm.shape[0]) \n","# OOF 방식으로 훈련된 모델로 테스트 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n","oof_test_preds_lgbm = np.zeros(X_test_lgbm.shape[0])"]},{"cell_type":"code","execution_count":20,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["######################################## 폴드 1 / 폴드 10 ########################################\n","[LightGBM] [Info] Number of positive: 59605, number of negative: 171110\n","[LightGBM] [Info] Total Bins 883\n","[LightGBM] [Info] Number of data points in the train set: 230715, number of used features: 187\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258349 -> initscore=-1.054567\n","[LightGBM] [Info] Start training from score -1.054567\n","Training until validation scores don't improve for 200 rounds\n","Did not meet early stopping. Best iteration is:\n","[2389]\tvalid_0's binary_logloss: 0.487666\tvalid_0's roc_auc: 0.740225\n","폴드 1 roc-auc : 0.7402252385799368\n","\n","######################################## 폴드 2 / 폴드 10 ########################################\n","[LightGBM] [Info] Number of positive: 59606, number of negative: 171110\n","[LightGBM] [Info] Total Bins 884\n","[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 187\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258352 -> initscore=-1.054550\n","[LightGBM] [Info] Start training from score -1.054550\n","Training until validation scores don't improve for 200 rounds\n","Did not meet early stopping. Best iteration is:\n","[2358]\tvalid_0's binary_logloss: 0.487016\tvalid_0's roc_auc: 0.739779\n","폴드 2 roc-auc : 0.739778961581914\n","\n","######################################## 폴드 3 / 폴드 10 ########################################\n","[LightGBM] [Info] Number of positive: 59606, number of negative: 171110\n","[LightGBM] [Info] Total Bins 888\n","[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258352 -> initscore=-1.054550\n","[LightGBM] [Info] Start training from score -1.054550\n","Training until validation scores don't improve for 200 rounds\n","Did not meet early stopping. Best iteration is:\n","[2484]\tvalid_0's binary_logloss: 0.489732\tvalid_0's roc_auc: 0.734934\n","폴드 3 roc-auc : 0.7349336303509642\n","\n","######################################## 폴드 4 / 폴드 10 ########################################\n","[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n","[LightGBM] [Info] Total Bins 880\n","[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n","[LightGBM] [Info] Start training from score -1.054573\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[1943]\tvalid_0's binary_logloss: 0.488257\tvalid_0's roc_auc: 0.739376\n","폴드 4 roc-auc : 0.7393761877516332\n","\n","######################################## 폴드 5 / 폴드 10 ########################################\n","[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n","[LightGBM] [Info] Total Bins 887\n","[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n","[LightGBM] [Info] Start training from score -1.054573\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[1958]\tvalid_0's binary_logloss: 0.486852\tvalid_0's roc_auc: 0.742261\n","폴드 5 roc-auc : 0.7422605442039214\n","\n","######################################## 폴드 6 / 폴드 10 ########################################\n","[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n","[LightGBM] [Info] Total Bins 886\n","[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n","[LightGBM] [Info] Start training from score -1.054573\n","Training until validation scores don't improve for 200 rounds\n","Did not meet early stopping. Best iteration is:\n","[2310]\tvalid_0's binary_logloss: 0.489021\tvalid_0's roc_auc: 0.736742\n","폴드 6 roc-auc : 0.7367415166542621\n","\n","######################################## 폴드 7 / 폴드 10 ########################################\n","[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n","[LightGBM] [Info] Total Bins 886\n","[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n","[LightGBM] [Info] Start training from score -1.054573\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[1624]\tvalid_0's binary_logloss: 0.486388\tvalid_0's roc_auc: 0.744286\n","폴드 7 roc-auc : 0.7442860456164608\n","\n","######################################## 폴드 8 / 폴드 10 ########################################\n","[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n","[LightGBM] [Info] Total Bins 886\n","[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n","[LightGBM] [Info] Start training from score -1.054573\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[1513]\tvalid_0's binary_logloss: 0.488071\tvalid_0's roc_auc: 0.740538\n","폴드 8 roc-auc : 0.7405378069824635\n","\n","######################################## 폴드 9 / 폴드 10 ########################################\n","[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n","[LightGBM] [Info] Total Bins 882\n","[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n","[LightGBM] [Info] Start training from score -1.054573\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[1772]\tvalid_0's binary_logloss: 0.484757\tvalid_0's roc_auc: 0.745692\n","폴드 9 roc-auc : 0.7456924620412662\n","\n","######################################## 폴드 10 / 폴드 10 ########################################\n","[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n","[LightGBM] [Info] Total Bins 889\n","[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 186\n","[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n","[LightGBM] [Info] Start training from score -1.054573\n","Training until validation scores don't improve for 200 rounds\n","Early stopping, best iteration is:\n","[1978]\tvalid_0's binary_logloss: 0.487648\tvalid_0's roc_auc: 0.741565\n","폴드 10 roc-auc : 0.7415650831905429\n","\n"]}],"source":["# OOF 방식으로 모델 훈련, 검증, 예측\n","for idx, (train_idx, valid_idx) in enumerate(folds.split(X_lgbm, y_lgbm)):\n","    # 각 폴드를 구분하는 문구 출력\n","    print('#'*40, f'폴드 {idx+1} / 폴드 {folds.n_splits}', '#'*40)\n","\n","    # 데이터가 DataFrame인지 확인 후 인덱싱 방식 결정\n","    if isinstance(X_lgbm, pd.DataFrame):\n","        X_train, X_valid = X_lgbm.iloc[train_idx], X_lgbm.iloc[valid_idx]\n","    else:  # numpy.ndarray일 경우\n","        X_train, X_valid = X_lgbm[train_idx], X_lgbm[valid_idx]\n","\n","    y_train, y_valid = y_lgbm[train_idx], y_lgbm[valid_idx]\n","\n","    # LightGBM 전용 데이터셋 생성\n","    dtrain = lgb.Dataset(X_train, y_train) # LightGBM 전용 훈련 데이터셋\n","    dvalid = lgb.Dataset(X_valid, y_valid) # LightGBM 전용 검증 데이터셋\n","                          \n","    # LightGBM 모델 훈련\n","    lgb_model = lgb.train(params=max_params_lgbm,    # 최적 하이퍼파라미터\n","                          train_set=dtrain,     # 훈련 데이터셋\n","                          num_boost_round=2500, # 부스팅 반복 횟수\n","                          valid_sets=dvalid,    # 성능 평가용 검증 데이터셋\n","                          feval = lgb_roc_auc,\n","                          callbacks=[early_stopping(stopping_rounds=200)])\n","    \n","    # 테스트 데이터를 활용해 OOF 예측\n","    oof_test_preds_lgbm += lgb_model.predict(X_test_lgbm)/folds.n_splits\n","    # 모델 성능 평가를 위한 검증 데이터 타깃값 예측 \n","    oof_val_preds_lgbm[valid_idx] += lgb_model.predict(X_valid)\n","    \n","    # 검증 데이터 예측 확률에 대한 ROC-AUC\n","    roc_auc = roc_auc_score(y_valid, oof_val_preds_lgbm[valid_idx])\n","    print(f'폴드 {idx+1} roc-auc : {roc_auc}\\n')"]},{"cell_type":"markdown","metadata":{},"source":["### 4) 모델 평가"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["LGBM OOF 검증 데이터 ROC-AUC : 0.7404986919647052\n"]}],"source":["print('LGBM OOF 검증 데이터 ROC-AUC :', roc_auc_score(y_lgbm, oof_val_preds_lgbm))"]},{"cell_type":"markdown","id":"5d9165ff-a239-4886-b0b4-fda7bf29fcb3","metadata":{},"source":["## 5. CatBoost"]},{"cell_type":"markdown","id":"32a0b264-d42a-4bf1-9eba-b73d1c3a136d","metadata":{},"source":["### 1) CatBoost 데이터 - kiwi_dataset"]},{"cell_type":"code","execution_count":22,"id":"81a3ab35-0d8d-4dc2-88d5-52f523ee7be5","metadata":{"trusted":true},"outputs":[],"source":["kiwi_dataset = KiwiDataset()\n","kiwi_dataset.set_data(train_df)\n","kiwi_dataset.generate_dummy_variable()\n","kiwi_dataset.missing_value_imputation()\n","kiwi_dataset.transform_specific_procedure()\n","kiwi_dataset.transform_main_purpose()\n","kiwi_dataset.one_hot_encode()\n","kiwi_dataset.select_data()\n","X_cat, y_cat = kiwi_dataset.get_data()"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["kiwi_dataset.set_train_mode(False)\n","kiwi_dataset.set_data(test_df)\n","kiwi_dataset.generate_dummy_variable()\n","kiwi_dataset.missing_value_imputation()\n","kiwi_dataset.transform_specific_procedure()\n","kiwi_dataset.transform_main_purpose()\n","kiwi_dataset.one_hot_encode()\n","kiwi_dataset.select_data()\n","\n","X_test_cat = kiwi_dataset.get_data()"]},{"cell_type":"markdown","id":"ecba6c28-2aa7-45b9-b234-5ca9310e2cc8","metadata":{},"source":["### 2) 파라미터 최적화"]},{"cell_type":"markdown","id":"f73752d5-78da-4c78-9694-3cfd1a786e34","metadata":{},"source":["※ 해당 부분은 최적 파라미터를 추출하는 코드이므로 주석 처리 되었습니다."]},{"cell_type":"code","execution_count":24,"id":"3b843bbb-71e8-4565-8bc0-08ebca12a428","metadata":{"trusted":true},"outputs":[],"source":["# from catboost import CatBoostClassifier, Pool\n","# from sklearn.model_selection import train_test_split\n","\n","# # 8:2 비율로 훈련 데이터, 검증 데이터 분리 (베이지안 최적화 수행용)\n","# X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n","#                                                       test_size=0.2, \n","#                                                       random_state=0)\n","\n","# # CatBoost 전용 데이터셋\n","# bayes_dtrain = Pool(X_train, y_train, cat_features=None)\n","# bayes_dvalid = Pool(X_valid, y_valid, cat_features=None)"]},{"cell_type":"code","execution_count":25,"id":"3b67c0d0-1bd4-4c0d-ab5c-461f38a99a40","metadata":{"trusted":true},"outputs":[],"source":["# # 베이지안 최적화를 위한 하이퍼파라미터 범위\n","# param_bounds = {\n","#     'depth': (6, 10),\n","#     'learning_rate': (0.05, 0.1),\n","#     'l2_leaf_reg': (8, 10),\n","#     'bagging_temperature': (0.5, 1.0),\n","#     'border_count': (200, 255)\n","# }\n","\n","# # 고정된 하이퍼파라미터\n","# fixed_params_cat = {\n","#     'loss_function': 'Logloss',\n","#     'eval_metric': 'AUC',\n","#     'iterations': 2500,\n","#     'random_seed': 1991,\n","#     'verbose': 200\n","# }"]},{"cell_type":"code","execution_count":26,"id":"154508f4-0e23-460b-a911-93e0b28ce709","metadata":{"trusted":true},"outputs":[],"source":["# from sklearn.metrics import roc_auc_score\n","\n","# # 평가 함수 정의\n","# def eval_function(depth, learning_rate, l2_leaf_reg, bagging_temperature, border_count):\n","#     params = {\n","#         'depth': int(round(depth)),\n","#         'learning_rate': learning_rate,\n","#         'l2_leaf_reg': l2_leaf_reg,\n","#         'bagging_temperature': bagging_temperature,\n","#         'border_count': int(round(border_count))\n","#     }\n","    \n","#     params.update(fixed_params_cat)\n","#     print('하이퍼파라미터:', params)\n","    \n","#     # CatBoost 모델 훈련\n","#     cat_model = CatBoostClassifier(**params)\n","#     cat_model.fit(bayes_dtrain, \n","#                   eval_set=bayes_dvalid, \n","#                   early_stopping_rounds=200, \n","#                   verbose=0)\n","    \n","#     # 검증 데이터 예측\n","#     preds = cat_model.predict_proba(X_valid)[:, 1]\n","    \n","#     # ROC-AUC 계산\n","#     roc_auc = roc_auc_score(y_valid, preds)\n","#     print(f'ROC-AUC : {roc_auc}\\n')\n","    \n","#     return roc_auc"]},{"cell_type":"code","execution_count":27,"id":"7d3dbf9d-fd42-4e98-ae69-a25451b56370","metadata":{"trusted":true},"outputs":[],"source":["# from bayes_opt import BayesianOptimization\n","\n","# # 베이지안 최적화 객체 생성\n","# optimizer = BayesianOptimization(f=eval_function,      # 평가지표 계산 함수\n","#                                  pbounds=param_bounds, # 하이퍼파라미터 범위\n","#                                  random_state=0)"]},{"cell_type":"code","execution_count":28,"id":"da67a433-eb0a-4ca6-bc9a-1e835bff02ee","metadata":{"trusted":true},"outputs":[],"source":["# # 베이지안 최적화 수행\n","# optimizer.maximize(init_points=15, n_iter=60)"]},{"cell_type":"code","execution_count":29,"id":"a96515c4-8d4f-41a6-b528-64b715060f6c","metadata":{"trusted":true},"outputs":[],"source":["# max_params_cat = optimizer.max['params']\n","# max_params_cat['depth'] = int(round(max_params_cat['depth']))\n","# max_params_cat['border_count'] = int(round(max_params_cat['border_count']))\n","# max_params_cat.update(fixed_params_cat)"]},{"cell_type":"code","execution_count":30,"id":"05b237fd-59e0-4355-bd3a-b60d26893c09","metadata":{"trusted":true},"outputs":[],"source":["# max_params_cat"]},{"cell_type":"markdown","metadata":{},"source":["### 3) 층화 K-Fold 모델 학습 및 테스트 데이터 예측"]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[],"source":["max_params_cat = {\n","    'bagging_temperature': 0.6322778060523135,\n","    'border_count': 243,\n","    'depth': 8,\n","    'l2_leaf_reg': 9.136867897737297,\n","    'learning_rate': 0.05093949002181776,\n","    'loss_function': 'Logloss',\n","    'eval_metric': 'AUC',\n","    'iterations': 2500,\n","    'random_seed': 1991,\n","    'verbose': 200\n"," }"]},{"cell_type":"code","execution_count":32,"metadata":{},"outputs":[],"source":["# 층화 K 폴드 교차 검증기\n","folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=1991)"]},{"cell_type":"code","execution_count":33,"metadata":{},"outputs":[],"source":["oof_val_preds_cat = np.zeros(X_cat.shape[0]) \n","oof_test_preds_cat = np.zeros(X_test_cat.shape[0]) "]},{"cell_type":"code","execution_count":34,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["######################################## 폴드 1 / 폴드 10 ########################################\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\jun04\\AppData\\Local\\Temp\\ipykernel_32984\\1699458433.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n","  y_train, y_valid = y_cat[train_idx], y_cat[valid_idx]\n"]},{"name":"stdout","output_type":"stream","text":["0:\ttest: 0.7076247\tbest: 0.7076247 (0)\ttotal: 166ms\tremaining: 6m 54s\n","500:\ttest: 0.7400435\tbest: 0.7400682 (464)\ttotal: 7.36s\tremaining: 29.4s\n","Stopped by overfitting detector  (200 iterations wait)\n","\n","bestTest = 0.7401129161\n","bestIteration = 512\n","\n","Shrink model to first 513 iterations.\n","폴드 1 ROC-AUC : 0.7401129160583952\n","\n","######################################## 폴드 2 / 폴드 10 ########################################\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\jun04\\AppData\\Local\\Temp\\ipykernel_32984\\1699458433.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n","  y_train, y_valid = y_cat[train_idx], y_cat[valid_idx]\n"]},{"name":"stdout","output_type":"stream","text":["0:\ttest: 0.7164902\tbest: 0.7164902 (0)\ttotal: 17.3ms\tremaining: 43.3s\n","500:\ttest: 0.7390021\tbest: 0.7391402 (418)\ttotal: 7.51s\tremaining: 30s\n","Stopped by overfitting detector  (200 iterations wait)\n","\n","bestTest = 0.7391402254\n","bestIteration = 418\n","\n","Shrink model to first 419 iterations.\n","폴드 2 ROC-AUC : 0.7391402253617091\n","\n","######################################## 폴드 3 / 폴드 10 ########################################\n","0:\ttest: 0.7041943\tbest: 0.7041943 (0)\ttotal: 16.8ms\tremaining: 42s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\jun04\\AppData\\Local\\Temp\\ipykernel_32984\\1699458433.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n","  y_train, y_valid = y_cat[train_idx], y_cat[valid_idx]\n"]},{"name":"stdout","output_type":"stream","text":["500:\ttest: 0.7345699\tbest: 0.7347153 (441)\ttotal: 7.42s\tremaining: 29.6s\n","Stopped by overfitting detector  (200 iterations wait)\n","\n","bestTest = 0.7347183951\n","bestIteration = 606\n","\n","Shrink model to first 607 iterations.\n","폴드 3 ROC-AUC : 0.7347183950805218\n","\n","######################################## 폴드 4 / 폴드 10 ########################################\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\jun04\\AppData\\Local\\Temp\\ipykernel_32984\\1699458433.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n","  y_train, y_valid = y_cat[train_idx], y_cat[valid_idx]\n"]},{"name":"stdout","output_type":"stream","text":["0:\ttest: 0.7080247\tbest: 0.7080247 (0)\ttotal: 16.8ms\tremaining: 41.9s\n","Stopped by overfitting detector  (200 iterations wait)\n","\n","bestTest = 0.7386261469\n","bestIteration = 297\n","\n","Shrink model to first 298 iterations.\n","폴드 4 ROC-AUC : 0.7386261469070974\n","\n","######################################## 폴드 5 / 폴드 10 ########################################\n","0:\ttest: 0.7212343\tbest: 0.7212343 (0)\ttotal: 16.8ms\tremaining: 41.9s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\jun04\\AppData\\Local\\Temp\\ipykernel_32984\\1699458433.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n","  y_train, y_valid = y_cat[train_idx], y_cat[valid_idx]\n"]},{"name":"stdout","output_type":"stream","text":["500:\ttest: 0.7417388\tbest: 0.7418784 (390)\ttotal: 8.01s\tremaining: 32s\n","Stopped by overfitting detector  (200 iterations wait)\n","\n","bestTest = 0.7418783702\n","bestIteration = 390\n","\n","Shrink model to first 391 iterations.\n","폴드 5 ROC-AUC : 0.7418783702301198\n","\n","######################################## 폴드 6 / 폴드 10 ########################################\n","0:\ttest: 0.7137358\tbest: 0.7137358 (0)\ttotal: 17.5ms\tremaining: 43.7s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\jun04\\AppData\\Local\\Temp\\ipykernel_32984\\1699458433.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n","  y_train, y_valid = y_cat[train_idx], y_cat[valid_idx]\n"]},{"name":"stdout","output_type":"stream","text":["500:\ttest: 0.7353946\tbest: 0.7354862 (486)\ttotal: 8s\tremaining: 31.9s\n","Stopped by overfitting detector  (200 iterations wait)\n","\n","bestTest = 0.7354861805\n","bestIteration = 486\n","\n","Shrink model to first 487 iterations.\n","폴드 6 ROC-AUC : 0.7354861805376447\n","\n","######################################## 폴드 7 / 폴드 10 ########################################\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\jun04\\AppData\\Local\\Temp\\ipykernel_32984\\1699458433.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n","  y_train, y_valid = y_cat[train_idx], y_cat[valid_idx]\n"]},{"name":"stdout","output_type":"stream","text":["0:\ttest: 0.7136191\tbest: 0.7136191 (0)\ttotal: 17ms\tremaining: 42.4s\n","500:\ttest: 0.7435441\tbest: 0.7437801 (411)\ttotal: 8.07s\tremaining: 32.2s\n","Stopped by overfitting detector  (200 iterations wait)\n","\n","bestTest = 0.7437801388\n","bestIteration = 411\n","\n","Shrink model to first 412 iterations.\n","폴드 7 ROC-AUC : 0.7437801388279006\n","\n","######################################## 폴드 8 / 폴드 10 ########################################\n","0:\ttest: 0.7205828\tbest: 0.7205828 (0)\ttotal: 18ms\tremaining: 45.1s\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\jun04\\AppData\\Local\\Temp\\ipykernel_32984\\1699458433.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n","  y_train, y_valid = y_cat[train_idx], y_cat[valid_idx]\n"]},{"name":"stdout","output_type":"stream","text":["500:\ttest: 0.7404301\tbest: 0.7405930 (470)\ttotal: 8.23s\tremaining: 32.8s\n","Stopped by overfitting detector  (200 iterations wait)\n","\n","bestTest = 0.7405929507\n","bestIteration = 470\n","\n","Shrink model to first 471 iterations.\n","폴드 8 ROC-AUC : 0.7405929506794646\n","\n","######################################## 폴드 9 / 폴드 10 ########################################\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\jun04\\AppData\\Local\\Temp\\ipykernel_32984\\1699458433.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n","  y_train, y_valid = y_cat[train_idx], y_cat[valid_idx]\n"]},{"name":"stdout","output_type":"stream","text":["0:\ttest: 0.7286846\tbest: 0.7286846 (0)\ttotal: 18.7ms\tremaining: 46.7s\n","Stopped by overfitting detector  (200 iterations wait)\n","\n","bestTest = 0.744791603\n","bestIteration = 287\n","\n","Shrink model to first 288 iterations.\n","폴드 9 ROC-AUC : 0.7447916029670334\n","\n","######################################## 폴드 10 / 폴드 10 ########################################\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\jun04\\AppData\\Local\\Temp\\ipykernel_32984\\1699458433.py:10: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n","  y_train, y_valid = y_cat[train_idx], y_cat[valid_idx]\n"]},{"name":"stdout","output_type":"stream","text":["0:\ttest: 0.7225677\tbest: 0.7225677 (0)\ttotal: 18.2ms\tremaining: 45.6s\n","500:\ttest: 0.7407621\tbest: 0.7409408 (423)\ttotal: 8.26s\tremaining: 33s\n","Stopped by overfitting detector  (200 iterations wait)\n","\n","bestTest = 0.7409407566\n","bestIteration = 423\n","\n","Shrink model to first 424 iterations.\n","폴드 10 ROC-AUC : 0.7409407566329922\n","\n"]}],"source":["for idx, (train_idx, valid_idx) in enumerate(folds.split(X_cat, y_cat)):\n","    print('#'*40, f'폴드 {idx+1} / 폴드 {folds.n_splits}', '#'*40)\n","    \n","    # 데이터가 DataFrame인지 확인 후 인덱싱 방식 결정\n","    if isinstance(X_cat, pd.DataFrame):\n","        X_train, X_valid = X_cat.iloc[train_idx], X_cat.iloc[valid_idx]\n","    else:  # numpy.ndarray일 경우\n","        X_train, X_valid = X_cat[train_idx], X_cat[valid_idx]\n","\n","    y_train, y_valid = y_cat[train_idx], y_cat[valid_idx]\n","    \n","    dtrain = Pool(X_train, y_train, cat_features=None)\n","    dvalid = Pool(X_valid, y_valid, cat_features=None)\n","    \n","    cat_model = CatBoostClassifier(**max_params_cat)\n","    cat_model.fit(dtrain, eval_set=dvalid, early_stopping_rounds=200, verbose=500)\n","    \n","    # 테스트 데이터 예측\n","    oof_test_preds_cat += cat_model.predict_proba(X_test_cat)[:, 1] / folds.n_splits\n","    # 검증 데이터 예측\n","    oof_val_preds_cat[valid_idx] += cat_model.predict_proba(X_valid)[:, 1]\n","    \n","    # 검증 데이터 ROC-AUC 계산\n","    roc_auc = roc_auc_score(y_valid, oof_val_preds_cat[valid_idx])\n","    print(f'폴드 {idx+1} ROC-AUC : {roc_auc}\\n')"]},{"cell_type":"markdown","metadata":{},"source":["### 4) 모델 평가"]},{"cell_type":"code","execution_count":35,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["CatBoost OOF 검증 데이터 ROC-AUC : 0.7399695623163609\n"]}],"source":["print('CatBoost OOF 검증 데이터 ROC-AUC :', roc_auc_score(y_cat, oof_val_preds_cat))"]},{"cell_type":"markdown","metadata":{},"source":["## 6. Neural Network"]},{"cell_type":"markdown","metadata":{},"source":["### 1) NN 모델 데이터 - kiwi_dataset"]},{"cell_type":"code","execution_count":36,"metadata":{},"outputs":[],"source":["kiwi_dataset = KiwiDataset()\n","kiwi_dataset.set_data(train_df)\n","kiwi_dataset.generate_dummy_variable()\n","kiwi_dataset.missing_value_imputation()\n","kiwi_dataset.transform_specific_procedure()\n","kiwi_dataset.transform_main_purpose()\n","kiwi_dataset.one_hot_encode()\n","kiwi_dataset.select_data()\n","X_nn, y_nn = kiwi_dataset.get_data()"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[],"source":["kiwi_dataset.set_train_mode(False)\n","kiwi_dataset.set_data(test_df)\n","kiwi_dataset.generate_dummy_variable()\n","kiwi_dataset.missing_value_imputation()\n","kiwi_dataset.transform_specific_procedure()\n","kiwi_dataset.transform_main_purpose()\n","kiwi_dataset.one_hot_encode()\n","kiwi_dataset.select_data()\n","\n","X_test_nn = kiwi_dataset.get_data()"]},{"cell_type":"code","execution_count":38,"metadata":{},"outputs":[],"source":["# 데이터 변환\n","X_tensor = np.array(X_nn) \n","y_tensor = np.array(y_nn).astype(int)\n","\n","X_test_tensor = np.array(X_test_nn)"]},{"cell_type":"code","execution_count":39,"metadata":{},"outputs":[],"source":["# PyTorch Dataset 생성\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, X, y=None):\n","        self.X = torch.tensor(X, dtype=torch.float32)\n","        self.y = torch.tensor(y, dtype=torch.float32) if y is not None else None\n","\n","    def __len__(self):\n","        return len(self.X)\n","\n","    def __getitem__(self, idx):\n","        if self.y is not None:\n","            return self.X[idx], self.y[idx]\n","        return self.X[idx]"]},{"cell_type":"markdown","metadata":{},"source":["### 2) 모델 구축"]},{"cell_type":"code","execution_count":40,"metadata":{},"outputs":[],"source":["class NeuralNetwork(nn.Module):\n","    def __init__(self, input_dim):\n","        super(NeuralNetwork, self).__init__()\n","        self.model = nn.Sequential(\n","            nn.Linear(input_dim, 512),\n","            nn.BatchNorm1d(512),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),  # Dropout 증가\n","            \n","            nn.Linear(512, 256),\n","            nn.BatchNorm1d(256),\n","            nn.ReLU(),\n","            nn.Dropout(0.5),\n","\n","            nn.Linear(256, 128),\n","            nn.BatchNorm1d(128),\n","            nn.ReLU(),\n","            \n","            nn.Linear(128, 1),  # 이진 분류: 출력층은 1개 뉴런\n","            nn.Sigmoid()        # 이진 분류 확률 출력\n","        )\n","        \n","    def forward(self, x):  \n","        return self.model(x)"]},{"cell_type":"markdown","metadata":{},"source":["### 3) 층화 K-Fold 모델 학습 및 테스트 데이터 예측"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Using device: cuda\n"]}],"source":["# GPU 사용 여부 확인\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","print(f\"Using device: {device}\")"]},{"cell_type":"code","execution_count":42,"metadata":{},"outputs":[],"source":["# K-Fold 설정\n","n_splits = 10\n","folds = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=1991)"]},{"cell_type":"code","execution_count":43,"metadata":{},"outputs":[],"source":["# OOF 예측 저장용\n","oof_val_preds_nn = np.zeros(X_tensor.shape[0])\n","oof_test_preds_nn = np.zeros(X_test_tensor.shape[0])"]},{"cell_type":"code","execution_count":44,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","#### Fold 1/10 ####\n","Epoch 1: Train Loss = 0.5546261921393133, Valid Loss = 0.5241704743642074, AUC = 0.706672419172276, LR = 0.00012071061595315047\n","Epoch 10: Train Loss = 0.49386398784354724, Valid Loss = 0.4913685115484091, AUC = 0.7329642435181809, LR = 0.0001904848026045092\n","Epoch 20: Train Loss = 0.4903081851986657, Valid Loss = 0.48922450038102955, AUC = 0.7360884518891964, LR = 0.0003950390612538755\n","Epoch 30: Train Loss = 0.4889277734060203, Valid Loss = 0.48879584670066833, AUC = 0.7372055582907786, LR = 0.000713637822416415\n","Epoch 40: Train Loss = 0.4883318481455862, Valid Loss = 0.48901418309945327, AUC = 0.7371396966651845, LR = 0.0011150916822163179\n","Epoch 50: Train Loss = 0.48777688077065795, Valid Loss = 0.4883568493219522, AUC = 0.7375974323821239, LR = 0.0015601000905663418\n","Epoch 60: Train Loss = 0.4870769601743833, Valid Loss = 0.4887784249507464, AUC = 0.7374017732838675, LR = 0.0020050987004944063\n","Early stopping at epoch 66\n","Best iteration: [46]  Valid Loss: 0.48765694751189304  AUC: 0.7387850461018276\n","Fold 1 Valid Preds Min/Max: 5.456874774267817e-08, 0.6913397908210754\n","Fold 1 Valid AUC: 0.7373849018757075\n","\n","#### Fold 2/10 ####\n","Epoch 1: Train Loss = 0.5580453612899359, Valid Loss = 0.5381170809268951, AUC = 0.7079292843601597, LR = 0.00012071061595315047\n","Epoch 10: Train Loss = 0.49431152180232835, Valid Loss = 0.49912120745732236, AUC = 0.7348856692387251, LR = 0.0001904848026045092\n","Epoch 20: Train Loss = 0.4907127633295228, Valid Loss = 0.49686592473433566, AUC = 0.7371992796167075, LR = 0.0003950390612538755\n","Epoch 30: Train Loss = 0.4891731141679055, Valid Loss = 0.49661923486452836, AUC = 0.7376005493578659, LR = 0.000713637822416415\n","Epoch 40: Train Loss = 0.4883714165307779, Valid Loss = 0.4970927926210257, AUC = 0.7372017735786589, LR = 0.0011150916822163179\n","Epoch 50: Train Loss = 0.4875577214808591, Valid Loss = 0.4959532538285622, AUC = 0.7387533951836956, LR = 0.0015601000905663418\n","Early stopping at epoch 53\n","Best iteration: [33]  Valid Loss: 0.49589291788064516  AUC: 0.7391640689087723\n","Fold 2 Valid Preds Min/Max: 7.346213237724442e-07, 0.6634270548820496\n","Fold 2 Valid AUC: 0.7381499000755225\n","\n","#### Fold 3/10 ####\n","Epoch 1: Train Loss = 0.5574814079873329, Valid Loss = 0.5315606548235967, AUC = 0.7007373811521891, LR = 0.00012071061595315047\n","Epoch 10: Train Loss = 0.4939277579562854, Valid Loss = 0.49440491657990676, AUC = 0.7266527950490821, LR = 0.0001904848026045092\n","Epoch 20: Train Loss = 0.4902293117700425, Valid Loss = 0.4923238628185712, AUC = 0.7295128729976246, LR = 0.0003950390612538755\n","Epoch 30: Train Loss = 0.48874410578107413, Valid Loss = 0.4911657331081537, AUC = 0.7309950687382775, LR = 0.000713637822416415\n","Epoch 40: Train Loss = 0.4878899547378574, Valid Loss = 0.49052234337880063, AUC = 0.7319523887413788, LR = 0.0011150916822163179\n","Epoch 50: Train Loss = 0.48739670269784674, Valid Loss = 0.49099982587190777, AUC = 0.7318526938037578, LR = 0.0015601000905663418\n","Epoch 60: Train Loss = 0.4868241251833671, Valid Loss = 0.4930197298526764, AUC = 0.7307248471665964, LR = 0.0020050987004944063\n","Epoch 70: Train Loss = 0.4857567325893757, Valid Loss = 0.4911514463332983, AUC = 0.7317875648610801, LR = 0.002406524124250426\n","Epoch 80: Train Loss = 0.48510664160800193, Valid Loss = 0.49124478147580075, AUC = 0.7318534840878794, LR = 0.0027250785955095754\n","Early stopping at epoch 82\n","Best iteration: [62]  Valid Loss: 0.4903250359571897  AUC: 0.7327135078046634\n","Fold 3 Valid Preds Min/Max: 3.39552599371018e-07, 0.6796019077301025\n","Fold 3 Valid AUC: 0.7314461025514294\n","\n","#### Fold 4/10 ####\n","Epoch 1: Train Loss = 0.5972202077376104, Valid Loss = 0.544433071063115, AUC = 0.7040225061571768, LR = 0.00012071061595315047\n","Epoch 10: Train Loss = 0.49390155907753297, Valid Loss = 0.493850432909452, AUC = 0.7336737211419417, LR = 0.0001904848026045092\n","Epoch 20: Train Loss = 0.49032868062500407, Valid Loss = 0.492608259503658, AUC = 0.7357748242573117, LR = 0.0003950390612538755\n","Epoch 30: Train Loss = 0.4886776909100271, Valid Loss = 0.49188745480317336, AUC = 0.736818524050816, LR = 0.000713637822416415\n","Epoch 40: Train Loss = 0.48798739092539895, Valid Loss = 0.49248963250563693, AUC = 0.7362471651446154, LR = 0.0011150916822163179\n","Epoch 50: Train Loss = 0.4873544050265202, Valid Loss = 0.49285300649129427, AUC = 0.7363856934814472, LR = 0.0015601000905663418\n","Epoch 60: Train Loss = 0.4865519929248675, Valid Loss = 0.4921429890852708, AUC = 0.7370395951995987, LR = 0.0020050987004944063\n","Epoch 70: Train Loss = 0.4860661517729801, Valid Loss = 0.49252023834448594, AUC = 0.7367253988270764, LR = 0.002406524124250426\n","Epoch 80: Train Loss = 0.48524856989362597, Valid Loss = 0.4924085449713927, AUC = 0.7366611737132795, LR = 0.0027250785955095754\n","Epoch 90: Train Loss = 0.48358603929523875, Valid Loss = 0.49215515989523667, AUC = 0.7367386218782044, LR = 0.0029295770461809033\n","Epoch 100: Train Loss = 0.48263751220914114, Valid Loss = 0.49206327016537005, AUC = 0.7370950446548392, LR = 0.0029999999998210807\n","Early stopping at epoch 107\n","Best iteration: [87]  Valid Loss: 0.4914560936964475  AUC: 0.7381500019107905\n","Fold 4 Valid Preds Min/Max: 2.7840956207114687e-09, 0.7739266753196716\n","Fold 4 Valid AUC: 0.7362310195212262\n","\n","#### Fold 5/10 ####\n","Epoch 1: Train Loss = 0.5395920363675176, Valid Loss = 0.5202807784080505, AUC = 0.7141827372932514, LR = 0.00012071061595315047\n","Epoch 10: Train Loss = 0.4942561639884932, Valid Loss = 0.48947359965397763, AUC = 0.7348664443245696, LR = 0.0001904848026045092\n","Epoch 20: Train Loss = 0.49056270771321997, Valid Loss = 0.48528789900816405, AUC = 0.7384870308791043, LR = 0.0003950390612538755\n","Epoch 30: Train Loss = 0.4891932766258189, Valid Loss = 0.4844198524951935, AUC = 0.7397124622515643, LR = 0.000713637822416415\n","Epoch 40: Train Loss = 0.4881121414688836, Valid Loss = 0.48418016502490413, AUC = 0.7400290570393663, LR = 0.0011150916822163179\n","Epoch 50: Train Loss = 0.4874936153667163, Valid Loss = 0.4852144087736423, AUC = 0.7390042785187223, LR = 0.0015601000905663418\n","Epoch 60: Train Loss = 0.4868682285325717, Valid Loss = 0.4843704390984315, AUC = 0.7393478912163965, LR = 0.0020050987004944063\n","Epoch 70: Train Loss = 0.4862169521836053, Valid Loss = 0.4859577738321744, AUC = 0.7379612577467622, LR = 0.002406524124250426\n","Epoch 80: Train Loss = 0.4853761233059706, Valid Loss = 0.48444753082898945, AUC = 0.7388984861679262, LR = 0.0027250785955095754\n","Epoch 90: Train Loss = 0.4841579122353444, Valid Loss = 0.48411159446606267, AUC = 0.739683570083394, LR = 0.0029295770461809033\n","Early stopping at epoch 97\n","Best iteration: [77]  Valid Loss: 0.48348331107543063  AUC: 0.7403627941429999\n","Fold 5 Valid Preds Min/Max: 1.4149696969667502e-09, 0.7999876141548157\n","Fold 5 Valid AUC: 0.7387162621990786\n","\n","#### Fold 6/10 ####\n","Epoch 1: Train Loss = 0.5672255946999103, Valid Loss = 0.5351075449815164, AUC = 0.7049715479648588, LR = 0.00012071061595315047\n","Epoch 10: Train Loss = 0.4937958275586103, Valid Loss = 0.49179676977487713, AUC = 0.7300657898018048, LR = 0.0001904848026045092\n","Epoch 20: Train Loss = 0.4900468946558184, Valid Loss = 0.4884047301915976, AUC = 0.7332703545483594, LR = 0.0003950390612538755\n","Epoch 30: Train Loss = 0.48866692712876647, Valid Loss = 0.4874975108183347, AUC = 0.7345794485226859, LR = 0.000713637822416415\n","Epoch 40: Train Loss = 0.487831735505467, Valid Loss = 0.4893457545683934, AUC = 0.7337580230564903, LR = 0.0011150916822163179\n","Epoch 50: Train Loss = 0.48714418102682167, Valid Loss = 0.4885603498954039, AUC = 0.7335710379950595, LR = 0.0015601000905663418\n","Early stopping at epoch 59\n","Best iteration: [39]  Valid Loss: 0.4874975108183347  AUC: 0.7351904289316356\n","Fold 6 Valid Preds Min/Max: 1.7226025050831595e-08, 0.6575654149055481\n","Fold 6 Valid AUC: 0.7337853228992844\n","\n","#### Fold 7/10 ####\n","Epoch 1: Train Loss = 0.5607502951031238, Valid Loss = 0.5344943404197693, AUC = 0.7084985447019658, LR = 0.00012071061595315047\n","Epoch 10: Train Loss = 0.4946306317517188, Valid Loss = 0.4912442324253229, AUC = 0.7386747823215765, LR = 0.0001904848026045092\n","Epoch 20: Train Loss = 0.4906048838016206, Valid Loss = 0.48847232873623186, AUC = 0.7427827792766373, LR = 0.0003950390612538755\n","Epoch 30: Train Loss = 0.48901802802507854, Valid Loss = 0.48805568997676557, AUC = 0.7424769892702524, LR = 0.000713637822416415\n","Epoch 40: Train Loss = 0.4882178797131091, Valid Loss = 0.487970232963562, AUC = 0.7432259897425973, LR = 0.0011150916822163179\n","Epoch 50: Train Loss = 0.4876119697515943, Valid Loss = 0.48819032082190883, AUC = 0.7434405089291095, LR = 0.0015601000905663418\n","Early stopping at epoch 56\n","Best iteration: [36]  Valid Loss: 0.48731806988899523  AUC: 0.7436978858906439\n","Fold 7 Valid Preds Min/Max: 6.328311030756595e-08, 0.6619570255279541\n","Fold 7 Valid AUC: 0.7407885247677993\n","\n","#### Fold 8/10 ####\n","Epoch 1: Train Loss = 0.556083686188259, Valid Loss = 0.5281583896050086, AUC = 0.711648065023675, LR = 0.00012071061595315047\n","Epoch 10: Train Loss = 0.4938292574566022, Valid Loss = 0.4957050050680454, AUC = 0.7353873729757177, LR = 0.0001904848026045092\n","Epoch 20: Train Loss = 0.4900617694432757, Valid Loss = 0.49431587297182816, AUC = 0.7381527894729201, LR = 0.0003950390612538755\n","Epoch 30: Train Loss = 0.4891809354313707, Valid Loss = 0.4935840723606256, AUC = 0.7383866627588911, LR = 0.000713637822416415\n","Epoch 40: Train Loss = 0.4881604878248367, Valid Loss = 0.4941027680268654, AUC = 0.738601745811247, LR = 0.0011150916822163179\n","Epoch 50: Train Loss = 0.48761425648642853, Valid Loss = 0.4937059088395192, AUC = 0.7386031673885156, LR = 0.0015601000905663418\n","Epoch 60: Train Loss = 0.48676162852650195, Valid Loss = 0.4940365037092796, AUC = 0.7385216292107794, LR = 0.0020050987004944063\n","Early stopping at epoch 61\n","Best iteration: [41]  Valid Loss: 0.49318716388482314  AUC: 0.7392619810929271\n","Fold 8 Valid Preds Min/Max: 3.156592640607414e-07, 0.6494520902633667\n","Fold 8 Valid AUC: 0.7378384223522901\n","\n","#### Fold 9/10 ####\n","Epoch 1: Train Loss = 0.601555451882624, Valid Loss = 0.5501212156735934, AUC = 0.7046679816547599, LR = 0.00012071061595315047\n","Epoch 10: Train Loss = 0.4940851504823803, Valid Loss = 0.4985368045476767, AUC = 0.7373472912313715, LR = 0.0001904848026045092\n","Epoch 20: Train Loss = 0.4907022044721958, Valid Loss = 0.49584771348879886, AUC = 0.7420074240324197, LR = 0.0003950390612538755\n","Epoch 30: Train Loss = 0.4894057957999474, Valid Loss = 0.4949975781715833, AUC = 0.7427832279867808, LR = 0.000713637822416415\n","Epoch 40: Train Loss = 0.4887793461042168, Valid Loss = 0.4949126002880243, AUC = 0.7430019602835772, LR = 0.0011150916822163179\n","Epoch 50: Train Loss = 0.4880438495790009, Valid Loss = 0.49494480513609374, AUC = 0.7424945564709101, LR = 0.0015601000905663418\n","Epoch 60: Train Loss = 0.4874119291790819, Valid Loss = 0.4952997462107585, AUC = 0.7431121245801067, LR = 0.0020050987004944063\n","Epoch 70: Train Loss = 0.48651536798055195, Valid Loss = 0.4951978153907336, AUC = 0.7425799066994219, LR = 0.002406524124250426\n","Epoch 80: Train Loss = 0.48580501116482555, Valid Loss = 0.4956338760944513, AUC = 0.7434332580908634, LR = 0.0027250785955095754\n","Early stopping at epoch 85\n","Best iteration: [65]  Valid Loss: 0.4945617856887671  AUC: 0.7442121633073657\n","Fold 9 Valid Preds Min/Max: 4.603094350130732e-09, 0.656012237071991\n","Fold 9 Valid AUC: 0.742841254547181\n","\n","#### Fold 10/10 ####\n","Epoch 1: Train Loss = 0.5627238942986041, Valid Loss = 0.5235926107718394, AUC = 0.7138155057643132, LR = 0.00012071061595315047\n","Epoch 10: Train Loss = 0.4938136198088131, Valid Loss = 0.4904755915586765, AUC = 0.7345321155588884, LR = 0.0001904848026045092\n","Epoch 20: Train Loss = 0.49060227464785616, Valid Loss = 0.4868320513230104, AUC = 0.7380040599293773, LR = 0.0003950390612538755\n","Epoch 30: Train Loss = 0.4888823065346321, Valid Loss = 0.48656527812664324, AUC = 0.7391779214024383, LR = 0.000713637822416415\n","Epoch 40: Train Loss = 0.48816407702665415, Valid Loss = 0.48743365705013275, AUC = 0.7384566734539172, LR = 0.0011150916822163179\n","Epoch 50: Train Loss = 0.48743720088912323, Valid Loss = 0.4865877009355105, AUC = 0.7390204439965425, LR = 0.0015601000905663418\n","Early stopping at epoch 55\n","Best iteration: [35]  Valid Loss: 0.48623685653393084  AUC: 0.7394478344517839\n","Fold 10 Valid Preds Min/Max: 7.287022896207418e-08, 0.6324443817138672\n","Fold 10 Valid AUC: 0.7384390943406008\n"]}],"source":["# K-Fold 훈련\n","for fold_idx, (train_idx, valid_idx) in enumerate(folds.split(X_tensor, y_tensor)):\n","    print(f\"\\n#### Fold {fold_idx+1}/{n_splits} ####\")\n","\n","    # 훈련/검증 데이터 설정\n","    X_train, y_train = X_tensor[train_idx], y_tensor[train_idx]\n","    X_valid, y_valid = X_tensor[valid_idx], y_tensor[valid_idx]\n","\n","    # NaN 값 0으로 채우기 (필요하면 평균값으로 대체 가능)\n","    X_train = np.nan_to_num(X_train, nan=0.0)\n","    X_valid = np.nan_to_num(X_valid, nan=0.0)\n","\n","    train_dataset = CustomDataset(X_train, y_train)\n","    valid_dataset = CustomDataset(X_valid, y_valid)\n","    \n","    train_loader = DataLoader(train_dataset, batch_size=1024, shuffle=True)\n","    valid_loader = DataLoader(valid_dataset, batch_size=1024, shuffle=False)\n","\n","    # 모델 초기화\n","    model = NeuralNetwork(input_dim=X_train.shape[1]).to(device)\n","\n","    # 최적화 알고리즘 & 스케줄러 설정\n","    optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n","\n","    # `total_steps`를 정확하게 설정해야 ValueError 방지 가능!\n","    total_steps = len(train_loader) * 1000\n","    scheduler = OneCycleLR(optimizer, max_lr=0.003, total_steps=total_steps, pct_start=0.1)\n","\n","    criterion = nn.BCELoss()  \n","    best_auc = 0.0  # AUC 기준 Early Stopping\n","\n","    # Early Stopping 설정\n","    best_valid_loss = np.inf\n","    patience, patience_counter = 20, 0\n","\n","    # 학습 진행\n","    for epoch in range(1000):\n","        model.train()\n","        train_loss = 0.0\n","\n","        for X_batch, y_batch in train_loader:  \n","            X_batch, y_batch = X_batch.to(device), y_batch.to(device).unsqueeze(1)\n","    \n","            optimizer.zero_grad()\n","            preds = model(X_batch)\n","    \n","            loss = criterion(preds, y_batch)  # Loss 계산\n","            loss.backward()  # 역전파\n","            optimizer.step()  # 가중치 업데이트\n","    \n","            train_loss += loss.item()\n","            scheduler.step() # lr update\n","\n","        # 검증 데이터 평가\n","        model.eval()\n","        valid_loss, valid_preds = 0.0, []\n","        with torch.no_grad():\n","            for X_batch, y_batch in valid_loader:\n","                X_batch, y_batch = X_batch.to(device), y_batch.to(device).unsqueeze(1)\n","                preds = model(X_batch)\n","                loss = criterion(preds, y_batch)\n","                valid_loss += loss.item()\n","                valid_preds.extend(preds.cpu().numpy())\n","\n","        valid_loss /= len(valid_loader)\n","        train_loss /= len(train_loader)\n","        roc_auc = roc_auc_score(y_valid, np.array(valid_preds).flatten())\n","\n","        # 10 에폭마다 출력 (첫 에폭 포함)\n","        if (epoch + 1) % 10 == 0 or epoch == 0:\n","            current_lr = optimizer.param_groups[0]['lr']  # 현재 Learning Rate 확인\n","            print(f\"Epoch {epoch+1}: Train Loss = {train_loss}, Valid Loss = {valid_loss:}, AUC = {roc_auc}, LR = {current_lr}\")\n","\n","        # AUC & Loss 기준 Best Model 저장\n","        if roc_auc > best_auc or valid_loss < best_valid_loss:\n","            best_auc = max(best_auc, roc_auc)\n","            best_valid_loss = min(best_valid_loss, valid_loss)\n","            patience_counter = 0\n","            best_model_state = model.state_dict()\n","            best_iteration = epoch + 1  # Best Iteration 저장\n","        else:\n","            patience_counter += 1\n","\n","        # Early Stopping\n","        if patience_counter >= patience:\n","            print(f\"Early stopping at epoch {epoch+1}\")\n","            print(f\"Best iteration: [{best_iteration}]  Valid Loss: {best_valid_loss}  AUC: {best_auc}\")\n","            break\n","\n","    # 최적 모델 로드\n","    model.load_state_dict(best_model_state)\n","\n","    # 검증 데이터 예측 저장\n","    model.eval()\n","    valid_preds = []\n","    with torch.no_grad():\n","        for X_batch in valid_loader:\n","            X_batch = X_batch[0].to(device)  \n","            preds = model(X_batch)\n","            valid_preds.extend(preds.cpu().numpy())\n","\n","    valid_preds = np.array(valid_preds).flatten()\n","    \n","    print(f\"Fold {fold_idx+1} Valid Preds Min/Max: {valid_preds.min()}, {valid_preds.max()}\")\n","    print(f\"Fold {fold_idx+1} Valid AUC: {roc_auc_score(y_valid, valid_preds)}\")\n","\n","    # OOF 예측 저장\n","    oof_val_preds_nn[valid_idx] = valid_preds\n","\n","    # 테스트 데이터 예측 저장\n","    test_dataset = CustomDataset(X_test_tensor)\n","    test_loader = DataLoader(test_dataset, batch_size=1024, shuffle=False)\n","\n","    test_preds = []\n","    with torch.no_grad():\n","        for X_batch in test_loader:\n","            X_batch = X_batch.to(device)\n","            preds = model(X_batch)\n","            test_preds.extend(preds.cpu().numpy())\n","\n","    oof_test_preds_nn += np.array(test_preds).flatten() / n_splits"]},{"cell_type":"markdown","metadata":{},"source":["### 4) 모델 평가"]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["NN OOF 검증 데이터 ROC-AUC : 0.7371480163680295\n"]}],"source":["print('NN OOF 검증 데이터 ROC-AUC :', roc_auc_score(y_tensor, oof_val_preds_nn))"]},{"cell_type":"markdown","metadata":{},"source":["## 7. 앙상블"]},{"cell_type":"markdown","metadata":{},"source":["### 1) 앙상블 모델 평가"]},{"cell_type":"code","execution_count":48,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["앙상블 OOF 검증 데이터 ROC-AUC : 0.7407225517194111\n"]}],"source":["ensemble_val_preds = oof_val_preds_lgbm * 0.6 + oof_val_preds_cat * 0.25 + oof_val_preds_nn * 0.15\n","\n","print('앙상블 OOF 검증 데이터 ROC-AUC :',  roc_auc_score(y_cat, ensemble_val_preds))"]},{"cell_type":"markdown","metadata":{},"source":["### 2) 테스트 데이터 앙상블 예측"]},{"cell_type":"code","execution_count":49,"metadata":{},"outputs":[],"source":["ensemble_test_preds = oof_test_preds_lgbm * 0.6 + oof_test_preds_cat * 0.25 + oof_test_preds_nn * 0.15"]},{"cell_type":"markdown","id":"6bd9ec16-656d-44c8-b3c1-b7633a1127f1","metadata":{},"source":["## 8. 최종 결과 제출"]},{"cell_type":"code","execution_count":50,"id":"9f09e926-92e9-4ec6-b250-0476560f19f4","metadata":{"trusted":true},"outputs":[],"source":["submission_df[\"probability\"] = ensemble_test_preds\n","submission_df.to_csv(\"lgbm_cat_nn_submission.csv\", index=True)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":6583998,"sourceId":10634121,"sourceType":"datasetVersion"},{"datasetId":6737373,"sourceId":10903088,"sourceType":"datasetVersion"}],"dockerImageVersionId":30918,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.21"},"papermill":{"default_parameters":{},"duration":701.319225,"end_time":"2025-02-25T10:14:01.050255","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-02-25T10:02:19.731030","version":"2.6.0"}},"nbformat":4,"nbformat_minor":5}
