{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f03ababa",
   "metadata": {
    "papermill": {
     "duration": 0.006461,
     "end_time": "2025-02-13T08:51:26.949877",
     "exception": false,
     "start_time": "2025-02-13T08:51:26.943416",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Feature Importance (LGBM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f2c4938a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:26.962358Z",
     "iopub.status.busy": "2025-02-13T08:51:26.962004Z",
     "iopub.status.idle": "2025-02-13T08:51:27.677702Z",
     "shell.execute_reply": "2025-02-13T08:51:27.676597Z"
    },
    "papermill": {
     "duration": 0.723261,
     "end_time": "2025-02-13T08:51:27.678959",
     "exception": false,
     "start_time": "2025-02-13T08:51:26.955698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/lg-aimers/sample_submission.csv\n",
      "/kaggle/input/lg-aimers/train.csv\n",
      "/kaggle/input/lg-aimers/test.csv\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf3d83df",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:27.691720Z",
     "iopub.status.busy": "2025-02-13T08:51:27.691399Z",
     "iopub.status.idle": "2025-02-13T08:51:31.673243Z",
     "shell.execute_reply": "2025-02-13T08:51:31.672325Z"
    },
    "papermill": {
     "duration": 3.989678,
     "end_time": "2025-02-13T08:51:31.674842",
     "exception": false,
     "start_time": "2025-02-13T08:51:27.685164",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_path = '/kaggle/input/lg-aimers/'\n",
    "\n",
    "train = pd.read_csv(data_path + 'train.csv', index_col= 'ID')\n",
    "test = pd.read_csv(data_path + 'test.csv', index_col= 'ID')\n",
    "submission = pd.read_csv(data_path + 'sample_submission.csv', index_col= 'ID')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe240d0b",
   "metadata": {
    "papermill": {
     "duration": 0.005599,
     "end_time": "2025-02-13T08:51:31.686792",
     "exception": false,
     "start_time": "2025-02-13T08:51:31.681193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. 데이터 통합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e5d80c2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:31.699062Z",
     "iopub.status.busy": "2025-02-13T08:51:31.698804Z",
     "iopub.status.idle": "2025-02-13T08:51:31.900309Z",
     "shell.execute_reply": "2025-02-13T08:51:31.899356Z"
    },
    "papermill": {
     "duration": 0.209494,
     "end_time": "2025-02-13T08:51:31.902017",
     "exception": false,
     "start_time": "2025-02-13T08:51:31.692523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_data = pd.concat([train, test], ignore_index= True)\n",
    "all_data = all_data.drop('임신 성공 여부', axis= 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0d34153",
   "metadata": {
    "papermill": {
     "duration": 0.00576,
     "end_time": "2025-02-13T08:51:31.915252",
     "exception": false,
     "start_time": "2025-02-13T08:51:31.909492",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. 피처 엔지니어링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "879c1a2b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:31.927638Z",
     "iopub.status.busy": "2025-02-13T08:51:31.927395Z",
     "iopub.status.idle": "2025-02-13T08:51:31.930506Z",
     "shell.execute_reply": "2025-02-13T08:51:31.929856Z"
    },
    "papermill": {
     "duration": 0.010653,
     "end_time": "2025-02-13T08:51:31.931615",
     "exception": false,
     "start_time": "2025-02-13T08:51:31.920962",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_features = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "042c9ab9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:31.943671Z",
     "iopub.status.busy": "2025-02-13T08:51:31.943467Z",
     "iopub.status.idle": "2025-02-13T08:51:31.947496Z",
     "shell.execute_reply": "2025-02-13T08:51:31.946650Z"
    },
    "papermill": {
     "duration": 0.011256,
     "end_time": "2025-02-13T08:51:31.948658",
     "exception": false,
     "start_time": "2025-02-13T08:51:31.937402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "# \"시술 시기 코드\", \"특정 시술 유형\", \"배아 생성 주요 이유\" 제거\n",
    "# \"정자 출처\", \"정자 기증자 나이\" 제거 -> 제외\n",
    "# \"주요 시술 유형\" 생성\n",
    "\n",
    "cat_features = [ \n",
    "    \"시술 당시 나이\", # FI top4\n",
    "    \"시술 유형\",\n",
    "    \"주요 시술 유형\",\n",
    "    \"배란 유도 유형\",\n",
    "    \"난자 출처\", # FI top\n",
    "        \n",
    "    \n",
    "    \"난자 기증자 나이\", #FI top (알수 없음)\n",
    "\n",
    "    \"정자 출처\",\n",
    "    \"정자 기증자 나이\",\n",
    "    \"시술 시기 코드\", \n",
    "    \"배아 생성 주요 이유\"\n",
    "]\n",
    "\n",
    "print(len(cat_features))\n",
    "\n",
    "drop_features = drop_features + [\"특정 시술 유형\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "151da9d0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:31.960741Z",
     "iopub.status.busy": "2025-02-13T08:51:31.960535Z",
     "iopub.status.idle": "2025-02-13T08:51:31.964641Z",
     "shell.execute_reply": "2025-02-13T08:51:31.963913Z"
    },
    "papermill": {
     "duration": 0.01141,
     "end_time": "2025-02-13T08:51:31.965832",
     "exception": false,
     "start_time": "2025-02-13T08:51:31.954422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# \"IVF 시술 횟수\", \"IVF 임신 횟수\", \"IVF 출산 횟수\" 제거\n",
    "# \"DI 시술 횟수\", \"DI 임신 횟수\", \"DI 출산 횟수\" 제거\n",
    "# \"IVF 임신 성공률\", \"IVF 출산 성공률\", \"IVF 실패 횟수\", \"IVF 유산 횟수\", \"DI 임신 성공률\", \"DI 출산 성공률\", \"DI 실패 횟수\", \"DI 유산 횟수\" 생성 \n",
    "\n",
    "ord_features = [\n",
    "    \"IVF 임신 성공률\", \n",
    "    \"IVF 출산 성공률\", \n",
    "    \"IVF 실패 횟수\", \n",
    "    \"IVF 유산 횟수\", \n",
    "    \"DI 임신 성공률\", \n",
    "    \"DI 출산 성공률\", \n",
    "    \"DI 실패 횟수\", \n",
    "    \"DI 유산 횟수\",\n",
    "    \n",
    "    \"클리닉 내 총 시술 횟수\", #FI top\n",
    "    \"총 시술 횟수\",\n",
    "    \"총 임신 횟수\",\n",
    "    \"총 출산 횟수\"\n",
    "]\n",
    "\n",
    "print(len(ord_features))\n",
    "\n",
    "# drop_features = drop_features + [\"총 시술 횟수\", \"총 임신 횟수\", \"총 출산 횟수\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "96e45e04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:31.978775Z",
     "iopub.status.busy": "2025-02-13T08:51:31.978558Z",
     "iopub.status.idle": "2025-02-13T08:51:31.982901Z",
     "shell.execute_reply": "2025-02-13T08:51:31.982202Z"
    },
    "papermill": {
     "duration": 0.011823,
     "end_time": "2025-02-13T08:51:31.984056",
     "exception": false,
     "start_time": "2025-02-13T08:51:31.972233",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "# \"난자 해동 경과일\", \"난자 혼합 경과일\", \"배아 해동 경과일\" 제거 ->제외 \n",
    "# \"저장된 신선 난자 수\", \"기증자 정자와 혼합된 난자 수\" 제거 -> 제외\n",
    "\n",
    "num_features = [\n",
    "    \"이식된 배아 수\", # FI top1\n",
    "    \"해동 난자 수\", #FI top\n",
    "    \"수집된 신선 난자 수\", #FI top7\n",
    "    \"파트너 정자와 혼합된 난자 수\", #FI top\n",
    "    \"배아 이식 경과일\", # FI top2,\n",
    "    \n",
    "    \n",
    "    \"저장된 배아 수\", # FI top3\n",
    "    \"미세주입 후 저장된 배아 수\", #FI top\n",
    "    \"총 생성 배아 수\", # FI top5\n",
    "    \"미세주입된 난자 수\", #FI top8\n",
    "    \"혼합된 난자 수\", #FI top\n",
    "    \"미세주입에서 생성된 배아 수\", #FI top\n",
    "    \"미세주입 배아 이식 수\", #FI top\n",
    "    \"해동된 배아 수\", #FI top\n",
    "    \"난자 채취 경과일\", #FI top\n",
    "    \"임신 시도 또는 마지막 임신 경과 연수\", #FI top\n",
    "\n",
    "    \"난자 해동 경과일\",\n",
    "    \"난자 혼합 경과일\",\n",
    "    \"배아 해동 경과일\",\n",
    "    \"저장된 신선 난자 수\",\n",
    "    \"기증자 정자와 혼합된 난자 수\"\n",
    "]\n",
    "\n",
    "print(len(num_features))\n",
    "\n",
    "# drop_features = drop_features + [\"난자 해동 경과일\", \"난자 혼합 경과일\", \"배아 해동 경과일\", \"저장된 신선 난자 수\", \"기증자 정자와 혼합된 난자 수\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "436410d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:31.996769Z",
     "iopub.status.busy": "2025-02-13T08:51:31.996563Z",
     "iopub.status.idle": "2025-02-13T08:51:32.000887Z",
     "shell.execute_reply": "2025-02-13T08:51:32.000144Z"
    },
    "papermill": {
     "duration": 0.01183,
     "end_time": "2025-02-13T08:51:32.002090",
     "exception": false,
     "start_time": "2025-02-13T08:51:31.990260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# \"남성 주 불임 원인\", \"남성 부 불임 원인\", \"불임 원인 - 남성 요인\", \"불임 원인 - 정자 농도\", \"불임 원인 - 정자 면역학적 요인\", \"불임 원인 - 정자 운동성\", \"불임 원인 - 정자 형태\",\n",
    "# \"여성 주 불임 원인\", \"여성 부 불임 원인\", \"불임 원인 - 난관 질환\", \"불임 원인 - 배란 장애\", \"불임 원인 - 여성 요인\", \"불임 원인 - 자궁경부 문제\", \"불임 원인 - 자궁내막증\" 제거\n",
    "# \"부부 주 불임 원인\", \"부부 부 불임 원인\" 제거\n",
    "# \"불명확 불임 원인\" 제거 -> 제외\n",
    "# \"남성 불임 원인\", \"여성 불임 원인\", \"부부 불임 원인\" 생성\n",
    "# '착상 전 유전 검사 사용 여부', \"기증 배아 사용 여부\" 제거 -> 제외\n",
    "# \"대리모 여부\", \"PGD 시술 여부\", \"PGS 시술 여부\" 제거 \n",
    "\n",
    "bin_features = [\n",
    "    '배란 자극 여부',\n",
    "    '단일 배아 이식 여부', #FI top\n",
    "    '착상 전 유전 진단 사용 여부',\n",
    "    '남성 불임 원인',\n",
    "    '여성 불임 원인',\n",
    "    '부부 불임 원인',\n",
    "    \"동결 배아 사용 여부\",\n",
    "    \"신선 배아 사용 여부\",\n",
    "\n",
    "    \"불명확 불임 원인\",\n",
    "    \"기증 배아 사용 여부\",\n",
    "    '착상 전 유전 검사 사용 여부',\n",
    "    \"대리모 여부\"\n",
    "]\n",
    "\n",
    "print(len(bin_features))\n",
    "\n",
    "drop_features = drop_features + [\"PGD 시술 여부\", \"PGS 시술 여부\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36925b95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:32.015398Z",
     "iopub.status.busy": "2025-02-13T08:51:32.015194Z",
     "iopub.status.idle": "2025-02-13T08:51:32.117505Z",
     "shell.execute_reply": "2025-02-13T08:51:32.116776Z"
    },
    "papermill": {
     "duration": 0.110388,
     "end_time": "2025-02-13T08:51:32.118788",
     "exception": false,
     "start_time": "2025-02-13T08:51:32.008400",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "주요 시술 유형\n",
       "ICSI     50.208130\n",
       "IVF      36.909168\n",
       "Other    10.511578\n",
       "IUI       2.371124\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시술 유형(cat feature) 피처 엔지니어링 \n",
    "\n",
    "all_data[\"주요 시술 유형\"] = all_data[\"특정 시술 유형\"].apply(lambda x: \n",
    "    \"ICSI\" if \"ICSI\" in str(x) else \n",
    "    \"IVF\" if \"IVF\" in str(x) else \n",
    "    \"IUI\" if \"IUI\" in str(x) else \n",
    "    \"Other\"\n",
    ")\n",
    "\n",
    "drop_features = drop_features + ['특정 시술 유형']\n",
    "\n",
    "all_data['주요 시술 유형'].value_counts(normalize=True, dropna=False) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20f6db0c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:32.132439Z",
     "iopub.status.busy": "2025-02-13T08:51:32.132215Z",
     "iopub.status.idle": "2025-02-13T08:51:32.483718Z",
     "shell.execute_reply": "2025-02-13T08:51:32.482714Z"
    },
    "papermill": {
     "duration": 0.359769,
     "end_time": "2025-02-13T08:51:32.485104",
     "exception": false,
     "start_time": "2025-02-13T08:51:32.125335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "남성 불임 원인\n",
      "0    60.57855\n",
      "1    39.42145\n",
      "Name: proportion, dtype: float64\n",
      "여성 불임 원인\n",
      "0    66.416583\n",
      "1    33.583417\n",
      "Name: proportion, dtype: float64\n",
      "부부 불임 원인\n",
      "0    95.81546\n",
      "1     4.18454\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 불임 원인(bin features) 피처 엔지니어링 \n",
    "\n",
    "infertility_features = [\"남성 주 불임 원인\", \"남성 부 불임 원인\", \"여성 주 불임 원인\", \"여성 부 불임 원인\",\n",
    "                        \"불임 원인 - 남성 요인\", \"불임 원인 - 정자 농도\", \"불임 원인 - 정자 면역학적 요인\", \"불임 원인 - 정자 운동성\", \"불임 원인 - 정자 형태\",\n",
    "                        \"불임 원인 - 난관 질환\", \"불임 원인 - 배란 장애\", \"불임 원인 - 여성 요인\", \"불임 원인 - 자궁경부 문제\", \"불임 원인 - 자궁내막증\",\n",
    "                        \"부부 주 불임 원인\", \"부부 부 불임 원인\"]\n",
    "\n",
    "all_data[\"남성 불임 원인\"] = (\n",
    "    all_data[\"남성 주 불임 원인\"] + \n",
    "    all_data[\"남성 부 불임 원인\"] + \n",
    "    all_data[\"불임 원인 - 남성 요인\"] + \n",
    "    all_data[\"불임 원인 - 정자 농도\"] + \n",
    "    all_data[\"불임 원인 - 정자 면역학적 요인\"] + \n",
    "    all_data[\"불임 원인 - 정자 운동성\"] + \n",
    "    all_data[\"불임 원인 - 정자 형태\"]\n",
    ").apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "all_data[\"여성 불임 원인\"] = (\n",
    "    all_data[\"여성 주 불임 원인\"] + \n",
    "    all_data[\"여성 부 불임 원인\"] + \n",
    "    all_data[\"불임 원인 - 난관 질환\"] + \n",
    "    all_data[\"불임 원인 - 배란 장애\"] + \n",
    "    all_data[\"불임 원인 - 여성 요인\"] + \n",
    "    all_data[\"불임 원인 - 자궁경부 문제\"] + \n",
    "    all_data[\"불임 원인 - 자궁내막증\"]\n",
    ").apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "all_data[\"부부 불임 원인\"] = (\n",
    "    all_data[\"부부 주 불임 원인\"] + \n",
    "    all_data[\"부부 부 불임 원인\"]\n",
    ").apply(lambda x: 1 if x > 0 else 0)\n",
    "\n",
    "drop_features = drop_features + infertility_features\n",
    "\n",
    "print(all_data['남성 불임 원인'].value_counts(normalize=True, dropna=False) * 100)\n",
    "print(all_data['여성 불임 원인'].value_counts(normalize=True, dropna=False) * 100)\n",
    "print(all_data['부부 불임 원인'].value_counts(normalize=True, dropna=False) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "05091d93",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:32.499077Z",
     "iopub.status.busy": "2025-02-13T08:51:32.498860Z",
     "iopub.status.idle": "2025-02-13T08:51:34.603617Z",
     "shell.execute_reply": "2025-02-13T08:51:34.602877Z"
    },
    "papermill": {
     "duration": 2.113562,
     "end_time": "2025-02-13T08:51:34.605297",
     "exception": false,
     "start_time": "2025-02-13T08:51:32.491735",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 과거 이력(ord feature) 피처 엔지니어링\n",
    "\n",
    "past_features = [\"IVF 시술 횟수\", \"DI 시술 횟수\", \"IVF 임신 횟수\", \"DI 임신 횟수\", \"IVF 출산 횟수\", \"DI 출산 횟수\"]\n",
    "\n",
    "for col in [\"총 시술 횟수\", \"총 임신 횟수\", \"총 출산 횟수\", \"클리닉 내 총 시술 횟수\"]:\n",
    "    all_data[col] = all_data[col].str.replace(\"회 이상\", \"\").str.replace(\"회\", \"\").astype(float)\n",
    "        \n",
    "for col in past_features:\n",
    "    all_data[col] = all_data[col].str.replace(\"회 이상\", \"\").str.replace(\"회\", \"\").astype(float)\n",
    "\n",
    "all_data[\"IVF 임신 성공률\"] = all_data[\"IVF 임신 횟수\"] / (all_data[\"IVF 시술 횟수\"] + 1)\n",
    "all_data[\"IVF 출산 성공률\"] = all_data[\"IVF 출산 횟수\"] / (all_data[\"IVF 임신 횟수\"] + 1)\n",
    "all_data[\"IVF 실패 횟수\"] = all_data[\"IVF 시술 횟수\"] - all_data[\"IVF 임신 횟수\"]\n",
    "all_data[\"IVF 유산 횟수\"] = all_data[\"IVF 임신 횟수\"] - all_data[\"IVF 출산 횟수\"]\n",
    "\n",
    "all_data[\"DI 임신 성공률\"] = all_data[\"DI 임신 횟수\"] / (all_data[\"DI 시술 횟수\"] + 1)\n",
    "all_data[\"DI 출산 성공률\"] = all_data[\"DI 출산 횟수\"] / (all_data[\"DI 임신 횟수\"] + 1)\n",
    "all_data[\"DI 실패 횟수\"] = all_data[\"DI 시술 횟수\"] - all_data[\"DI 임신 횟수\"]\n",
    "all_data[\"DI 유산 횟수\"] = all_data[\"DI 임신 횟수\"] - all_data[\"DI 출산 횟수\"]\n",
    "\n",
    "drop_features = drop_features + past_features\n",
    "\n",
    "# print(all_data['IVF 임신 성공률'].value_counts(normalize=True, dropna=False) * 100)\n",
    "# print(all_data[\"IVF 출산 성공률\"].value_counts(normalize=True, dropna=False) * 100)\n",
    "# print(all_data[\"IVF 실패 횟수\"].value_counts(normalize=True, dropna=False) * 100)\n",
    "# print(all_data[\"IVF 유산 횟수\"].value_counts(normalize=True, dropna=False) * 100)\n",
    "# print(all_data[\"DI 임신 성공률\"].value_counts(normalize=True, dropna=False) * 100)\n",
    "# print(all_data[\"DI 출산 성공률\"].value_counts(normalize=True, dropna=False) * 100)\n",
    "# print(all_data[\"DI 실패 횟수\"].value_counts(normalize=True, dropna=False) * 100)\n",
    "# print(all_data[\"DI 유산 횟수\"].value_counts(normalize=True, dropna=False) * 100)\n",
    "\n",
    "# print(all_data[\"총 시술 횟수\"].value_counts(normalize=True, dropna=False) * 100)\n",
    "# print(all_data[\"총 임신 횟수\"].value_counts(normalize=True, dropna=False) * 100)\n",
    "# print(all_data[\"총 출산 횟수\"].value_counts(normalize=True, dropna=False) * 100)\n",
    "# print(all_data[\"IVF 임신 횟수\"].value_counts(normalize=True, dropna=False) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "62f15907",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:34.619644Z",
     "iopub.status.busy": "2025-02-13T08:51:34.619398Z",
     "iopub.status.idle": "2025-02-13T08:51:34.706861Z",
     "shell.execute_reply": "2025-02-13T08:51:34.706203Z"
    },
    "papermill": {
     "duration": 0.096293,
     "end_time": "2025-02-13T08:51:34.708396",
     "exception": false,
     "start_time": "2025-02-13T08:51:34.612103",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "extracted_data = all_data.drop(columns=drop_features, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d4f3d8db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:34.722667Z",
     "iopub.status.busy": "2025-02-13T08:51:34.722428Z",
     "iopub.status.idle": "2025-02-13T08:51:34.727332Z",
     "shell.execute_reply": "2025-02-13T08:51:34.726387Z"
    },
    "papermill": {
     "duration": 0.013169,
     "end_time": "2025-02-13T08:51:34.728500",
     "exception": false,
     "start_time": "2025-02-13T08:51:34.715331",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['시술 시기 코드', '시술 당시 나이', '임신 시도 또는 마지막 임신 경과 연수', '시술 유형', '배란 자극 여부',\n",
       "       '배란 유도 유형', '단일 배아 이식 여부', '착상 전 유전 검사 사용 여부', '착상 전 유전 진단 사용 여부',\n",
       "       '불명확 불임 원인', '배아 생성 주요 이유', '총 시술 횟수', '클리닉 내 총 시술 횟수', '총 임신 횟수',\n",
       "       '총 출산 횟수', '총 생성 배아 수', '미세주입된 난자 수', '미세주입에서 생성된 배아 수', '이식된 배아 수',\n",
       "       '미세주입 배아 이식 수', '저장된 배아 수', '미세주입 후 저장된 배아 수', '해동된 배아 수', '해동 난자 수',\n",
       "       '수집된 신선 난자 수', '저장된 신선 난자 수', '혼합된 난자 수', '파트너 정자와 혼합된 난자 수',\n",
       "       '기증자 정자와 혼합된 난자 수', '난자 출처', '정자 출처', '난자 기증자 나이', '정자 기증자 나이',\n",
       "       '동결 배아 사용 여부', '신선 배아 사용 여부', '기증 배아 사용 여부', '대리모 여부', '난자 채취 경과일',\n",
       "       '난자 해동 경과일', '난자 혼합 경과일', '배아 이식 경과일', '배아 해동 경과일', '주요 시술 유형',\n",
       "       '남성 불임 원인', '여성 불임 원인', '부부 불임 원인', 'IVF 임신 성공률', 'IVF 출산 성공률',\n",
       "       'IVF 실패 횟수', 'IVF 유산 횟수', 'DI 임신 성공률', 'DI 출산 성공률', 'DI 실패 횟수',\n",
       "       'DI 유산 횟수'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extracted_features = extracted_data.columns\n",
    "extracted_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9ad9855",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:34.742073Z",
     "iopub.status.busy": "2025-02-13T08:51:34.741848Z",
     "iopub.status.idle": "2025-02-13T08:51:34.746161Z",
     "shell.execute_reply": "2025-02-13T08:51:34.745377Z"
    },
    "papermill": {
     "duration": 0.012384,
     "end_time": "2025-02-13T08:51:34.747415",
     "exception": false,
     "start_time": "2025-02-13T08:51:34.735031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(extracted_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e965de",
   "metadata": {
    "papermill": {
     "duration": 0.006205,
     "end_time": "2025-02-13T08:51:34.760070",
     "exception": false,
     "start_time": "2025-02-13T08:51:34.753865",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. 피처 엔지니어링: 원 핫 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "431c0495",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:34.773578Z",
     "iopub.status.busy": "2025-02-13T08:51:34.773354Z",
     "iopub.status.idle": "2025-02-13T08:51:36.708465Z",
     "shell.execute_reply": "2025-02-13T08:51:36.707541Z"
    },
    "papermill": {
     "duration": 1.94343,
     "end_time": "2025-02-13T08:51:36.709912",
     "exception": false,
     "start_time": "2025-02-13T08:51:34.766482",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<346418x57 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3464180 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "onehot_encoder = OneHotEncoder()\n",
    "\n",
    "encoded_cat_matrix = onehot_encoder.fit_transform(extracted_data[cat_features])\n",
    "\n",
    "encoded_cat_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bb8a01f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:36.726946Z",
     "iopub.status.busy": "2025-02-13T08:51:36.726585Z",
     "iopub.status.idle": "2025-02-13T08:51:36.729792Z",
     "shell.execute_reply": "2025-02-13T08:51:36.729187Z"
    },
    "papermill": {
     "duration": 0.012886,
     "end_time": "2025-02-13T08:51:36.730985",
     "exception": false,
     "start_time": "2025-02-13T08:51:36.718099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "remaining_features = list(set(extracted_features) - set(cat_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "83a74707",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:36.745696Z",
     "iopub.status.busy": "2025-02-13T08:51:36.745490Z",
     "iopub.status.idle": "2025-02-13T08:51:36.800513Z",
     "shell.execute_reply": "2025-02-13T08:51:36.799429Z"
    },
    "papermill": {
     "duration": 0.06392,
     "end_time": "2025-02-13T08:51:36.801884",
     "exception": false,
     "start_time": "2025-02-13T08:51:36.737964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저장된 신선 난자 수              float64\n",
      "난자 해동 경과일                float64\n",
      "IVF 임신 성공률               float64\n",
      "미세주입 후 저장된 배아 수          float64\n",
      "미세주입에서 생성된 배아 수          float64\n",
      "불명확 불임 원인                  int64\n",
      "IVF 실패 횟수                float64\n",
      "해동된 배아 수                 float64\n",
      "혼합된 난자 수                 float64\n",
      "배아 해동 경과일                float64\n",
      "착상 전 유전 검사 사용 여부         float64\n",
      "저장된 배아 수                 float64\n",
      "여성 불임 원인                   int64\n",
      "DI 유산 횟수                 float64\n",
      "DI 출산 성공률                float64\n",
      "단일 배아 이식 여부              float64\n",
      "총 생성 배아 수                float64\n",
      "파트너 정자와 혼합된 난자 수         float64\n",
      "수집된 신선 난자 수              float64\n",
      "배아 이식 경과일                float64\n",
      "이식된 배아 수                 float64\n",
      "DI 임신 성공률                float64\n",
      "미세주입 배아 이식 수             float64\n",
      "배란 자극 여부                   int64\n",
      "착상 전 유전 진단 사용 여부         float64\n",
      "기증 배아 사용 여부              float64\n",
      "총 시술 횟수                  float64\n",
      "IVF 출산 성공률               float64\n",
      "임신 시도 또는 마지막 임신 경과 연수    float64\n",
      "미세주입된 난자 수               float64\n",
      "부부 불임 원인                   int64\n",
      "난자 혼합 경과일                float64\n",
      "대리모 여부                   float64\n",
      "남성 불임 원인                   int64\n",
      "총 출산 횟수                  float64\n",
      "난자 채취 경과일                float64\n",
      "DI 실패 횟수                 float64\n",
      "동결 배아 사용 여부              float64\n",
      "신선 배아 사용 여부              float64\n",
      "해동 난자 수                  float64\n",
      "기증자 정자와 혼합된 난자 수         float64\n",
      "총 임신 횟수                  float64\n",
      "IVF 유산 횟수                float64\n",
      "클리닉 내 총 시술 횟수            float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(extracted_data[remaining_features].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2a11fe5c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:36.816529Z",
     "iopub.status.busy": "2025-02-13T08:51:36.816320Z",
     "iopub.status.idle": "2025-02-13T08:51:37.538023Z",
     "shell.execute_reply": "2025-02-13T08:51:37.537375Z"
    },
    "papermill": {
     "duration": 0.73069,
     "end_time": "2025-02-13T08:51:37.539654",
     "exception": false,
     "start_time": "2025-02-13T08:51:36.808964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import sparse\n",
    "\n",
    "extracted_data_sprs = sparse.hstack([sparse.csr_matrix(extracted_data[remaining_features].fillna(0)),\n",
    "                               encoded_cat_matrix],\n",
    "                              format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2897c4a4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:37.554795Z",
     "iopub.status.busy": "2025-02-13T08:51:37.554546Z",
     "iopub.status.idle": "2025-02-13T08:51:37.558058Z",
     "shell.execute_reply": "2025-02-13T08:51:37.557455Z"
    },
    "papermill": {
     "duration": 0.012079,
     "end_time": "2025-02-13T08:51:37.559098",
     "exception": false,
     "start_time": "2025-02-13T08:51:37.547019",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "extracted_encoded_features = list(remaining_features) + list(onehot_encoder.get_feature_names_out(cat_features))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115ef263",
   "metadata": {
    "papermill": {
     "duration": 0.006853,
     "end_time": "2025-02-13T08:51:37.572837",
     "exception": false,
     "start_time": "2025-02-13T08:51:37.565984",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. 데이터 나누기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "244c406e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:37.587586Z",
     "iopub.status.busy": "2025-02-13T08:51:37.587344Z",
     "iopub.status.idle": "2025-02-13T08:51:37.658133Z",
     "shell.execute_reply": "2025-02-13T08:51:37.657143Z"
    },
    "papermill": {
     "duration": 0.079816,
     "end_time": "2025-02-13T08:51:37.659806",
     "exception": false,
     "start_time": "2025-02-13T08:51:37.579990",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "num_train = len(train) \n",
    "\n",
    "X = extracted_data_sprs[:num_train]\n",
    "X_test = extracted_data_sprs[num_train:]\n",
    "\n",
    "y = train['임신 성공 여부'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aafb5e7",
   "metadata": {
    "papermill": {
     "duration": 0.006803,
     "end_time": "2025-02-13T08:51:37.674006",
     "exception": false,
     "start_time": "2025-02-13T08:51:37.667203",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. ROC-AUC 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "62f8192d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:37.688692Z",
     "iopub.status.busy": "2025-02-13T08:51:37.688442Z",
     "iopub.status.idle": "2025-02-13T08:51:37.771677Z",
     "shell.execute_reply": "2025-02-13T08:51:37.771010Z"
    },
    "papermill": {
     "duration": 0.091996,
     "end_time": "2025-02-13T08:51:37.772936",
     "exception": false,
     "start_time": "2025-02-13T08:51:37.680940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# LGBM 커스텀 평가 함수\n",
    "def lgb_roc_auc(y_pred, dataset):\n",
    "    y_true = dataset.get_label()\n",
    "    return \"roc_auc\", roc_auc_score(y_true, y_pred), True  # (지표 이름, 값, 높은 값이 더 좋은지 여부)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688bc08c",
   "metadata": {
    "papermill": {
     "duration": 0.007075,
     "end_time": "2025-02-13T08:51:37.787224",
     "exception": false,
     "start_time": "2025-02-13T08:51:37.780149",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. 모델 훈련 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "220dfafa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:37.801792Z",
     "iopub.status.busy": "2025-02-13T08:51:37.801560Z",
     "iopub.status.idle": "2025-02-13T08:51:42.167089Z",
     "shell.execute_reply": "2025-02-13T08:51:42.166102Z"
    },
    "papermill": {
     "duration": 4.37474,
     "end_time": "2025-02-13T08:51:42.168908",
     "exception": false,
     "start_time": "2025-02-13T08:51:37.794168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 8:2 비율로 훈련 데이터, 검증 데이터 분리 (베이지안 최적화 수행용)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, \n",
    "                                                      test_size=0.2, \n",
    "                                                      random_state=0)\n",
    "\n",
    "# 베이지안 최적화용 데이터셋\n",
    "bayes_dtrain = lgb.Dataset(X_train, y_train)\n",
    "bayes_dvalid = lgb.Dataset(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8f005f2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:42.184718Z",
     "iopub.status.busy": "2025-02-13T08:51:42.184168Z",
     "iopub.status.idle": "2025-02-13T08:51:42.188693Z",
     "shell.execute_reply": "2025-02-13T08:51:42.188028Z"
    },
    "papermill": {
     "duration": 0.013255,
     "end_time": "2025-02-13T08:51:42.189845",
     "exception": false,
     "start_time": "2025-02-13T08:51:42.176590",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 베이지안 최적화를 위한 하이퍼파라미터 범위\n",
    "# TODO: 점점 줄여나가자!!!!\n",
    "param_bounds = {\n",
    "    'num_leaves': (20, 40),  \n",
    "    'lambda_l1': (0, 0.5),  \n",
    "    'lambda_l2': (0.8, 2),  \n",
    "    'feature_fraction': (0.8, 1),  \n",
    "    'bagging_fraction': (0.5, 1),  \n",
    "    'min_child_samples': (5, 25),  \n",
    "    'min_child_weight': (25, 40)  \n",
    "}\n",
    "\n",
    "# 값이 고정된 하이퍼파라미터\n",
    "fixed_params = {'objective': 'binary', # binary classification\n",
    "                'learning_rate': 0.005, # 0.01~0.001\n",
    "                'bagging_freq': 1, # 0 or 1\n",
    "                'force_row_wise': True,\n",
    "                'random_state': 1991}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d4f30773",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:42.204738Z",
     "iopub.status.busy": "2025-02-13T08:51:42.204520Z",
     "iopub.status.idle": "2025-02-13T08:51:42.209596Z",
     "shell.execute_reply": "2025-02-13T08:51:42.208991Z"
    },
    "papermill": {
     "duration": 0.013721,
     "end_time": "2025-02-13T08:51:42.210764",
     "exception": false,
     "start_time": "2025-02-13T08:51:42.197043",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from lightgbm import early_stopping\n",
    "\n",
    "def eval_function(num_leaves, lambda_l1, lambda_l2, feature_fraction,\n",
    "                  bagging_fraction, min_child_samples, min_child_weight):\n",
    "    '''최적화하려는 평가지표 계산 함수'''\n",
    "    \n",
    "    # 베이지안 최적화를 수행할 하이퍼파라미터 \n",
    "    params = {'num_leaves': int(round(num_leaves)),\n",
    "              'lambda_l1': lambda_l1,\n",
    "              'lambda_l2': lambda_l2,\n",
    "              'feature_fraction': feature_fraction,\n",
    "              'bagging_fraction': bagging_fraction,\n",
    "              'min_child_samples': int(round(min_child_samples)),\n",
    "              'min_child_weight': min_child_weight,\n",
    "              'feature_pre_filter': False}\n",
    "    # 고정된 하이퍼파라미터도 추가\n",
    "    params.update(fixed_params)\n",
    "    \n",
    "    print('하이퍼파라미터:', params)    \n",
    "    \n",
    "    # LightGBM 모델 훈련\n",
    "    lgb_model = lgb.train(params=params, \n",
    "                           train_set=bayes_dtrain,\n",
    "                           num_boost_round=2500,\n",
    "                           valid_sets=bayes_dvalid,\n",
    "                           callbacks=[early_stopping(stopping_rounds=100)])\n",
    "    # 검증 데이터로 예측 수행\n",
    "    preds = lgb_model.predict(X_valid) \n",
    "    # roc-auc 계산\n",
    "    roc_auc = roc_auc_score(y_valid, preds)\n",
    "    print(f'roc-auc : {roc_auc}\\n')\n",
    "    \n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e85932e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:42.225536Z",
     "iopub.status.busy": "2025-02-13T08:51:42.225312Z",
     "iopub.status.idle": "2025-02-13T08:51:42.277765Z",
     "shell.execute_reply": "2025-02-13T08:51:42.277181Z"
    },
    "papermill": {
     "duration": 0.061176,
     "end_time": "2025-02-13T08:51:42.279010",
     "exception": false,
     "start_time": "2025-02-13T08:51:42.217834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "\n",
    "# 베이지안 최적화 객체 생성\n",
    "optimizer = BayesianOptimization(f=eval_function,      # 평가지표 계산 함수\n",
    "                                 pbounds=param_bounds, # 하이퍼파라미터 범위\n",
    "                                 random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e9356f37",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T08:51:42.294165Z",
     "iopub.status.busy": "2025-02-13T08:51:42.293905Z",
     "iopub.status.idle": "2025-02-13T09:25:56.469762Z",
     "shell.execute_reply": "2025-02-13T09:25:56.468627Z"
    },
    "papermill": {
     "duration": 2054.185077,
     "end_time": "2025-02-13T09:25:56.471387",
     "exception": false,
     "start_time": "2025-02-13T08:51:42.286310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | baggin... | featur... | lambda_l1 | lambda_l2 | min_ch... | min_ch... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "하이퍼파라미터: {'num_leaves': 29, 'lambda_l1': 0.30138168803582194, 'lambda_l2': 1.4538598195962762, 'feature_fraction': 0.943037873274484, 'bagging_fraction': 0.7744067519636624, 'min_child_samples': 13, 'min_child_weight': 34.68841169599984, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2205]\tvalid_0's binary_logloss: 0.489117\n",
      "roc-auc : 0.7415412313830232\n",
      "\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.7415   \u001b[39m | \u001b[39m0.7744   \u001b[39m | \u001b[39m0.943    \u001b[39m | \u001b[39m0.3014   \u001b[39m | \u001b[39m1.454    \u001b[39m | \u001b[39m13.47    \u001b[39m | \u001b[39m34.69    \u001b[39m | \u001b[39m28.75    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 39, 'lambda_l1': 0.19172075941288885, 'lambda_l2': 1.7500700456991976, 'feature_fraction': 0.9927325521002058, 'bagging_fraction': 0.9458865003910399, 'min_child_samples': 16, 'min_child_weight': 33.52066841640898, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1861]\tvalid_0's binary_logloss: 0.489271\n",
      "roc-auc : 0.7412798119449492\n",
      "\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m0.7413   \u001b[39m | \u001b[39m0.9459   \u001b[39m | \u001b[39m0.9927   \u001b[39m | \u001b[39m0.1917   \u001b[39m | \u001b[39m1.75     \u001b[39m | \u001b[39m15.58    \u001b[39m | \u001b[39m33.52    \u001b[39m | \u001b[39m38.51    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 40, 'lambda_l1': 0.01010919872016286, 'lambda_l2': 1.7991438146575256, 'feature_fraction': 0.8174258599403081, 'bagging_fraction': 0.5355180290989434, 'min_child_samples': 21, 'min_child_weight': 38.050182223702286, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1865]\tvalid_0's binary_logloss: 0.489127\n",
      "roc-auc : 0.7416188025515744\n",
      "\n",
      "| \u001b[35m3        \u001b[39m | \u001b[35m0.7416   \u001b[39m | \u001b[35m0.5355   \u001b[39m | \u001b[35m0.8174   \u001b[39m | \u001b[35m0.01011  \u001b[39m | \u001b[35m1.799    \u001b[39m | \u001b[35m20.56    \u001b[39m | \u001b[35m38.05    \u001b[39m | \u001b[35m39.57    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 39, 'lambda_l1': 0.39026458814322773, 'lambda_l2': 0.9419293110427199, 'feature_fraction': 0.8922958724505864, 'bagging_fraction': 0.8995792821083618, 'min_child_samples': 18, 'min_child_weight': 27.150299311135697, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1896]\tvalid_0's binary_logloss: 0.489198\n",
      "roc-auc : 0.7414616642242603\n",
      "\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.7415   \u001b[39m | \u001b[39m0.8996   \u001b[39m | \u001b[39m0.8923   \u001b[39m | \u001b[39m0.3903   \u001b[39m | \u001b[39m0.9419   \u001b[39m | \u001b[39m17.8     \u001b[39m | \u001b[39m27.15    \u001b[39m | \u001b[39m38.89    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 20, 'lambda_l1': 0.13227780605231348, 'lambda_l2': 1.72908042732106, 'feature_fraction': 0.8829323879981047, 'bagging_fraction': 0.7609241608750359, 'min_child_samples': 14, 'min_child_weight': 33.52650923302973, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\tvalid_0's binary_logloss: 0.489084\n",
      "roc-auc : 0.7416495409982607\n",
      "\n",
      "| \u001b[35m5        \u001b[39m | \u001b[35m0.7416   \u001b[39m | \u001b[35m0.7609   \u001b[39m | \u001b[35m0.8829   \u001b[39m | \u001b[35m0.1323   \u001b[39m | \u001b[35m1.729    \u001b[39m | \u001b[35m14.12    \u001b[39m | \u001b[35m33.53    \u001b[39m | \u001b[35m20.38    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 29, 'lambda_l1': 0.30846699843737846, 'lambda_l2': 1.932497694217549, 'feature_fraction': 0.9224191445444843, 'bagging_fraction': 0.8088177485379385, 'min_child_samples': 19, 'min_child_weight': 30.39261850860679, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2487]\tvalid_0's binary_logloss: 0.489099\n",
      "roc-auc : 0.7415885270719549\n",
      "\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.8088   \u001b[39m | \u001b[39m0.9224   \u001b[39m | \u001b[39m0.3085   \u001b[39m | \u001b[39m1.932    \u001b[39m | \u001b[39m18.64    \u001b[39m | \u001b[39m30.39    \u001b[39m | \u001b[39m28.74    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 26, 'lambda_l1': 0.33338335772283384, 'lambda_l2': 1.6047654435417913, 'feature_fraction': 0.812045094325854, 'bagging_fraction': 0.8488155979636325, 'min_child_samples': 9, 'min_child_weight': 26.9338944648228, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\tvalid_0's binary_logloss: 0.489132\n",
      "roc-auc : 0.7415626413888096\n",
      "\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.8488   \u001b[39m | \u001b[39m0.812    \u001b[39m | \u001b[39m0.3334   \u001b[39m | \u001b[39m1.605    \u001b[39m | \u001b[39m9.208    \u001b[39m | \u001b[39m26.93    \u001b[39m | \u001b[39m26.31    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 23, 'lambda_l1': 0.21930075673116017, 'lambda_l2': 1.9860486056710713, 'feature_fraction': 0.914039354083576, 'bagging_fraction': 0.6818553854713113, 'min_child_samples': 7, 'min_child_weight': 28.13315134142252, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2471]\tvalid_0's binary_logloss: 0.489066\n",
      "roc-auc : 0.7417038029102011\n",
      "\n",
      "| \u001b[35m8        \u001b[39m | \u001b[35m0.7417   \u001b[39m | \u001b[35m0.6819   \u001b[39m | \u001b[35m0.914    \u001b[39m | \u001b[35m0.2193   \u001b[39m | \u001b[35m1.986    \u001b[39m | \u001b[35m7.041    \u001b[39m | \u001b[35m28.13    \u001b[39m | \u001b[35m23.23    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 33, 'lambda_l1': 0.23315538642815314, 'lambda_l2': 1.0933107104019233, 'feature_fraction': 0.8506583205079564, 'bagging_fraction': 0.8265541627326992, 'min_child_samples': 8, 'min_child_weight': 26.655627117464576, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2489]\tvalid_0's binary_logloss: 0.489146\n",
      "roc-auc : 0.7414982356611352\n",
      "\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.7415   \u001b[39m | \u001b[39m0.8266   \u001b[39m | \u001b[39m0.8507   \u001b[39m | \u001b[39m0.2332   \u001b[39m | \u001b[39m1.093    \u001b[39m | \u001b[39m8.179    \u001b[39m | \u001b[39m26.66    \u001b[39m | \u001b[39m33.13    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 22, 'lambda_l1': 0.18436258533048205, 'lambda_l2': 1.7851918758175223, 'feature_fraction': 0.8393164723360107, 'bagging_fraction': 0.5690914756743068, 'min_child_samples': 7, 'min_child_weight': 37.56917361248206, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2472]\tvalid_0's binary_logloss: 0.489079\n",
      "roc-auc : 0.7416873216774744\n",
      "\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.5691   \u001b[39m | \u001b[39m0.8393   \u001b[39m | \u001b[39m0.1844   \u001b[39m | \u001b[39m1.785    \u001b[39m | \u001b[39m6.942    \u001b[39m | \u001b[39m37.57    \u001b[39m | \u001b[39m21.92    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 21, 'lambda_l1': 0.4039928216818806, 'lambda_l2': 0.8840649217302511, 'feature_fraction': 0.926826561957561, 'bagging_fraction': 0.7236739037371791, 'min_child_samples': 7, 'min_child_weight': 31.998002523958334, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2466]\tvalid_0's binary_logloss: 0.48907\n",
      "roc-auc : 0.7416667063166535\n",
      "\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.7237   \u001b[39m | \u001b[39m0.9268   \u001b[39m | \u001b[39m0.404    \u001b[39m | \u001b[39m0.8841   \u001b[39m | \u001b[39m6.879    \u001b[39m | \u001b[39m32.0     \u001b[39m | \u001b[39m20.57    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 20, 'lambda_l1': 0.3785668344391128, 'lambda_l2': 1.2468332613094224, 'feature_fraction': 0.8065597410217538, 'bagging_fraction': 0.9744824068399911, 'min_child_samples': 5, 'min_child_weight': 25.139937325841053, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2498]\tvalid_0's binary_logloss: 0.489194\n",
      "roc-auc : 0.7415449203125093\n",
      "\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.7415   \u001b[39m | \u001b[39m0.9745   \u001b[39m | \u001b[39m0.8066   \u001b[39m | \u001b[39m0.3786   \u001b[39m | \u001b[39m1.247    \u001b[39m | \u001b[39m5.441    \u001b[39m | \u001b[39m25.14    \u001b[39m | \u001b[39m20.27    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 25, 'lambda_l1': 0.42606210481304, 'lambda_l2': 1.9953421280987835, 'feature_fraction': 0.9125287779917916, 'bagging_fraction': 0.9225195098205766, 'min_child_samples': 5, 'min_child_weight': 32.90946767485143, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2486]\tvalid_0's binary_logloss: 0.489134\n",
      "roc-auc : 0.7415442154969747\n",
      "\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.7415   \u001b[39m | \u001b[39m0.9225   \u001b[39m | \u001b[39m0.9125   \u001b[39m | \u001b[39m0.4261   \u001b[39m | \u001b[39m1.995    \u001b[39m | \u001b[39m5.451    \u001b[39m | \u001b[39m32.91    \u001b[39m | \u001b[39m25.17    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 21, 'lambda_l1': 0.1443952436499672, 'lambda_l2': 1.794180395851215, 'feature_fraction': 0.9469117220942515, 'bagging_fraction': 0.6346463074393469, 'min_child_samples': 10, 'min_child_weight': 29.371156502406087, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2465]\tvalid_0's binary_logloss: 0.489029\n",
      "roc-auc : 0.7417214183628849\n",
      "\n",
      "| \u001b[35m14       \u001b[39m | \u001b[35m0.7417   \u001b[39m | \u001b[35m0.6346   \u001b[39m | \u001b[35m0.9469   \u001b[39m | \u001b[35m0.1444   \u001b[39m | \u001b[35m1.794    \u001b[39m | \u001b[35m9.827    \u001b[39m | \u001b[35m29.37    \u001b[39m | \u001b[35m21.42    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 20, 'lambda_l1': 0.44687527876405037, 'lambda_l2': 1.1029237683738289, 'feature_fraction': 0.8242518858458799, 'bagging_fraction': 0.965957363105081, 'min_child_samples': 11, 'min_child_weight': 39.16483867605878, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2498]\tvalid_0's binary_logloss: 0.489155\n",
      "roc-auc : 0.7415915526456436\n",
      "\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.966    \u001b[39m | \u001b[39m0.8243   \u001b[39m | \u001b[39m0.4469   \u001b[39m | \u001b[39m1.103    \u001b[39m | \u001b[39m11.22    \u001b[39m | \u001b[39m39.16    \u001b[39m | \u001b[39m20.05    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 21, 'lambda_l1': 0.10021977334572185, 'lambda_l2': 1.6658190495193719, 'feature_fraction': 0.8713654473665896, 'bagging_fraction': 0.873897102666993, 'min_child_samples': 14, 'min_child_weight': 27.082618460275544, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2499]\tvalid_0's binary_logloss: 0.489122\n",
      "roc-auc : 0.7416078127597712\n",
      "\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.8739   \u001b[39m | \u001b[39m0.8714   \u001b[39m | \u001b[39m0.1002   \u001b[39m | \u001b[39m1.666    \u001b[39m | \u001b[39m14.2     \u001b[39m | \u001b[39m27.08    \u001b[39m | \u001b[39m20.62    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 22, 'lambda_l1': 0.13668572968171627, 'lambda_l2': 1.9854703008977248, 'feature_fraction': 0.9233625194289788, 'bagging_fraction': 0.6320115338015484, 'min_child_samples': 10, 'min_child_weight': 33.41750688619755, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\tvalid_0's binary_logloss: 0.489053\n",
      "roc-auc : 0.7416734089741891\n",
      "\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.632    \u001b[39m | \u001b[39m0.9234   \u001b[39m | \u001b[39m0.1367   \u001b[39m | \u001b[39m1.985    \u001b[39m | \u001b[39m10.06    \u001b[39m | \u001b[39m33.42    \u001b[39m | \u001b[39m21.76    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 36, 'lambda_l1': 0.4053266183954154, 'lambda_l2': 1.9791901473262905, 'feature_fraction': 0.8402190576864844, 'bagging_fraction': 0.5943290429123511, 'min_child_samples': 25, 'min_child_weight': 39.235715180861625, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1915]\tvalid_0's binary_logloss: 0.489098\n",
      "roc-auc : 0.7416684417028019\n",
      "\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.5943   \u001b[39m | \u001b[39m0.8402   \u001b[39m | \u001b[39m0.4053   \u001b[39m | \u001b[39m1.979    \u001b[39m | \u001b[39m24.95    \u001b[39m | \u001b[39m39.24    \u001b[39m | \u001b[39m35.69    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 29, 'lambda_l1': 0.018962188078548936, 'lambda_l2': 0.8801091098026634, 'feature_fraction': 0.9011325940424821, 'bagging_fraction': 0.7117527638613899, 'min_child_samples': 25, 'min_child_weight': 39.94266343151798, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2485]\tvalid_0's binary_logloss: 0.489039\n",
      "roc-auc : 0.7416555496987645\n",
      "\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.7118   \u001b[39m | \u001b[39m0.9011   \u001b[39m | \u001b[39m0.01896  \u001b[39m | \u001b[39m0.8801   \u001b[39m | \u001b[39m24.88    \u001b[39m | \u001b[39m39.94    \u001b[39m | \u001b[39m29.45    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 23, 'lambda_l1': 0.07721356581977468, 'lambda_l2': 1.8807962279720734, 'feature_fraction': 0.8000968246070979, 'bagging_fraction': 0.5610909816718046, 'min_child_samples': 25, 'min_child_weight': 35.152686433932615, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2471]\tvalid_0's binary_logloss: 0.489107\n",
      "roc-auc : 0.7416361050819549\n",
      "\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.5611   \u001b[39m | \u001b[39m0.8001   \u001b[39m | \u001b[39m0.07721  \u001b[39m | \u001b[39m1.881    \u001b[39m | \u001b[39m24.6     \u001b[39m | \u001b[39m35.15    \u001b[39m | \u001b[39m23.31    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 20, 'lambda_l1': 0.40047813431667423, 'lambda_l2': 1.0343348896138864, 'feature_fraction': 0.8111137463578477, 'bagging_fraction': 0.6876703201606966, 'min_child_samples': 25, 'min_child_weight': 28.03488182781357, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\tvalid_0's binary_logloss: 0.489053\n",
      "roc-auc : 0.7417182032589682\n",
      "\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.6877   \u001b[39m | \u001b[39m0.8111   \u001b[39m | \u001b[39m0.4005   \u001b[39m | \u001b[39m1.034    \u001b[39m | \u001b[39m24.71    \u001b[39m | \u001b[39m28.03    \u001b[39m | \u001b[39m20.14    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 25, 'lambda_l1': 0.4253936509525018, 'lambda_l2': 1.0718078672783256, 'feature_fraction': 0.8854084500802262, 'bagging_fraction': 0.7735548630195079, 'min_child_samples': 25, 'min_child_weight': 25.734324915268108, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\tvalid_0's binary_logloss: 0.489078\n",
      "roc-auc : 0.7416160504147247\n",
      "\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.7736   \u001b[39m | \u001b[39m0.8854   \u001b[39m | \u001b[39m0.4254   \u001b[39m | \u001b[39m1.072    \u001b[39m | \u001b[39m24.66    \u001b[39m | \u001b[39m25.73    \u001b[39m | \u001b[39m25.19    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 20, 'lambda_l1': 0.06922370140053197, 'lambda_l2': 1.1238104612314412, 'feature_fraction': 0.8448879777622037, 'bagging_fraction': 0.6048264552491246, 'min_child_samples': 21, 'min_child_weight': 30.857463153444296, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2477]\tvalid_0's binary_logloss: 0.489092\n",
      "roc-auc : 0.741647685181447\n",
      "\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.6048   \u001b[39m | \u001b[39m0.8449   \u001b[39m | \u001b[39m0.06922  \u001b[39m | \u001b[39m1.124    \u001b[39m | \u001b[39m20.86    \u001b[39m | \u001b[39m30.86    \u001b[39m | \u001b[39m20.47    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 20, 'lambda_l1': 0.27456319946750074, 'lambda_l2': 0.8043322804043956, 'feature_fraction': 0.8814659493362227, 'bagging_fraction': 0.749731221878132, 'min_child_samples': 23, 'min_child_weight': 25.34141509873908, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2495]\tvalid_0's binary_logloss: 0.489112\n",
      "roc-auc : 0.7415795372189097\n",
      "\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.7497   \u001b[39m | \u001b[39m0.8815   \u001b[39m | \u001b[39m0.2746   \u001b[39m | \u001b[39m0.8043   \u001b[39m | \u001b[39m22.87    \u001b[39m | \u001b[39m25.34    \u001b[39m | \u001b[39m20.01    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 20, 'lambda_l1': 0.004158515362600423, 'lambda_l2': 1.3147413820606744, 'feature_fraction': 0.8492852103406, 'bagging_fraction': 0.9479520925943505, 'min_child_samples': 25, 'min_child_weight': 32.00177599776167, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2478]\tvalid_0's binary_logloss: 0.48918\n",
      "roc-auc : 0.7415024201331959\n",
      "\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m0.7415   \u001b[39m | \u001b[39m0.948    \u001b[39m | \u001b[39m0.8493   \u001b[39m | \u001b[39m0.004159 \u001b[39m | \u001b[39m1.315    \u001b[39m | \u001b[39m24.8     \u001b[39m | \u001b[39m32.0     \u001b[39m | \u001b[39m20.05    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 22, 'lambda_l1': 0.4612329573499926, 'lambda_l2': 0.8007868230680615, 'feature_fraction': 0.8163121912534652, 'bagging_fraction': 0.5919141668617725, 'min_child_samples': 8, 'min_child_weight': 29.444850505469788, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2466]\tvalid_0's binary_logloss: 0.489078\n",
      "roc-auc : 0.7416518893962399\n",
      "\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.5919   \u001b[39m | \u001b[39m0.8163   \u001b[39m | \u001b[39m0.4612   \u001b[39m | \u001b[39m0.8008   \u001b[39m | \u001b[39m8.08     \u001b[39m | \u001b[39m29.44    \u001b[39m | \u001b[39m22.16    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 20, 'lambda_l1': 0.13188400219299862, 'lambda_l2': 0.9608137529534437, 'feature_fraction': 0.8851314091570746, 'bagging_fraction': 0.6888615172844197, 'min_child_samples': 11, 'min_child_weight': 30.94825065614907, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\tvalid_0's binary_logloss: 0.48905\n",
      "roc-auc : 0.7417161263235552\n",
      "\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.6889   \u001b[39m | \u001b[39m0.8851   \u001b[39m | \u001b[39m0.1319   \u001b[39m | \u001b[39m0.9608   \u001b[39m | \u001b[39m11.35    \u001b[39m | \u001b[39m30.95    \u001b[39m | \u001b[39m20.46    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 23, 'lambda_l1': 0.054193098819820984, 'lambda_l2': 1.9356916322319413, 'feature_fraction': 0.8757786779660228, 'bagging_fraction': 0.9653389830888223, 'min_child_samples': 13, 'min_child_weight': 31.126300579301855, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2498]\tvalid_0's binary_logloss: 0.489136\n",
      "roc-auc : 0.7415885616217359\n",
      "\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.9653   \u001b[39m | \u001b[39m0.8758   \u001b[39m | \u001b[39m0.05419  \u001b[39m | \u001b[39m1.936    \u001b[39m | \u001b[39m12.64    \u001b[39m | \u001b[39m31.13    \u001b[39m | \u001b[39m23.1     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 20, 'lambda_l1': 0.08803205573287448, 'lambda_l2': 1.1423794878665716, 'feature_fraction': 0.8483162994187579, 'bagging_fraction': 0.7724194301442715, 'min_child_samples': 7, 'min_child_weight': 35.39263443775881, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2489]\tvalid_0's binary_logloss: 0.48908\n",
      "roc-auc : 0.7416657458327386\n",
      "\n",
      "| \u001b[39m29       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.7724   \u001b[39m | \u001b[39m0.8483   \u001b[39m | \u001b[39m0.08803  \u001b[39m | \u001b[39m1.142    \u001b[39m | \u001b[39m7.292    \u001b[39m | \u001b[39m35.39    \u001b[39m | \u001b[39m20.01    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 20, 'lambda_l1': 0.1914362458718279, 'lambda_l2': 1.827821301782977, 'feature_fraction': 0.8020114220073162, 'bagging_fraction': 0.6482693681368321, 'min_child_samples': 10, 'min_child_weight': 31.42090447156147, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2463]\tvalid_0's binary_logloss: 0.489077\n",
      "roc-auc : 0.7416901350167936\n",
      "\n",
      "| \u001b[39m30       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.6483   \u001b[39m | \u001b[39m0.802    \u001b[39m | \u001b[39m0.1914   \u001b[39m | \u001b[39m1.828    \u001b[39m | \u001b[39m9.549    \u001b[39m | \u001b[39m31.42    \u001b[39m | \u001b[39m20.14    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 32, 'lambda_l1': 0.26478133805801257, 'lambda_l2': 1.587724682917183, 'feature_fraction': 0.8164620332785847, 'bagging_fraction': 0.9396758049134295, 'min_child_samples': 24, 'min_child_weight': 36.212587023453644, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2290]\tvalid_0's binary_logloss: 0.48922\n",
      "roc-auc : 0.7413779510917643\n",
      "\n",
      "| \u001b[39m31       \u001b[39m | \u001b[39m0.7414   \u001b[39m | \u001b[39m0.9397   \u001b[39m | \u001b[39m0.8165   \u001b[39m | \u001b[39m0.2648   \u001b[39m | \u001b[39m1.588    \u001b[39m | \u001b[39m24.11    \u001b[39m | \u001b[39m36.21    \u001b[39m | \u001b[39m31.88    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 20, 'lambda_l1': 0.3430715989532696, 'lambda_l2': 1.1820592919849298, 'feature_fraction': 0.9230276953382668, 'bagging_fraction': 0.6517498369358636, 'min_child_samples': 11, 'min_child_weight': 27.536654289061364, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\tvalid_0's binary_logloss: 0.489087\n",
      "roc-auc : 0.7416513385740153\n",
      "\n",
      "| \u001b[39m32       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.6517   \u001b[39m | \u001b[39m0.923    \u001b[39m | \u001b[39m0.3431   \u001b[39m | \u001b[39m1.182    \u001b[39m | \u001b[39m10.75    \u001b[39m | \u001b[39m27.54    \u001b[39m | \u001b[39m20.04    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 39, 'lambda_l1': 0.42671426606900587, 'lambda_l2': 1.7334646073116118, 'feature_fraction': 0.8942436625418354, 'bagging_fraction': 0.8174365952761659, 'min_child_samples': 25, 'min_child_weight': 39.89842681667326, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1853]\tvalid_0's binary_logloss: 0.489164\n",
      "roc-auc : 0.7414928439210086\n",
      "\n",
      "| \u001b[39m33       \u001b[39m | \u001b[39m0.7415   \u001b[39m | \u001b[39m0.8174   \u001b[39m | \u001b[39m0.8942   \u001b[39m | \u001b[39m0.4267   \u001b[39m | \u001b[39m1.733    \u001b[39m | \u001b[39m24.77    \u001b[39m | \u001b[39m39.9     \u001b[39m | \u001b[39m38.9     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 23, 'lambda_l1': 0.20797428261628603, 'lambda_l2': 0.832430257114294, 'feature_fraction': 0.8277795260627084, 'bagging_fraction': 0.5273779521888131, 'min_child_samples': 25, 'min_child_weight': 28.24156236805395, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2383]\tvalid_0's binary_logloss: 0.489101\n",
      "roc-auc : 0.7416197067687029\n",
      "\n",
      "| \u001b[39m34       \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.5274   \u001b[39m | \u001b[39m0.8278   \u001b[39m | \u001b[39m0.208    \u001b[39m | \u001b[39m0.8324   \u001b[39m | \u001b[39m24.95    \u001b[39m | \u001b[39m28.24    \u001b[39m | \u001b[39m22.59    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 20, 'lambda_l1': 0.04210032180199713, 'lambda_l2': 1.1301071409129362, 'feature_fraction': 0.8302099099015073, 'bagging_fraction': 0.9993754176248141, 'min_child_samples': 5, 'min_child_weight': 38.652584568726, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2495]\tvalid_0's binary_logloss: 0.489122\n",
      "roc-auc : 0.7415956453140004\n",
      "\n",
      "| \u001b[39m35       \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.9994   \u001b[39m | \u001b[39m0.8302   \u001b[39m | \u001b[39m0.0421   \u001b[39m | \u001b[39m1.13     \u001b[39m | \u001b[39m5.248    \u001b[39m | \u001b[39m38.65    \u001b[39m | \u001b[39m20.29    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 22, 'lambda_l1': 0.25843770662353094, 'lambda_l2': 1.159627459087005, 'feature_fraction': 0.8932179701530235, 'bagging_fraction': 0.6711761060775603, 'min_child_samples': 9, 'min_child_weight': 36.64986900362843, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2493]\tvalid_0's binary_logloss: 0.489037\n",
      "roc-auc : 0.7416896848825024\n",
      "\n",
      "| \u001b[39m36       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.6712   \u001b[39m | \u001b[39m0.8932   \u001b[39m | \u001b[39m0.2584   \u001b[39m | \u001b[39m1.16     \u001b[39m | \u001b[39m9.165    \u001b[39m | \u001b[39m36.65    \u001b[39m | \u001b[39m22.42    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 25, 'lambda_l1': 0.08109090767033089, 'lambda_l2': 1.8207224954760892, 'feature_fraction': 0.8566731443500173, 'bagging_fraction': 0.5725720101332591, 'min_child_samples': 8, 'min_child_weight': 38.70487353035977, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2499]\tvalid_0's binary_logloss: 0.489078\n",
      "roc-auc : 0.7416674525919255\n",
      "\n",
      "| \u001b[39m37       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.5726   \u001b[39m | \u001b[39m0.8567   \u001b[39m | \u001b[39m0.08109  \u001b[39m | \u001b[39m1.821    \u001b[39m | \u001b[39m8.484    \u001b[39m | \u001b[39m38.7     \u001b[39m | \u001b[39m25.17    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 26, 'lambda_l1': 0.26933844973958543, 'lambda_l2': 1.353815290769846, 'feature_fraction': 0.8309625925426313, 'bagging_fraction': 0.8986338653925369, 'min_child_samples': 24, 'min_child_weight': 39.94968684820828, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2499]\tvalid_0's binary_logloss: 0.489134\n",
      "roc-auc : 0.7415539072041447\n",
      "\n",
      "| \u001b[39m38       \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.8986   \u001b[39m | \u001b[39m0.831    \u001b[39m | \u001b[39m0.2693   \u001b[39m | \u001b[39m1.354    \u001b[39m | \u001b[39m24.01    \u001b[39m | \u001b[39m39.95    \u001b[39m | \u001b[39m25.54    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 20, 'lambda_l1': 0.3269955553536966, 'lambda_l2': 1.9033607732514444, 'feature_fraction': 0.9793613818597051, 'bagging_fraction': 0.7326622782065487, 'min_child_samples': 8, 'min_child_weight': 28.668697874167904, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\tvalid_0's binary_logloss: 0.489069\n",
      "roc-auc : 0.7416451245490981\n",
      "\n",
      "| \u001b[39m39       \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.7327   \u001b[39m | \u001b[39m0.9794   \u001b[39m | \u001b[39m0.327    \u001b[39m | \u001b[39m1.903    \u001b[39m | \u001b[39m8.315    \u001b[39m | \u001b[39m28.67    \u001b[39m | \u001b[39m20.01    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 20, 'lambda_l1': 0.48642624318785394, 'lambda_l2': 1.1657956844491042, 'feature_fraction': 0.8136395331812732, 'bagging_fraction': 0.8315295506055409, 'min_child_samples': 11, 'min_child_weight': 34.6677375034418, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2489]\tvalid_0's binary_logloss: 0.489113\n",
      "roc-auc : 0.7416392323307139\n",
      "\n",
      "| \u001b[39m40       \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.8315   \u001b[39m | \u001b[39m0.8136   \u001b[39m | \u001b[39m0.4864   \u001b[39m | \u001b[39m1.166    \u001b[39m | \u001b[39m10.69    \u001b[39m | \u001b[39m34.67    \u001b[39m | \u001b[39m20.09    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 25, 'lambda_l1': 0.4790306962627683, 'lambda_l2': 0.8345588929994263, 'feature_fraction': 0.8425734390406703, 'bagging_fraction': 0.7214926133554848, 'min_child_samples': 5, 'min_child_weight': 39.40454193415121, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\tvalid_0's binary_logloss: 0.489076\n",
      "roc-auc : 0.7416098946308672\n",
      "\n",
      "| \u001b[39m41       \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.7215   \u001b[39m | \u001b[39m0.8426   \u001b[39m | \u001b[39m0.479    \u001b[39m | \u001b[39m0.8346   \u001b[39m | \u001b[39m5.207    \u001b[39m | \u001b[39m39.4     \u001b[39m | \u001b[39m24.59    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 25, 'lambda_l1': 0.08436715841913012, 'lambda_l2': 1.7587119290442923, 'feature_fraction': 0.9410556684868921, 'bagging_fraction': 0.6507249838346787, 'min_child_samples': 5, 'min_child_weight': 27.782172974926233, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2227]\tvalid_0's binary_logloss: 0.48906\n",
      "roc-auc : 0.741680476872268\n",
      "\n",
      "| \u001b[39m42       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.6507   \u001b[39m | \u001b[39m0.9411   \u001b[39m | \u001b[39m0.08437  \u001b[39m | \u001b[39m1.759    \u001b[39m | \u001b[39m5.081    \u001b[39m | \u001b[39m27.78    \u001b[39m | \u001b[39m24.96    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 21, 'lambda_l1': 0.4055086093682382, 'lambda_l2': 1.7045905354988022, 'feature_fraction': 0.9319050050793867, 'bagging_fraction': 0.6232617063744976, 'min_child_samples': 19, 'min_child_weight': 34.3982484593532, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2470]\tvalid_0's binary_logloss: 0.489077\n",
      "roc-auc : 0.7416713774470598\n",
      "\n",
      "| \u001b[39m43       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.6233   \u001b[39m | \u001b[39m0.9319   \u001b[39m | \u001b[39m0.4055   \u001b[39m | \u001b[39m1.705    \u001b[39m | \u001b[39m18.61    \u001b[39m | \u001b[39m34.4     \u001b[39m | \u001b[39m21.0     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 20, 'lambda_l1': 0.43887568033054747, 'lambda_l2': 1.221549282383143, 'feature_fraction': 0.845170565284324, 'bagging_fraction': 0.8240678523381832, 'min_child_samples': 17, 'min_child_weight': 30.808423536842863, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2499]\tvalid_0's binary_logloss: 0.489068\n",
      "roc-auc : 0.7417008128734301\n",
      "\n",
      "| \u001b[39m44       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.8241   \u001b[39m | \u001b[39m0.8452   \u001b[39m | \u001b[39m0.4389   \u001b[39m | \u001b[39m1.222    \u001b[39m | \u001b[39m17.07    \u001b[39m | \u001b[39m30.81    \u001b[39m | \u001b[39m20.2     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 23, 'lambda_l1': 0.3276696692509975, 'lambda_l2': 0.8510447832916533, 'feature_fraction': 0.8316119437842648, 'bagging_fraction': 0.7161867241316888, 'min_child_samples': 18, 'min_child_weight': 31.676714057687647, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\tvalid_0's binary_logloss: 0.489054\n",
      "roc-auc : 0.7416707535767266\n",
      "\n",
      "| \u001b[39m45       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.7162   \u001b[39m | \u001b[39m0.8316   \u001b[39m | \u001b[39m0.3277   \u001b[39m | \u001b[39m0.851    \u001b[39m | \u001b[39m18.47    \u001b[39m | \u001b[39m31.68    \u001b[39m | \u001b[39m23.15    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 22, 'lambda_l1': 0.24309821836854262, 'lambda_l2': 0.8008220105672806, 'feature_fraction': 0.9926343296726672, 'bagging_fraction': 0.5961299032180885, 'min_child_samples': 19, 'min_child_weight': 28.299699797455002, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2474]\tvalid_0's binary_logloss: 0.48906\n",
      "roc-auc : 0.7416828223088372\n",
      "\n",
      "| \u001b[39m46       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.5961   \u001b[39m | \u001b[39m0.9926   \u001b[39m | \u001b[39m0.2431   \u001b[39m | \u001b[39m0.8008   \u001b[39m | \u001b[39m18.76    \u001b[39m | \u001b[39m28.3     \u001b[39m | \u001b[39m21.61    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 20, 'lambda_l1': 0.11741110951897632, 'lambda_l2': 1.6840440119076563, 'feature_fraction': 0.8145668159921787, 'bagging_fraction': 0.726676717801133, 'min_child_samples': 18, 'min_child_weight': 39.081475601076576, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\tvalid_0's binary_logloss: 0.48911\n",
      "roc-auc : 0.7415935664043142\n",
      "\n",
      "| \u001b[39m47       \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.7267   \u001b[39m | \u001b[39m0.8146   \u001b[39m | \u001b[39m0.1174   \u001b[39m | \u001b[39m1.684    \u001b[39m | \u001b[39m17.9     \u001b[39m | \u001b[39m39.08    \u001b[39m | \u001b[39m20.23    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 40, 'lambda_l1': 0.09406442533410098, 'lambda_l2': 1.4206196990696607, 'feature_fraction': 0.8283869608212318, 'bagging_fraction': 0.7845736318083735, 'min_child_samples': 5, 'min_child_weight': 39.86268364690325, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1982]\tvalid_0's binary_logloss: 0.48915\n",
      "roc-auc : 0.741483051525905\n",
      "\n",
      "| \u001b[39m48       \u001b[39m | \u001b[39m0.7415   \u001b[39m | \u001b[39m0.7846   \u001b[39m | \u001b[39m0.8284   \u001b[39m | \u001b[39m0.09406  \u001b[39m | \u001b[39m1.421    \u001b[39m | \u001b[39m5.044    \u001b[39m | \u001b[39m39.86    \u001b[39m | \u001b[39m39.61    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 25, 'lambda_l1': 0.08295080975123248, 'lambda_l2': 1.5431784928144827, 'feature_fraction': 0.8670417931369437, 'bagging_fraction': 0.7483145520800984, 'min_child_samples': 19, 'min_child_weight': 25.668114691830247, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2221]\tvalid_0's binary_logloss: 0.489101\n",
      "roc-auc : 0.7416234420936093\n",
      "\n",
      "| \u001b[39m49       \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.7483   \u001b[39m | \u001b[39m0.867    \u001b[39m | \u001b[39m0.08295  \u001b[39m | \u001b[39m1.543    \u001b[39m | \u001b[39m18.53    \u001b[39m | \u001b[39m25.67    \u001b[39m | \u001b[39m25.11    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 30, 'lambda_l1': 0.37874199639172895, 'lambda_l2': 1.926134957880622, 'feature_fraction': 0.9658418304125351, 'bagging_fraction': 0.5068822138874091, 'min_child_samples': 7, 'min_child_weight': 39.98536339640626, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1888]\tvalid_0's binary_logloss: 0.48914\n",
      "roc-auc : 0.7416360221624803\n",
      "\n",
      "| \u001b[39m50       \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.5069   \u001b[39m | \u001b[39m0.9658   \u001b[39m | \u001b[39m0.3787   \u001b[39m | \u001b[39m1.926    \u001b[39m | \u001b[39m7.098    \u001b[39m | \u001b[39m39.99    \u001b[39m | \u001b[39m30.4     \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 25, 'lambda_l1': 0.06273766303761036, 'lambda_l2': 1.0206275402912937, 'feature_fraction': 0.8050996794723333, 'bagging_fraction': 0.8087282115164022, 'min_child_samples': 12, 'min_child_weight': 39.98397694059843, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2489]\tvalid_0's binary_logloss: 0.489099\n",
      "roc-auc : 0.7415994053173219\n",
      "\n",
      "| \u001b[39m51       \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.8087   \u001b[39m | \u001b[39m0.8051   \u001b[39m | \u001b[39m0.06274  \u001b[39m | \u001b[39m1.021    \u001b[39m | \u001b[39m11.85    \u001b[39m | \u001b[39m39.98    \u001b[39m | \u001b[39m24.76    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 24, 'lambda_l1': 0.04811015026095178, 'lambda_l2': 1.9483311603902702, 'feature_fraction': 0.9534471026963212, 'bagging_fraction': 0.5676682710015916, 'min_child_samples': 20, 'min_child_weight': 35.098326662286894, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2170]\tvalid_0's binary_logloss: 0.489006\n",
      "roc-auc : 0.7418223441963306\n",
      "\n",
      "| \u001b[35m52       \u001b[39m | \u001b[35m0.7418   \u001b[39m | \u001b[35m0.5677   \u001b[39m | \u001b[35m0.9534   \u001b[39m | \u001b[35m0.04811  \u001b[39m | \u001b[35m1.948    \u001b[39m | \u001b[35m19.75    \u001b[39m | \u001b[35m35.1     \u001b[39m | \u001b[35m24.45    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 25, 'lambda_l1': 0.1989489173453292, 'lambda_l2': 1.3231883343947008, 'feature_fraction': 0.9394391841433092, 'bagging_fraction': 0.5817417839381753, 'min_child_samples': 20, 'min_child_weight': 36.73882593944697, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2297]\tvalid_0's binary_logloss: 0.48905\n",
      "roc-auc : 0.741702049755594\n",
      "\n",
      "| \u001b[39m53       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.5817   \u001b[39m | \u001b[39m0.9394   \u001b[39m | \u001b[39m0.1989   \u001b[39m | \u001b[39m1.323    \u001b[39m | \u001b[39m19.69    \u001b[39m | \u001b[39m36.74    \u001b[39m | \u001b[39m24.73    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 25, 'lambda_l1': 0.4303084055687436, 'lambda_l2': 1.2076602644726442, 'feature_fraction': 0.8223607272878416, 'bagging_fraction': 0.5554040442153764, 'min_child_samples': 21, 'min_child_weight': 33.84186128013285, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2493]\tvalid_0's binary_logloss: 0.489049\n",
      "roc-auc : 0.7417174214467788\n",
      "\n",
      "| \u001b[39m54       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.5554   \u001b[39m | \u001b[39m0.8224   \u001b[39m | \u001b[39m0.4303   \u001b[39m | \u001b[39m1.208    \u001b[39m | \u001b[39m20.99    \u001b[39m | \u001b[39m33.84    \u001b[39m | \u001b[39m24.99    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 25, 'lambda_l1': 0.48837871896811474, 'lambda_l2': 1.9768347853111652, 'feature_fraction': 0.8052069339821891, 'bagging_fraction': 0.9543948469013965, 'min_child_samples': 19, 'min_child_weight': 34.504824858805684, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2495]\tvalid_0's binary_logloss: 0.489221\n",
      "roc-auc : 0.7413993630718239\n",
      "\n",
      "| \u001b[39m55       \u001b[39m | \u001b[39m0.7414   \u001b[39m | \u001b[39m0.9544   \u001b[39m | \u001b[39m0.8052   \u001b[39m | \u001b[39m0.4884   \u001b[39m | \u001b[39m1.977    \u001b[39m | \u001b[39m18.71    \u001b[39m | \u001b[39m34.5     \u001b[39m | \u001b[39m24.51    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 25, 'lambda_l1': 0.26154403687102606, 'lambda_l2': 1.702721319023961, 'feature_fraction': 0.8858914449971139, 'bagging_fraction': 0.6740181750913994, 'min_child_samples': 9, 'min_child_weight': 38.921358347512275, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2485]\tvalid_0's binary_logloss: 0.489026\n",
      "roc-auc : 0.7417305325951422\n",
      "\n",
      "| \u001b[39m56       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.674    \u001b[39m | \u001b[39m0.8859   \u001b[39m | \u001b[39m0.2615   \u001b[39m | \u001b[39m1.703    \u001b[39m | \u001b[39m8.51     \u001b[39m | \u001b[39m38.92    \u001b[39m | \u001b[39m25.33    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 25, 'lambda_l1': 0.05130111759067757, 'lambda_l2': 1.35651772748019, 'feature_fraction': 0.9719783898739811, 'bagging_fraction': 0.5675374454279426, 'min_child_samples': 20, 'min_child_weight': 35.14544910804348, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2211]\tvalid_0's binary_logloss: 0.489062\n",
      "roc-auc : 0.7416688464288094\n",
      "\n",
      "| \u001b[39m57       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.5675   \u001b[39m | \u001b[39m0.972    \u001b[39m | \u001b[39m0.0513   \u001b[39m | \u001b[39m1.357    \u001b[39m | \u001b[39m19.96    \u001b[39m | \u001b[39m35.15    \u001b[39m | \u001b[39m24.57    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 25, 'lambda_l1': 0.3021492708102288, 'lambda_l2': 1.9567812875845025, 'feature_fraction': 0.956384819453195, 'bagging_fraction': 0.6753391359763006, 'min_child_samples': 8, 'min_child_weight': 38.66548023473677, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2484]\tvalid_0's binary_logloss: 0.489041\n",
      "roc-auc : 0.7416578003702197\n",
      "\n",
      "| \u001b[39m58       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.6753   \u001b[39m | \u001b[39m0.9564   \u001b[39m | \u001b[39m0.3021   \u001b[39m | \u001b[39m1.957    \u001b[39m | \u001b[39m8.478    \u001b[39m | \u001b[39m38.67    \u001b[39m | \u001b[39m25.11    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 24, 'lambda_l1': 0.1622955377379406, 'lambda_l2': 1.6530710692557267, 'feature_fraction': 0.8281942247965851, 'bagging_fraction': 0.8782933768840169, 'min_child_samples': 20, 'min_child_weight': 35.22908800600582, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2499]\tvalid_0's binary_logloss: 0.489119\n",
      "roc-auc : 0.7416061306789994\n",
      "\n",
      "| \u001b[39m59       \u001b[39m | \u001b[39m0.7416   \u001b[39m | \u001b[39m0.8783   \u001b[39m | \u001b[39m0.8282   \u001b[39m | \u001b[39m0.1623   \u001b[39m | \u001b[39m1.653    \u001b[39m | \u001b[39m19.54    \u001b[39m | \u001b[39m35.23    \u001b[39m | \u001b[39m24.23    \u001b[39m |\n",
      "하이퍼파라미터: {'num_leaves': 20, 'lambda_l1': 0.43711432451985155, 'lambda_l2': 1.9528225265083132, 'feature_fraction': 0.9953435628923555, 'bagging_fraction': 0.6722419982855203, 'min_child_samples': 23, 'min_child_weight': 26.487597682299235, 'feature_pre_filter': False, 'objective': 'binary', 'learning_rate': 0.005, 'bagging_freq': 1, 'force_row_wise': True, 'random_state': 1991}\n",
      "[LightGBM] [Info] Number of positive: 52867, number of negative: 152213\n",
      "[LightGBM] [Info] Total Bins 763\n",
      "[LightGBM] [Info] Number of data points in the train set: 205080, number of used features: 100\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.257787 -> initscore=-1.057502\n",
      "[LightGBM] [Info] Start training from score -1.057502\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\tvalid_0's binary_logloss: 0.489057\n",
      "roc-auc : 0.7416757731663537\n",
      "\n",
      "| \u001b[39m60       \u001b[39m | \u001b[39m0.7417   \u001b[39m | \u001b[39m0.6722   \u001b[39m | \u001b[39m0.9953   \u001b[39m | \u001b[39m0.4371   \u001b[39m | \u001b[39m1.953    \u001b[39m | \u001b[39m22.98    \u001b[39m | \u001b[39m26.49    \u001b[39m | \u001b[39m20.35    \u001b[39m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# 베이지안 최적화 수행\n",
    "# TODO: init_points 10~15, n_iter 30~70\n",
    "optimizer.maximize(init_points=10, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfefd269",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T09:25:56.500966Z",
     "iopub.status.busy": "2025-02-13T09:25:56.500623Z",
     "iopub.status.idle": "2025-02-13T09:25:56.506127Z",
     "shell.execute_reply": "2025-02-13T09:25:56.505475Z"
    },
    "papermill": {
     "duration": 0.021413,
     "end_time": "2025-02-13T09:25:56.507377",
     "exception": false,
     "start_time": "2025-02-13T09:25:56.485964",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.5676682710015916,\n",
       " 'feature_fraction': 0.9534471026963212,\n",
       " 'lambda_l1': 0.04811015026095178,\n",
       " 'lambda_l2': 1.9483311603902702,\n",
       " 'min_child_samples': 19.753033722267613,\n",
       " 'min_child_weight': 35.098326662286894,\n",
       " 'num_leaves': 24.44991218235853}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 평가함수 점수가 최대일 때 하이퍼파라미터\n",
    "max_params = optimizer.max['params']\n",
    "max_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "759c3f4e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T09:25:56.536763Z",
     "iopub.status.busy": "2025-02-13T09:25:56.536512Z",
     "iopub.status.idle": "2025-02-13T09:25:56.540062Z",
     "shell.execute_reply": "2025-02-13T09:25:56.539400Z"
    },
    "papermill": {
     "duration": 0.019573,
     "end_time": "2025-02-13T09:25:56.541310",
     "exception": false,
     "start_time": "2025-02-13T09:25:56.521737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 정수형 하이퍼파라미터 변환\n",
    "max_params['num_leaves'] = int(round(max_params['num_leaves']))\n",
    "max_params['min_child_samples'] = int(round(max_params['min_child_samples']))\n",
    "\n",
    "# 값이 고정된 하이퍼파라미터 추가\n",
    "max_params.update(fixed_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e67a55f3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T09:25:56.569843Z",
     "iopub.status.busy": "2025-02-13T09:25:56.569584Z",
     "iopub.status.idle": "2025-02-13T09:25:56.574652Z",
     "shell.execute_reply": "2025-02-13T09:25:56.573798Z"
    },
    "papermill": {
     "duration": 0.020783,
     "end_time": "2025-02-13T09:25:56.575942",
     "exception": false,
     "start_time": "2025-02-13T09:25:56.555159",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.5676682710015916,\n",
       " 'feature_fraction': 0.9534471026963212,\n",
       " 'lambda_l1': 0.04811015026095178,\n",
       " 'lambda_l2': 1.9483311603902702,\n",
       " 'min_child_samples': 20,\n",
       " 'min_child_weight': 35.098326662286894,\n",
       " 'num_leaves': 24,\n",
       " 'objective': 'binary',\n",
       " 'learning_rate': 0.005,\n",
       " 'bagging_freq': 1,\n",
       " 'force_row_wise': True,\n",
       " 'random_state': 1991}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "59c6fdc7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T09:25:56.606335Z",
     "iopub.status.busy": "2025-02-13T09:25:56.606011Z",
     "iopub.status.idle": "2025-02-13T09:25:56.609990Z",
     "shell.execute_reply": "2025-02-13T09:25:56.609105Z"
    },
    "papermill": {
     "duration": 0.020794,
     "end_time": "2025-02-13T09:25:56.611390",
     "exception": false,
     "start_time": "2025-02-13T09:25:56.590596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# 층화 K 폴드 교차 검증기 생성\n",
    "folds = StratifiedKFold(n_splits=10, shuffle=True, random_state=1991)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3754ce1c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T09:25:56.640315Z",
     "iopub.status.busy": "2025-02-13T09:25:56.640014Z",
     "iopub.status.idle": "2025-02-13T09:25:56.643786Z",
     "shell.execute_reply": "2025-02-13T09:25:56.642958Z"
    },
    "papermill": {
     "duration": 0.019665,
     "end_time": "2025-02-13T09:25:56.645107",
     "exception": false,
     "start_time": "2025-02-13T09:25:56.625442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def lgb_roc_auc(y_pred, dataset):\n",
    "    y_true = dataset.get_label()\n",
    "    return \"roc_auc\", roc_auc_score(y_true, y_pred), True  # (지표 이름, 값, 높은 값이 더 좋은지 여부)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "60ba9aa5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T09:25:56.674428Z",
     "iopub.status.busy": "2025-02-13T09:25:56.674094Z",
     "iopub.status.idle": "2025-02-13T09:35:58.440653Z",
     "shell.execute_reply": "2025-02-13T09:35:58.439780Z"
    },
    "papermill": {
     "duration": 601.783272,
     "end_time": "2025-02-13T09:35:58.442584",
     "exception": false,
     "start_time": "2025-02-13T09:25:56.659312",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######################################## 폴드 1 / 폴드 10 ########################################\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171110\n",
      "[LightGBM] [Info] Total Bins 747\n",
      "[LightGBM] [Info] Number of data points in the train set: 230715, number of used features: 91\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258349 -> initscore=-1.054567\n",
      "[LightGBM] [Info] Start training from score -1.054567\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2252]\tvalid_0's binary_logloss: 0.487853\tvalid_0's roc_auc: 0.740125\n",
      "폴드 1 roc-auc : 0.7401253641319613\n",
      "\n",
      "######################################## 폴드 2 / 폴드 10 ########################################\n",
      "[LightGBM] [Info] Number of positive: 59606, number of negative: 171110\n",
      "[LightGBM] [Info] Total Bins 746\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 91\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258352 -> initscore=-1.054550\n",
      "[LightGBM] [Info] Start training from score -1.054550\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2186]\tvalid_0's binary_logloss: 0.487174\tvalid_0's roc_auc: 0.739541\n",
      "폴드 2 roc-auc : 0.7395414037634966\n",
      "\n",
      "######################################## 폴드 3 / 폴드 10 ########################################\n",
      "[LightGBM] [Info] Number of positive: 59606, number of negative: 171110\n",
      "[LightGBM] [Info] Total Bins 751\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 91\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258352 -> initscore=-1.054550\n",
      "[LightGBM] [Info] Start training from score -1.054550\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[2500]\tvalid_0's binary_logloss: 0.489702\tvalid_0's roc_auc: 0.734962\n",
      "폴드 3 roc-auc : 0.7349624459368221\n",
      "\n",
      "######################################## 폴드 4 / 폴드 10 ########################################\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 745\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 91\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1903]\tvalid_0's binary_logloss: 0.488254\tvalid_0's roc_auc: 0.739345\n",
      "폴드 4 roc-auc : 0.739345318082123\n",
      "\n",
      "######################################## 폴드 5 / 폴드 10 ########################################\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 753\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 91\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2004]\tvalid_0's binary_logloss: 0.486964\tvalid_0's roc_auc: 0.74242\n",
      "폴드 5 roc-auc : 0.7424202373643303\n",
      "\n",
      "######################################## 폴드 6 / 폴드 10 ########################################\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 752\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 91\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2258]\tvalid_0's binary_logloss: 0.489283\tvalid_0's roc_auc: 0.736175\n",
      "폴드 6 roc-auc : 0.7361745813153158\n",
      "\n",
      "######################################## 폴드 7 / 폴드 10 ########################################\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 753\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 92\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1568]\tvalid_0's binary_logloss: 0.486662\tvalid_0's roc_auc: 0.744029\n",
      "폴드 7 roc-auc : 0.7440292881131775\n",
      "\n",
      "######################################## 폴드 8 / 폴드 10 ########################################\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 752\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 91\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[1949]\tvalid_0's binary_logloss: 0.488043\tvalid_0's roc_auc: 0.740472\n",
      "폴드 8 roc-auc : 0.7404724104572303\n",
      "\n",
      "######################################## 폴드 9 / 폴드 10 ########################################\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 748\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 91\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2008]\tvalid_0's binary_logloss: 0.484789\tvalid_0's roc_auc: 0.745771\n",
      "폴드 9 roc-auc : 0.7457711570644655\n",
      "\n",
      "######################################## 폴드 10 / 폴드 10 ########################################\n",
      "[LightGBM] [Info] Number of positive: 59605, number of negative: 171111\n",
      "[LightGBM] [Info] Total Bins 754\n",
      "[LightGBM] [Info] Number of data points in the train set: 230716, number of used features: 92\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.258348 -> initscore=-1.054573\n",
      "[LightGBM] [Info] Start training from score -1.054573\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Early stopping, best iteration is:\n",
      "[2256]\tvalid_0's binary_logloss: 0.487692\tvalid_0's roc_auc: 0.741323\n",
      "폴드 10 roc-auc : 0.7413229663447696\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "# OOF 방식으로 훈련된 모델로 검증 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
    "oof_val_preds_lgb = np.zeros(X.shape[0]) \n",
    "# OOF 방식으로 훈련된 모델로 테스트 데이터 타깃값을 예측한 확률을 담을 1차원 배열\n",
    "oof_test_preds_lgb = np.zeros(X_test.shape[0]) \n",
    "\n",
    "# fold별 feature importance\n",
    "fold_importance_df = pd.DataFrame()\n",
    "\n",
    "# OOF 방식으로 모델 훈련, 검증, 예측\n",
    "for idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
    "    # 각 폴드를 구분하는 문구 출력\n",
    "    print('#'*40, f'폴드 {idx+1} / 폴드 {folds.n_splits}', '#'*40)\n",
    "    \n",
    "    # 훈련용 데이터, 검증용 데이터 설정\n",
    "    X_train, y_train = X[train_idx], y[train_idx] # 훈련용 데이터\n",
    "    X_valid, y_valid = X[valid_idx], y[valid_idx] # 검증용 데이터\n",
    "\n",
    "    # LightGBM 전용 데이터셋 생성\n",
    "    dtrain = lgb.Dataset(X_train, y_train) # LightGBM 전용 훈련 데이터셋\n",
    "    dvalid = lgb.Dataset(X_valid, y_valid) # LightGBM 전용 검증 데이터셋\n",
    "                          \n",
    "    # LightGBM 모델 훈련\n",
    "    lgb_model = lgb.train(params=max_params,     # 최적 하이퍼파라미터\n",
    "                          train_set=dtrain,          # 훈련 데이터셋\n",
    "                          num_boost_round=2500,      # 부스팅 반복 횟수\n",
    "                          valid_sets=dvalid,         # 성능 평가용 검증 데이터셋\n",
    "                          feval = lgb_roc_auc,\n",
    "                          callbacks=[lgb.early_stopping(stopping_rounds=100)])\n",
    "\n",
    "    # 테스트 데이터를 활용해 OOF 예측\n",
    "    oof_test_preds_lgb += lgb_model.predict(X_test)/folds.n_splits\n",
    "    \n",
    "    # 모델 성능 평가를 위한 검증 데이터 타깃값 예측 \n",
    "    oof_val_preds_lgb[valid_idx] += lgb_model.predict(X_valid)\n",
    "\n",
    "    # Feature Importance 저장\n",
    "    fold_importance = pd.DataFrame({\n",
    "        'Feature': extracted_encoded_features,\n",
    "        'Importance': lgb_model.feature_importance(importance_type='gain'),\n",
    "        'Fold': idx + 1\n",
    "    })\n",
    "    fold_importance_df = pd.concat([fold_importance_df, fold_importance], axis=0)\n",
    "    \n",
    "    # 검증 데이터 예측 확률에 대한 ROC-AUC\n",
    "    roc_auc = roc_auc_score(y_valid, oof_val_preds_lgb[valid_idx])\n",
    "    print(f'폴드 {idx+1} roc-auc : {roc_auc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "18fd03f5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T09:35:58.475043Z",
     "iopub.status.busy": "2025-02-13T09:35:58.474816Z",
     "iopub.status.idle": "2025-02-13T09:35:58.584872Z",
     "shell.execute_reply": "2025-02-13T09:35:58.583985Z"
    },
    "papermill": {
     "duration": 0.12745,
     "end_time": "2025-02-13T09:35:58.586262",
     "exception": false,
     "start_time": "2025-02-13T09:35:58.458812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OOF 검증 데이터 roc-auc : 0.740382334703773\n"
     ]
    }
   ],
   "source": [
    "print('OOF 검증 데이터 roc-auc :', roc_auc_score(y, oof_val_preds_lgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b763e75b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T09:35:58.618877Z",
     "iopub.status.busy": "2025-02-13T09:35:58.618618Z",
     "iopub.status.idle": "2025-02-13T09:35:58.812933Z",
     "shell.execute_reply": "2025-02-13T09:35:58.812290Z"
    },
    "papermill": {
     "duration": 0.211637,
     "end_time": "2025-02-13T09:35:58.814480",
     "exception": false,
     "start_time": "2025-02-13T09:35:58.602843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "submission['posibility'] = oof_test_preds_lgb\n",
    "submission.to_csv('alllll_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "767f2a5d",
   "metadata": {
    "papermill": {
     "duration": 0.015127,
     "end_time": "2025-02-13T09:35:58.845556",
     "exception": false,
     "start_time": "2025-02-13T09:35:58.830429",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bf432147",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T09:35:58.877171Z",
     "iopub.status.busy": "2025-02-13T09:35:58.876897Z",
     "iopub.status.idle": "2025-02-13T09:35:59.151514Z",
     "shell.execute_reply": "2025-02-13T09:35:59.150826Z"
    },
    "papermill": {
     "duration": 0.292242,
     "end_time": "2025-02-13T09:35:59.152957",
     "exception": false,
     "start_time": "2025-02-13T09:35:58.860715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ca377fc3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T09:35:59.185138Z",
     "iopub.status.busy": "2025-02-13T09:35:59.184711Z",
     "iopub.status.idle": "2025-02-13T09:35:59.187600Z",
     "shell.execute_reply": "2025-02-13T09:35:59.186991Z"
    },
    "papermill": {
     "duration": 0.019714,
     "end_time": "2025-02-13T09:35:59.188655",
     "exception": false,
     "start_time": "2025-02-13T09:35:59.168941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !apt-get update -qq\n",
    "# !apt-get install -qq -y fonts-nanum\n",
    "# !fc-cache -fv\n",
    "# !rm -rf ~/.cache/matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ce227c0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-13T09:35:59.220017Z",
     "iopub.status.busy": "2025-02-13T09:35:59.219790Z",
     "iopub.status.idle": "2025-02-13T09:35:59.413188Z",
     "shell.execute_reply": "2025-02-13T09:35:59.411978Z"
    },
    "papermill": {
     "duration": 0.210443,
     "end_time": "2025-02-13T09:35:59.414408",
     "exception": true,
     "start_time": "2025-02-13T09:35:59.203965",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-43980524e636>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 3️⃣ Matplotlib에 한글 폰트 적용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'font'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfamily\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfont_prop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'axes.unicode_minus'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# 마이너스(-) 기호 깨짐 방지\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/font_manager.py\u001b[0m in \u001b[0;36mget_name\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0mReturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mname\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfont\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mbest\u001b[0m \u001b[0mmatches\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfont\u001b[0m \u001b[0mproperties\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    663\u001b[0m         \"\"\"\n\u001b[0;32m--> 664\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_font\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfindfont\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfamily_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    665\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    666\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_style\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/_api/deprecation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    295\u001b[0m                 f\"for the old name will be dropped %(removal)s.\")\n\u001b[1;32m    296\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;31m# wrapper() must keep the same documented signature as func(): if we\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/font_manager.py\u001b[0m in \u001b[0;36mget_font\u001b[0;34m(font_filepaths, hinting_factor)\u001b[0m\n\u001b[1;32m   1521\u001b[0m         \u001b[0mhinting_factor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text.hinting_factor'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1523\u001b[0;31m     return _get_font(\n\u001b[0m\u001b[1;32m   1524\u001b[0m         \u001b[0;31m# must be a tuple to be cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1525\u001b[0m         \u001b[0mpaths\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/matplotlib/font_manager.py\u001b[0m in \u001b[0;36m_get_font\u001b[0;34m(font_filepaths, hinting_factor, _kerning_factor, thread_id)\u001b[0m\n\u001b[1;32m   1462\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_font\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfont_filepaths\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhinting_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_kerning_factor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthread_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1463\u001b[0m     \u001b[0mfirst_fontpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mrest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfont_filepaths\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1464\u001b[0;31m     return ft2font.FT2Font(\n\u001b[0m\u001b[1;32m   1465\u001b[0m         \u001b[0mfirst_fontpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhinting_factor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m         _fallback_list=[\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/usr/share/fonts/truetype/nanum/NanumGothic.ttf'"
     ]
    }
   ],
   "source": [
    "# 2️⃣ 한글 폰트 경로 설정\n",
    "font_path = \"/usr/share/fonts/truetype/nanum/NanumGothic.ttf\"\n",
    "font_prop = fm.FontProperties(fname=font_path)\n",
    "\n",
    "# 3️⃣ Matplotlib에 한글 폰트 적용\n",
    "mpl.rc('font', family=font_prop.get_name())  \n",
    "mpl.rcParams['axes.unicode_minus'] = False  # 마이너스(-) 기호 깨짐 방지\n",
    "\n",
    "# 4️⃣ 폰트가 제대로 적용됐는지 확인\n",
    "plt.figure(figsize=(5, 2))\n",
    "plt.text(0.5, 0.5, '한글 폰트 적용 확인!', fontsize=15, fontproperties=font_prop, ha='center')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e43961",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 전체 Fold에서 평균 Feature Importance 계산\n",
    "mean_importance = fold_importance_df.groupby(\"Feature\")[\"Importance\"].mean().reset_index()\n",
    "\n",
    "# 중요도 순으로 정렬\n",
    "mean_importance = mean_importance.sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "def plot_feature_importance(feature_importance, top_n=50):\n",
    "    \"\"\"\n",
    "    LightGBM Feature Importance 시각화 (상위 top_n개만)\n",
    "    \"\"\"\n",
    "    # 전체 gain feature importance 총합\n",
    "    print(feature_importance[\"Importance\"].sum())\n",
    "\n",
    "    # Gain이 0인 피처 제거\n",
    "    feature_importance = feature_importance[feature_importance[\"Importance\"] > 0]\n",
    "    \n",
    "    # 중요도가 높은 순으로 정렬 후 상위 N개 선택\n",
    "    feature_importance = feature_importance.sort_values(by='Importance', ascending=False).head(top_n)\n",
    "\n",
    "    # threshold = feature_importance[\"Importance\"].sum() * 0.01  # 전체 Gain의 1%\n",
    "    # feature_importance = feature_importance[feature_importance[\"Importance\"] >= threshold]\n",
    "\n",
    "    # 그래프 크기 설정\n",
    "    plt.figure(figsize=(12, max(6, top_n // 5)))  # Feature 개수에 따라 동적 크기 조절\n",
    "    \n",
    "    # 가로 막대 그래프\n",
    "    bars = plt.barh(feature_importance['Feature'], feature_importance['Importance'], color='skyblue')\n",
    "\n",
    "    # 제목 & 라벨 설정 (한글 폰트 적용)\n",
    "    plt.xlabel('Feature Importance (Mean Gain)', fontsize=12, fontproperties=font_prop)\n",
    "    plt.ylabel('Features', fontsize=12, fontproperties=font_prop)\n",
    "    plt.title(f'LightGBM Feature Importance (Top {top_n})', fontsize=14, fontproperties=font_prop)\n",
    "\n",
    "    # 각 막대 앞부분에 Feature Importance 값 표시\n",
    "    for bar, importance in zip(bars, feature_importance['Importance']):\n",
    "        plt.text(bar.get_width() + feature_importance['Importance'].max() * 0.01,  # 오른쪽 여백 추가\n",
    "                 bar.get_y() + bar.get_height()/2,  # 막대 중앙 정렬\n",
    "                 f'{importance:,.0f}',  # 천 단위 콤마 추가\n",
    "                 va='center',  # 수직 정렬\n",
    "                 fontsize=10,\n",
    "                 fontproperties=font_prop)\n",
    "\n",
    "    # 중요도가 높은 순으로 보기 위해 Y축 반전\n",
    "    plt.gca().invert_yaxis()\n",
    "    \n",
    "    # 레이아웃 조정\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # 그래프 표시\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# Feature Importance 시각화 (상위 50개만)\n",
    "plot_feature_importance(mean_importance, top_n=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeacf3c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6583998,
     "sourceId": 10634121,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30887,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2676.220984,
   "end_time": "2025-02-13T09:36:00.554641",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-02-13T08:51:24.333657",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
